{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/sdoneva/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('final_train_data_StdSc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('final_test_data_StdSc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the columns from the dataframe.\n",
    "columns = df.columns.tolist()\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns_subset = [c for c in columns if c not in [\"is_churn\",\"msno\",\"Unnamed: 0\",\"Unnamed: 0.1\"]]\n",
    "# Store the variable we'll be predicting on.\n",
    "target = \"is_churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70598, 154)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df[columns_subset]\n",
    "y_train = df[target]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70598,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=df[target]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262843, 154)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test[columns_subset]\n",
    "y_test=df_test[target]\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(features):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=features, kernel_initializer='normal', activation='relu'))\n",
    "    #if we want a hidden layer :\n",
    "    #model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide on dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 9s 127us/step - loss: 0.2474 - acc: 0.9087\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 9s 123us/step - loss: 0.2182 - acc: 0.9211\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 8s 120us/step - loss: 0.2118 - acc: 0.9227\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 9s 125us/step - loss: 0.2082 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 9s 120us/step - loss: 0.2052 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 9s 127us/step - loss: 0.2021 - acc: 0.9255\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 9s 127us/step - loss: 0.1997 - acc: 0.9264\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 9s 126us/step - loss: 0.1971 - acc: 0.9268\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 9s 130us/step - loss: 0.1951 - acc: 0.9271\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 9s 124us/step - loss: 0.1930 - acc: 0.9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1a8bb940>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all=baseline_model(154)\n",
    "model_all.fit(X_train, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0220938 24612\n",
      "    1 1425 15868\n",
      "\n",
      "Accuracy Score:\n",
      "0.90094086584\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.90      0.94    245550\n",
      "          1       0.39      0.92      0.55     17293\n",
      "\n",
      "avg / total       0.95      0.90      0.92    262843\n",
      "\n",
      "Log Loss:\n",
      "0.225461077679\n",
      "AUC Score:\n",
      "0.96204957219\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_all,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_59=['number_of_days_201702_listened','is_auto_renew','total_cancel','active_days','avg_plan_list_price','avg_actual_amount_paid','num_unq_201702_sum','num_totalsec_201702_sum','number_of_days_lasttwo_listened','most_fq_payment_method_id','num_75_mean','number_of_days_listened','num_25_201702_sum','num_50_201702_sum','num_75_201702_sum','num_100_201702_sum','num_25_201702_mean','num_50_201702_mean','num_100_lasttwo_mean','num_totalsec_lasttwo_mean','number_of_days_lastthree_listened','total_churn','registered_via_3','registered_via_4','registered_via_7','bd','num_100_sum','num_totalsec_sum','num_50_mean','num_100_mean','num_totalsec_mean','num_100_med','num_totalsec_med','num_25_max','num_unq_max','num_totalsec_max','num_totalsec_min','num_985_201702_sum','num_75_201702_mean','num_100_201702_mean','num_unq_201702_mean','num_totalsec_201702_mean','num_unq_201701_sum','num_100_201701_mean','number_of_days_201701_listened','num_25_201612_mean','num_100_201612_mean','num_unq_lasttwo_sum','num_75_lasttwo_mean','num_100_lastthree_sum','num_totalsec_lastthree_sum','num_50_lastthree_mean','num_75_lastthree_mean','num_100_lastthree_mean','num_totalsec_lastthree_mean','num_above_50_sum','proportion_songs_above_50','gender_2','registered_via_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_59 = df[top_59]\n",
    "X_test_59 = df_test[top_59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 8s 119us/step - loss: 0.2367 - acc: 0.9133\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 8s 115us/step - loss: 0.2120 - acc: 0.9234\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 8s 117us/step - loss: 0.2075 - acc: 0.9254\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 8s 118us/step - loss: 0.2047 - acc: 0.9264\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 9s 124us/step - loss: 0.2017 - acc: 0.9265\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 9s 123us/step - loss: 0.1988 - acc: 0.9270\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 7s 99us/step - loss: 0.1970 - acc: 0.9277\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 8s 115us/step - loss: 0.1948 - acc: 0.9282\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 9s 131us/step - loss: 0.1934 - acc: 0.9285\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 8s 115us/step - loss: 0.1917 - acc: 0.9292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1aca7828>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_59=baseline_model(59)\n",
    "model_59.fit(X_train_59, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0219013 26537\n",
      "    1 1052 16241\n",
      "\n",
      "Accuracy Score:\n",
      "0.895036200317\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94    245550\n",
      "          1       0.38      0.94      0.54     17293\n",
      "\n",
      "avg / total       0.95      0.90      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.251584923852\n",
      "AUC Score:\n",
      "0.968598060806\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_59,X_test_59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen by RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_RFE=['number_of_days_listened','num_totalsec_201702_sum','num_totalsec_201702_mean','number_of_days_201702_listened','num_unq_201701_sum','number_of_days_201701_listened','num_unq_lasttwo_sum','num_100_lasttwo_mean','num_totalsec_lasttwo_mean','number_of_days_lasttwo_listened','number_of_days_lastthree_listened','most_fq_payment_method_id','is_auto_renew','total_cancel','active_days','avg_plan_list_price','avg_actual_amount_paid','registered_via_3','registered_via_4','registered_via_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_RFE = df[top_RFE]\n",
    "X_test_RFE = df_test[top_RFE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 8s 118us/step - loss: 0.2317 - acc: 0.9163\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 8s 108us/step - loss: 0.2104 - acc: 0.9244\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 8s 115us/step - loss: 0.2066 - acc: 0.9252\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 10s 136us/step - loss: 0.2036 - acc: 0.9260\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 9s 126us/step - loss: 0.2007 - acc: 0.9273\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 8s 109us/step - loss: 0.1983 - acc: 0.9275\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 8s 108us/step - loss: 0.1966 - acc: 0.9282\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 8s 106us/step - loss: 0.1950 - acc: 0.9280\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 8s 107us/step - loss: 0.1940 - acc: 0.9290\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 8s 115us/step - loss: 0.1931 - acc: 0.9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1f20f160>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfe=baseline_model(20)\n",
    "model_rfe.fit(X_train_RFE, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0220387 25163\n",
      "    1  927 16366\n",
      "\n",
      "Accuracy Score:\n",
      "0.900739224556\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.94    245550\n",
      "          1       0.39      0.95      0.56     17293\n",
      "\n",
      "avg / total       0.96      0.90      0.92    262843\n",
      "\n",
      "Log Loss:\n",
      "0.214808279573\n",
      "AUC Score:\n",
      "0.970122542678\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_rfe,X_test_RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_PCA=['num_100_mean','num_100_lastthree_mean','num_totalsec_mean','num_totalsec_lastthree_mean','num_100_med','num_100_lasttwo_mean','num_totalsec_med','num_totalsec_lasttwo_mean','num_75_lastthree_mean','num_50_lastthree_mean','num_100_lastthree_sum','num_100_sum','num_totalsec_lastthree_sum','num_75_mean','num_totalsec_sum','num_above_50_sum','num_100_201701_mean','num_100_201612_mean','num_50_mean','num_75_lasttwo_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_PCA = df[top_PCA]\n",
    "X_test_PCA = df_test[top_PCA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 10s 139us/step - loss: 0.6715 - acc: 0.5787\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 8s 118us/step - loss: 0.6645 - acc: 0.5927\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 8s 114us/step - loss: 0.6618 - acc: 0.5969\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 7s 96us/step - loss: 0.6604 - acc: 0.6006\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 6s 89us/step - loss: 0.6594 - acc: 0.6012\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 7s 94us/step - loss: 0.6581 - acc: 0.6033\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 7s 105us/step - loss: 0.6571 - acc: 0.6042\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 8s 118us/step - loss: 0.6559 - acc: 0.6080\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 9s 126us/step - loss: 0.6545 - acc: 0.6097\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 8s 114us/step - loss: 0.6538 - acc: 0.6117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1ac15358>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca=baseline_model(20)\n",
    "model_pca.fit(X_train_PCA, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0176298 69252\n",
      "    1 8988  8305\n",
      "\n",
      "Accuracy Score:\n",
      "0.702331810244\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.72      0.82    245550\n",
      "          1       0.11      0.48      0.18     17293\n",
      "\n",
      "avg / total       0.90      0.70      0.78    262843\n",
      "\n",
      "Log Loss:\n",
      "0.645068196714\n",
      "AUC Score:\n",
      "0.646011762274\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_pca,X_test_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen by F-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_F=['num_25_201702_sum','num_50_201702_sum','num_75_201702_sum','num_985_201702_sum','num_100_201702_sum','num_unq_201702_sum','num_totalsec_201702_sum','number_of_days_201702_listened','number_of_days_lasttwo_listened','number_of_days_lastthree_listened','total_churn','is_auto_renew','total_cancel','active_days','avg_plan_list_price','avg_actual_amount_paid','gender_2','registered_via_3','registered_via_4','registered_via_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_F = df[top_F]\n",
    "X_test_F = df_test[top_F]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 8s 114us/step - loss: 0.2362 - acc: 0.9151\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 8s 118us/step - loss: 0.2132 - acc: 0.9243\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 7s 104us/step - loss: 0.2093 - acc: 0.9256\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 7s 104us/step - loss: 0.2054 - acc: 0.9262\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 7s 105us/step - loss: 0.2027 - acc: 0.9279\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 8s 107us/step - loss: 0.2004 - acc: 0.9281\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1986 - acc: 0.9287\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 7s 105us/step - loss: 0.1970 - acc: 0.9291\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 7s 106us/step - loss: 0.1957 - acc: 0.9296\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 7s 103us/step - loss: 0.1951 - acc: 0.9296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a19c832b0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_f=baseline_model(20)\n",
    "model_f.fit(X_train_F, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0219464 26086\n",
      "    1  811 16482\n",
      "\n",
      "Accuracy Score:\n",
      "0.897668950666\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94    245550\n",
      "          1       0.39      0.95      0.55     17293\n",
      "\n",
      "avg / total       0.96      0.90      0.92    262843\n",
      "\n",
      "Log Loss:\n",
      "0.210309633582\n",
      "AUC Score:\n",
      "0.969964711246\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_f,X_test_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen by Mutual Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_MI=['num_50_201702_sum','num_75_201702_sum','num_100_201702_sum','num_unq_201702_sum','num_totalsec_201702_sum','num_25_201702_mean','num_50_201702_mean','num_75_201702_mean','num_100_201702_mean','num_unq_201702_mean','number_of_days_201702_listened','number_of_days_lasttwo_listened','most_fq_payment_method_id','total_churn','is_auto_renew','total_cancel','active_days','avg_plan_list_price','avg_actual_amount_paid','registered_via_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_MI = df[top_MI]\n",
    "X_test_MI = df_test[top_MI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 8s 116us/step - loss: 0.2321 - acc: 0.9158\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 7s 106us/step - loss: 0.2101 - acc: 0.9251\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.2063 - acc: 0.9256\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 8s 107us/step - loss: 0.2038 - acc: 0.9267\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 9s 130us/step - loss: 0.2012 - acc: 0.9267\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 10s 147us/step - loss: 0.1993 - acc: 0.9273\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 7s 102us/step - loss: 0.1970 - acc: 0.9278\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 7s 98us/step - loss: 0.1957 - acc: 0.9282\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1943 - acc: 0.9281\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1935 - acc: 0.9290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1fbc3898>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mi=baseline_model(20)\n",
    "model_mi.fit(X_train_MI, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0219656 25894\n",
      "    1  880 16413\n",
      "\n",
      "Accuracy Score:\n",
      "0.898136910627\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94    245550\n",
      "          1       0.39      0.95      0.55     17293\n",
      "\n",
      "avg / total       0.96      0.90      0.92    262843\n",
      "\n",
      "Log Loss:\n",
      "0.22791795016\n",
      "AUC Score:\n",
      "0.970694025781\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_mi,X_test_MI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen by random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_RForest=['active_days','is_auto_renew','avg_actual_amount_paid','total_cancel','number_of_days_201702_listened','avg_plan_list_price','most_fq_payment_method_id','num_totalsec_min','number_of_days_listened','bd','num_25_max','num_25_201702_sum','num_unq_max','num_25_201612_mean','num_totalsec_max','proportion_songs_above_50','num_75_mean','num_unq_201702_sum','num_25_201702_mean','num_50_201702_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_Rf = df[top_RForest]\n",
    "X_test_Rf = df_test[top_RForest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 8s 114us/step - loss: 0.2332 - acc: 0.9155\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 8s 110us/step - loss: 0.2129 - acc: 0.9234\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 8s 111us/step - loss: 0.2077 - acc: 0.9258\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 8s 114us/step - loss: 0.2040 - acc: 0.9267\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 8s 109us/step - loss: 0.2008 - acc: 0.9280\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1991 - acc: 0.9277\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1974 - acc: 0.9286\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1961 - acc: 0.9291\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1951 - acc: 0.9293\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 7s 95us/step - loss: 0.1943 - acc: 0.9293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c6022b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest=baseline_model(20)\n",
    "model_forest.fit(X_train_Rf, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0220573 24977\n",
      "    1  967 16326\n",
      "\n",
      "Accuracy Score:\n",
      "0.901294689225\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.94    245550\n",
      "          1       0.40      0.94      0.56     17293\n",
      "\n",
      "avg / total       0.96      0.90      0.92    262843\n",
      "\n",
      "Log Loss:\n",
      "0.211072022553\n",
      "AUC Score:\n",
      "0.970223929624\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_forest,X_test_Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features without correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_no_corr=['number_of_days_201702_listened','is_auto_renew','total_cancel','active_days','avg_actual_amount_paid','most_fq_payment_method_id','num_75_mean','number_of_days_listened','num_25_201702_sum','num_50_201702_sum','num_100_201702_sum','num_25_201702_mean','num_50_201702_mean','num_totalsec_lasttwo_mean','total_churn','registered_via_3','registered_via_4','registered_via_7','bd','num_totalsec_sum','num_100_med','num_25_max','num_unq_max','num_totalsec_max','num_totalsec_min','num_985_201702_sum','num_75_201702_mean','num_unq_201702_mean','num_unq_201701_sum','num_25_201612_mean','num_100_201612_mean','num_75_lasttwo_mean','num_50_lastthree_mean','proportion_songs_above_50','registered_via_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_no_corr = df[top_no_corr]\n",
    "X_test_no_corr = df_test[top_no_corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70598/70598 [==============================] - 7s 106us/step - loss: 0.2339 - acc: 0.9151\n",
      "Epoch 2/10\n",
      "70598/70598 [==============================] - 7s 97us/step - loss: 0.2098 - acc: 0.9241\n",
      "Epoch 3/10\n",
      "70598/70598 [==============================] - 7s 97us/step - loss: 0.2053 - acc: 0.9258\n",
      "Epoch 4/10\n",
      "70598/70598 [==============================] - 7s 99us/step - loss: 0.2028 - acc: 0.9265\n",
      "Epoch 5/10\n",
      "70598/70598 [==============================] - 9s 127us/step - loss: 0.2002 - acc: 0.9273\n",
      "Epoch 6/10\n",
      "70598/70598 [==============================] - 9s 125us/step - loss: 0.1989 - acc: 0.9276\n",
      "Epoch 7/10\n",
      "70598/70598 [==============================] - 9s 125us/step - loss: 0.1976 - acc: 0.9277\n",
      "Epoch 8/10\n",
      "70598/70598 [==============================] - 8s 117us/step - loss: 0.1952 - acc: 0.9284\n",
      "Epoch 9/10\n",
      "70598/70598 [==============================] - 8s 106us/step - loss: 0.1934 - acc: 0.9286\n",
      "Epoch 10/10\n",
      "70598/70598 [==============================] - 8s 107us/step - loss: 0.1918 - acc: 0.9289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2cead208>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_decorr=baseline_model(35)\n",
    "model_decorr.fit(X_train_no_corr, y_train,epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0222521 23029\n",
      "    1 1222 16071\n",
      "\n",
      "Accuracy Score:\n",
      "0.907735796654\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95    245550\n",
      "          1       0.41      0.93      0.57     17293\n",
      "\n",
      "avg / total       0.96      0.91      0.92    262843\n",
      "\n",
      "Log Loss:\n",
      "0.205458826098\n",
      "AUC Score:\n",
      "0.969268311514\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_decorr,X_test_no_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics\n",
    "\n",
    "- All features\n",
    "Log Loss:\n",
    "0.225461077679\n",
    "AUC Score:\n",
    "0.96204957219\n",
    "F1-1/F1-avg: 0.55/0.92\n",
    "\n",
    "- Top 59\n",
    "Log Loss:\n",
    "0.251584923852\n",
    "AUC Score:\n",
    "0.968598060806\n",
    "F1-1/F1-avg: 0.54/0.92\n",
    "\n",
    "- RFE\t\n",
    "Log Loss:\n",
    "0.214808279573\n",
    "AUC Score:\n",
    "0.970122542678\n",
    "F1-1/F1-avg: 0.56/0.92\n",
    "- PCA\n",
    "Log Loss:\n",
    "0.214808279573\n",
    "AUC Score:\n",
    "0.970122542678\n",
    "F1-1/F1-avg: 0.56/0.92\n",
    "- F-classification\n",
    "Log Loss:\n",
    "0.210309633582\n",
    "AUC Score:\n",
    "0.969964711246\n",
    "F1-1/F1-avg: 0.55/0.92\n",
    "- Mutual Info\t\n",
    "Log Loss:\n",
    "0.22791795016\n",
    "AUC Score:\n",
    "0.970694025781\n",
    "F1-1/F1-avg: 0.55/0.92\n",
    "- Random Forrest\t\n",
    "Log Loss:\n",
    "0.211072022553\n",
    "AUC Score:\n",
    "0.970223929624\n",
    "F1-1/F1-avg: 0.56/0.92\n",
    "- Without correlation\t\n",
    "Log Loss:\n",
    "0.205458826098\n",
    "AUC Score:\n",
    "0.969268311514\n",
    "F1-1/F1-avg: 0.57/0.92\n",
    "\n",
    ">Features after the correlation removal performed best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values_no_corr=model_decorr.predict_proba(X_test_no_corr)\n",
    "values_df=pd.DataFrame(values_no_corr)\n",
    "values_df.to_csv('predict_proba_ANN_decorr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling 0.1 from train for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sample= df.sample(frac=0.1, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sample=X_sample['is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7060, 157)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3484"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bd</th>\n",
       "      <th>num_25_sum</th>\n",
       "      <th>num_50_sum</th>\n",
       "      <th>num_75_sum</th>\n",
       "      <th>num_985_sum</th>\n",
       "      <th>num_100_sum</th>\n",
       "      <th>num_unq_sum</th>\n",
       "      <th>num_totalsec_sum</th>\n",
       "      <th>num_25_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>registered_via_3</th>\n",
       "      <th>registered_via_4</th>\n",
       "      <th>registered_via_7</th>\n",
       "      <th>registered_via_9</th>\n",
       "      <th>registered_via_13</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>msno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16349</th>\n",
       "      <td>16349</td>\n",
       "      <td>-0.811134</td>\n",
       "      <td>-0.455947</td>\n",
       "      <td>-0.685689</td>\n",
       "      <td>-0.502068</td>\n",
       "      <td>-0.445134</td>\n",
       "      <td>0.349455</td>\n",
       "      <td>0.485696</td>\n",
       "      <td>0.242797</td>\n",
       "      <td>-0.583489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508672</td>\n",
       "      <td>-0.541352</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>-0.357804</td>\n",
       "      <td>-0.232910</td>\n",
       "      <td>0.863924</td>\n",
       "      <td>-0.591173</td>\n",
       "      <td>-0.05888</td>\n",
       "      <td>0</td>\n",
       "      <td>5R8fn3LSz6IAAWr8i+10VpQUGWRMvslhSMQgG+Bytcc=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49358</th>\n",
       "      <td>49358</td>\n",
       "      <td>0.754708</td>\n",
       "      <td>-0.708717</td>\n",
       "      <td>-0.785512</td>\n",
       "      <td>-0.841180</td>\n",
       "      <td>-0.741389</td>\n",
       "      <td>-0.806527</td>\n",
       "      <td>-0.857370</td>\n",
       "      <td>-0.832914</td>\n",
       "      <td>-0.303228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508672</td>\n",
       "      <td>1.847228</td>\n",
       "      <td>-1.146185</td>\n",
       "      <td>-0.357804</td>\n",
       "      <td>4.293498</td>\n",
       "      <td>-1.157510</td>\n",
       "      <td>-0.591173</td>\n",
       "      <td>-0.05888</td>\n",
       "      <td>1</td>\n",
       "      <td>sZPVw0KE1FOsLkzG9nSL4InvKt3gvW+GosLlZd2TY1c=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50335</th>\n",
       "      <td>50335</td>\n",
       "      <td>0.629440</td>\n",
       "      <td>-0.818794</td>\n",
       "      <td>-0.839962</td>\n",
       "      <td>-0.900157</td>\n",
       "      <td>-0.705838</td>\n",
       "      <td>-0.852786</td>\n",
       "      <td>-0.937954</td>\n",
       "      <td>-0.881860</td>\n",
       "      <td>-0.719427</td>\n",
       "      <td>...</td>\n",
       "      <td>1.965905</td>\n",
       "      <td>-0.541352</td>\n",
       "      <td>-1.146185</td>\n",
       "      <td>2.794825</td>\n",
       "      <td>-0.232910</td>\n",
       "      <td>-1.157510</td>\n",
       "      <td>-0.591173</td>\n",
       "      <td>-0.05888</td>\n",
       "      <td>1</td>\n",
       "      <td>z0UMCpBGL2FDu0PPbNbD02j6SvTDlXoRpPqzQmpPvF8=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36982</th>\n",
       "      <td>36982</td>\n",
       "      <td>-0.811134</td>\n",
       "      <td>-0.831025</td>\n",
       "      <td>-0.903486</td>\n",
       "      <td>-0.944389</td>\n",
       "      <td>-0.836190</td>\n",
       "      <td>-0.902490</td>\n",
       "      <td>-0.992213</td>\n",
       "      <td>-0.935144</td>\n",
       "      <td>-0.719427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508672</td>\n",
       "      <td>-0.541352</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>-0.357804</td>\n",
       "      <td>-0.232910</td>\n",
       "      <td>0.863924</td>\n",
       "      <td>-0.591173</td>\n",
       "      <td>-0.05888</td>\n",
       "      <td>1</td>\n",
       "      <td>dqPvRDeeXpl6oAdo1H64dqe0SxDVkQeAw56uV3Z1/oI=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39963</th>\n",
       "      <td>39963</td>\n",
       "      <td>1.381044</td>\n",
       "      <td>-0.486524</td>\n",
       "      <td>-0.422517</td>\n",
       "      <td>-0.502068</td>\n",
       "      <td>-0.243680</td>\n",
       "      <td>-0.170712</td>\n",
       "      <td>-0.221831</td>\n",
       "      <td>-0.210368</td>\n",
       "      <td>-0.488205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508672</td>\n",
       "      <td>1.847228</td>\n",
       "      <td>-1.146185</td>\n",
       "      <td>-0.357804</td>\n",
       "      <td>-0.232910</td>\n",
       "      <td>-1.157510</td>\n",
       "      <td>1.691552</td>\n",
       "      <td>-0.05888</td>\n",
       "      <td>1</td>\n",
       "      <td>eJswEvGKsJqPKc+o6eAUB2GY9C2W5Jj+Zl70XUXf+no=</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        bd  num_25_sum  num_50_sum  num_75_sum  num_985_sum  \\\n",
       "16349       16349 -0.811134   -0.455947   -0.685689   -0.502068    -0.445134   \n",
       "49358       49358  0.754708   -0.708717   -0.785512   -0.841180    -0.741389   \n",
       "50335       50335  0.629440   -0.818794   -0.839962   -0.900157    -0.705838   \n",
       "36982       36982 -0.811134   -0.831025   -0.903486   -0.944389    -0.836190   \n",
       "39963       39963  1.381044   -0.486524   -0.422517   -0.502068    -0.243680   \n",
       "\n",
       "       num_100_sum  num_unq_sum  num_totalsec_sum  num_25_mean  \\\n",
       "16349     0.349455     0.485696          0.242797    -0.583489   \n",
       "49358    -0.806527    -0.857370         -0.832914    -0.303228   \n",
       "50335    -0.852786    -0.937954         -0.881860    -0.719427   \n",
       "36982    -0.902490    -0.992213         -0.935144    -0.719427   \n",
       "39963    -0.170712    -0.221831         -0.210368    -0.488205   \n",
       "\n",
       "                           ...                       gender_0  gender_1  \\\n",
       "16349                      ...                      -0.508672 -0.541352   \n",
       "49358                      ...                      -0.508672  1.847228   \n",
       "50335                      ...                       1.965905 -0.541352   \n",
       "36982                      ...                      -0.508672 -0.541352   \n",
       "39963                      ...                      -0.508672  1.847228   \n",
       "\n",
       "       gender_2  registered_via_3  registered_via_4  registered_via_7  \\\n",
       "16349  0.872460         -0.357804         -0.232910          0.863924   \n",
       "49358 -1.146185         -0.357804          4.293498         -1.157510   \n",
       "50335 -1.146185          2.794825         -0.232910         -1.157510   \n",
       "36982  0.872460         -0.357804         -0.232910          0.863924   \n",
       "39963 -1.146185         -0.357804         -0.232910         -1.157510   \n",
       "\n",
       "       registered_via_9  registered_via_13  is_churn  \\\n",
       "16349         -0.591173           -0.05888         0   \n",
       "49358         -0.591173           -0.05888         1   \n",
       "50335         -0.591173           -0.05888         1   \n",
       "36982         -0.591173           -0.05888         1   \n",
       "39963          1.691552           -0.05888         1   \n",
       "\n",
       "                                               msno  \n",
       "16349  5R8fn3LSz6IAAWr8i+10VpQUGWRMvslhSMQgG+Bytcc=  \n",
       "49358  sZPVw0KE1FOsLkzG9nSL4InvKt3gvW+GosLlZd2TY1c=  \n",
       "50335  z0UMCpBGL2FDu0PPbNbD02j6SvTDlXoRpPqzQmpPvF8=  \n",
       "36982  dqPvRDeeXpl6oAdo1H64dqe0SxDVkQeAw56uV3Z1/oI=  \n",
       "39963  eJswEvGKsJqPKc+o6eAUB2GY9C2W5Jj+Zl70XUXf+no=  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X_sample[['number_of_days_201702_listened','is_auto_renew','total_cancel','active_days','avg_actual_amount_paid','most_fq_payment_method_id','num_75_mean','number_of_days_listened','num_25_201702_sum','num_50_201702_sum','num_100_201702_sum','num_25_201702_mean','num_50_201702_mean','num_totalsec_lasttwo_mean','total_churn','registered_via_3','registered_via_4','registered_via_7','bd','num_totalsec_sum','num_100_med','num_25_max','num_unq_max','num_totalsec_max','num_totalsec_min','num_985_201702_sum','num_75_201702_mean','num_unq_201702_mean','num_unq_201701_sum','num_25_201612_mean','num_100_201612_mean','num_75_lasttwo_mean','num_50_lastthree_mean','proportion_songs_above_50','registered_via_9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=X_sample['is_churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning optimal number of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model_nurons(neurons):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=35, kernel_initializer='normal', activation='relu'))\n",
    "    #if we want a hidden layer :\n",
    "    #model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 1s 263us/step - loss: 0.6711 - acc: 0.6509\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.5824 - acc: 0.7524\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 114us/step - loss: 0.5210 - acc: 0.7726\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 123us/step - loss: 0.4880 - acc: 0.7888\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.4635 - acc: 0.8032\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 119us/step - loss: 0.4271 - acc: 0.8387\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.3669 - acc: 0.8908\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.3279 - acc: 0.9052\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 129us/step - loss: 0.3042 - acc: 0.9120\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 122us/step - loss: 0.2887 - acc: 0.9159\n",
      "2354/2354 [==============================] - 0s 143us/step\n",
      "4706/4706 [==============================] - 0s 69us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 381us/step - loss: 0.6478 - acc: 0.6643\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.5237 - acc: 0.8262\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.4493 - acc: 0.8681\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.4013 - acc: 0.8846\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.3685 - acc: 0.8902\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.3445 - acc: 0.8965\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 106us/step - loss: 0.3269 - acc: 0.8976\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.3129 - acc: 0.9018\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.3028 - acc: 0.9035\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2945 - acc: 0.9038\n",
      "2353/2353 [==============================] - 0s 149us/step\n",
      "4707/4707 [==============================] - 0s 57us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 1s 264us/step - loss: 0.6765 - acc: 0.5462\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.6213 - acc: 0.7185\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.5537 - acc: 0.7950\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.4703 - acc: 0.8693\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.4005 - acc: 0.8950\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.3566 - acc: 0.9029\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.3244 - acc: 0.9076\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 106us/step - loss: 0.3029 - acc: 0.9131\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2902 - acc: 0.9148\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2812 - acc: 0.9161\n",
      "2353/2353 [==============================] - 0s 148us/step\n",
      "4707/4707 [==============================] - 0s 58us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 1s 272us/step - loss: 0.5665 - acc: 0.8107\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.3396 - acc: 0.8946\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 108us/step - loss: 0.2659 - acc: 0.9084\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 108us/step - loss: 0.2450 - acc: 0.9110\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.2372 - acc: 0.9127\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 107us/step - loss: 0.2331 - acc: 0.9150\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 108us/step - loss: 0.2300 - acc: 0.9159\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.2284 - acc: 0.9152\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.2269 - acc: 0.9159\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 146us/step - loss: 0.2251 - acc: 0.9178\n",
      "2354/2354 [==============================] - 1s 220us/step\n",
      "4706/4706 [==============================] - 0s 62us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 1s 272us/step - loss: 0.5753 - acc: 0.8133\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.3501 - acc: 0.8849\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2850 - acc: 0.8967\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 122us/step - loss: 0.2647 - acc: 0.9027\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.2548 - acc: 0.9074\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 132us/step - loss: 0.2484 - acc: 0.9084\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 140us/step - loss: 0.2443 - acc: 0.9093\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 155us/step - loss: 0.2404 - acc: 0.9127\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 307us/step - loss: 0.2373 - acc: 0.9135\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 257us/step - loss: 0.2346 - acc: 0.9140\n",
      "2353/2353 [==============================] - 1s 238us/step\n",
      "4707/4707 [==============================] - 0s 75us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 437us/step - loss: 0.5676 - acc: 0.7778\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.3509 - acc: 0.8844\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.2802 - acc: 0.9012\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 138us/step - loss: 0.2560 - acc: 0.9042\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 125us/step - loss: 0.2452 - acc: 0.9110\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 128us/step - loss: 0.2392 - acc: 0.9118\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2349 - acc: 0.9125\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 183us/step - loss: 0.2319 - acc: 0.9137\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 124us/step - loss: 0.2300 - acc: 0.9152\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 116us/step - loss: 0.2282 - acc: 0.9174\n",
      "2353/2353 [==============================] - 0s 177us/step\n",
      "4707/4707 [==============================] - 0s 58us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 1s 293us/step - loss: 0.5189 - acc: 0.8092\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2895 - acc: 0.8993\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 114us/step - loss: 0.2496 - acc: 0.9118\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 112us/step - loss: 0.2370 - acc: 0.9154\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2308 - acc: 0.9180\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2273 - acc: 0.9214\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2242 - acc: 0.9197\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 108us/step - loss: 0.2213 - acc: 0.9214\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2182 - acc: 0.9207\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2174 - acc: 0.9216\n",
      "2354/2354 [==============================] - 0s 189us/step\n",
      "4706/4706 [==============================] - 0s 58us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 320us/step - loss: 0.5426 - acc: 0.8022\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.3034 - acc: 0.8929\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2614 - acc: 0.9065\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2514 - acc: 0.9108\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.2455 - acc: 0.9125\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.2408 - acc: 0.9142\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2382 - acc: 0.9144\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2350 - acc: 0.9152\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.2327 - acc: 0.9148\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 170us/step - loss: 0.2305 - acc: 0.9142\n",
      "2353/2353 [==============================] - 0s 190us/step\n",
      "4707/4707 [==============================] - 0s 60us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 358us/step - loss: 0.5322 - acc: 0.7884\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.3076 - acc: 0.8991\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.2577 - acc: 0.9097\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2433 - acc: 0.9129\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.2366 - acc: 0.9137\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2321 - acc: 0.9165\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.2295 - acc: 0.9144\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.2272 - acc: 0.9178\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.2250 - acc: 0.9188\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2239 - acc: 0.9186\n",
      "2353/2353 [==============================] - 0s 172us/step\n",
      "4707/4707 [==============================] - 0s 50us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 343us/step - loss: 0.4942 - acc: 0.8236\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 137us/step - loss: 0.2829 - acc: 0.9063\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.2436 - acc: 0.9118\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2313 - acc: 0.9180\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 133us/step - loss: 0.2255 - acc: 0.9199\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 126us/step - loss: 0.2226 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.2193 - acc: 0.9218\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 134us/step - loss: 0.2171 - acc: 0.9207\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 117us/step - loss: 0.2147 - acc: 0.9205\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 128us/step - loss: 0.2140 - acc: 0.9216\n",
      "2354/2354 [==============================] - 0s 187us/step\n",
      "4706/4706 [==============================] - 0s 73us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 399us/step - loss: 0.5096 - acc: 0.8088\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 130us/step - loss: 0.3029 - acc: 0.8934\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2621 - acc: 0.9059\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2498 - acc: 0.9089\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2432 - acc: 0.9099\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2387 - acc: 0.9116\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2357 - acc: 0.9103\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.2335 - acc: 0.9159\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.2306 - acc: 0.9148\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.2285 - acc: 0.9154\n",
      "2353/2353 [==============================] - 0s 185us/step\n",
      "4707/4707 [==============================] - 0s 62us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 368us/step - loss: 0.4964 - acc: 0.8039\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2797 - acc: 0.9040\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2440 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2338 - acc: 0.9148\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2283 - acc: 0.9167\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2250 - acc: 0.9195\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2232 - acc: 0.9199\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2206 - acc: 0.9197\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2189 - acc: 0.9216\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2173 - acc: 0.9205\n",
      "2353/2353 [==============================] - 0s 193us/step\n",
      "4707/4707 [==============================] - 0s 63us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 1s 316us/step - loss: 0.4520 - acc: 0.8434\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 115us/step - loss: 0.2542 - acc: 0.9103\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2346 - acc: 0.9156\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 114us/step - loss: 0.2262 - acc: 0.9173\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 117us/step - loss: 0.2225 - acc: 0.9207\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 115us/step - loss: 0.2193 - acc: 0.9216\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 115us/step - loss: 0.2163 - acc: 0.9229\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 115us/step - loss: 0.2143 - acc: 0.9220\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2121 - acc: 0.9233\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2102 - acc: 0.9254\n",
      "2354/2354 [==============================] - 0s 198us/step\n",
      "4706/4706 [==============================] - 0s 77us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 369us/step - loss: 0.4915 - acc: 0.8118\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2894 - acc: 0.9014\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 129us/step - loss: 0.2561 - acc: 0.9097\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.2450 - acc: 0.9110\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2386 - acc: 0.9140\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 135us/step - loss: 0.2356 - acc: 0.9148\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 155us/step - loss: 0.2318 - acc: 0.9157\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 148us/step - loss: 0.2286 - acc: 0.9176\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 151us/step - loss: 0.2256 - acc: 0.9174\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 153us/step - loss: 0.2242 - acc: 0.9188\n",
      "2353/2353 [==============================] - 1s 253us/step\n",
      "4707/4707 [==============================] - 0s 86us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 465us/step - loss: 0.4807 - acc: 0.8103\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 131us/step - loss: 0.2672 - acc: 0.9086\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 123us/step - loss: 0.2404 - acc: 0.9099\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2320 - acc: 0.9129\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2268 - acc: 0.9171\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.2245 - acc: 0.9154\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 124us/step - loss: 0.2226 - acc: 0.9169\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 116us/step - loss: 0.2202 - acc: 0.9171\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 1s 123us/step - loss: 0.2177 - acc: 0.9216\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2161 - acc: 0.9218\n",
      "2353/2353 [==============================] - 1s 225us/step\n",
      "4707/4707 [==============================] - 0s 72us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 346us/step - loss: 0.4528 - acc: 0.8381\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2603 - acc: 0.9101\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2340 - acc: 0.9197\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 125us/step - loss: 0.2259 - acc: 0.9222\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2206 - acc: 0.9216\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 116us/step - loss: 0.2172 - acc: 0.9235\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2142 - acc: 0.9222\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 114us/step - loss: 0.2119 - acc: 0.9237\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 112us/step - loss: 0.2091 - acc: 0.9244\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2069 - acc: 0.9271\n",
      "2354/2354 [==============================] - 1s 222us/step\n",
      "4706/4706 [==============================] - 0s 63us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 380us/step - loss: 0.4614 - acc: 0.8288\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.2746 - acc: 0.9012\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.2505 - acc: 0.9106\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2407 - acc: 0.9135\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.2356 - acc: 0.9148\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2319 - acc: 0.9169\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2285 - acc: 0.9176\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2262 - acc: 0.9208\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2238 - acc: 0.9199\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2212 - acc: 0.9220\n",
      "2353/2353 [==============================] - 0s 209us/step\n",
      "4707/4707 [==============================] - 0s 54us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 327us/step - loss: 0.4623 - acc: 0.8283\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2617 - acc: 0.9082\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2385 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2307 - acc: 0.9186\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2268 - acc: 0.9169\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2229 - acc: 0.9186\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2199 - acc: 0.9180\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2181 - acc: 0.9218\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2155 - acc: 0.9222\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2147 - acc: 0.9212\n",
      "2353/2353 [==============================] - 0s 208us/step\n",
      "4707/4707 [==============================] - 0s 58us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 334us/step - loss: 0.4430 - acc: 0.8321\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2512 - acc: 0.9097\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2300 - acc: 0.9165\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 0s 104us/step - loss: 0.2230 - acc: 0.9197\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2184 - acc: 0.9203\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2148 - acc: 0.9227\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2122 - acc: 0.9227\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 0s 104us/step - loss: 0.2093 - acc: 0.9250\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 0s 104us/step - loss: 0.2067 - acc: 0.9258\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2046 - acc: 0.9252\n",
      "2354/2354 [==============================] - 1s 215us/step\n",
      "4706/4706 [==============================] - 0s 57us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 358us/step - loss: 0.4577 - acc: 0.8300\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2715 - acc: 0.9021\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2482 - acc: 0.9082\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2399 - acc: 0.9116\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2346 - acc: 0.9133\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2304 - acc: 0.9165\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2270 - acc: 0.9180\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2235 - acc: 0.9188\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2211 - acc: 0.9197\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 127us/step - loss: 0.2185 - acc: 0.9233\n",
      "2353/2353 [==============================] - 1s 280us/step\n",
      "4707/4707 [==============================] - 0s 60us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 357us/step - loss: 0.4413 - acc: 0.8526\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2619 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.2395 - acc: 0.9114\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2315 - acc: 0.9163\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2264 - acc: 0.9176\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.2230 - acc: 0.9191\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 168us/step - loss: 0.2202 - acc: 0.9201\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 182us/step - loss: 0.2174 - acc: 0.9218\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 136us/step - loss: 0.2157 - acc: 0.9210\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2130 - acc: 0.9227\n",
      "2353/2353 [==============================] - 1s 242us/step\n",
      "4707/4707 [==============================] - 0s 63us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 369us/step - loss: 0.4192 - acc: 0.8370\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.2449 - acc: 0.9144\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.2284 - acc: 0.9199\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2206 - acc: 0.9229\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2163 - acc: 0.9233\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.2130 - acc: 0.9239\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.2106 - acc: 0.9220\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 127us/step - loss: 0.2070 - acc: 0.9256\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 137us/step - loss: 0.2038 - acc: 0.9265\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 120us/step - loss: 0.2005 - acc: 0.9282\n",
      "2354/2354 [==============================] - 1s 289us/step\n",
      "4706/4706 [==============================] - 0s 62us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 374us/step - loss: 0.4188 - acc: 0.8460\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.2582 - acc: 0.9067\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2418 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2340 - acc: 0.9161\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2286 - acc: 0.9144\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2239 - acc: 0.9176\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 130us/step - loss: 0.2195 - acc: 0.9222\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 146us/step - loss: 0.2173 - acc: 0.9218\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2133 - acc: 0.9222\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2103 - acc: 0.9267\n",
      "2353/2353 [==============================] - 1s 247us/step\n",
      "4707/4707 [==============================] - 0s 65us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 386us/step - loss: 0.4148 - acc: 0.8373\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 116us/step - loss: 0.2480 - acc: 0.9101\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2327 - acc: 0.9167\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2251 - acc: 0.9176\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 134us/step - loss: 0.2211 - acc: 0.9208\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 145us/step - loss: 0.2172 - acc: 0.9203\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 131us/step - loss: 0.2133 - acc: 0.9203\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 140us/step - loss: 0.2102 - acc: 0.9225\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 121us/step - loss: 0.2084 - acc: 0.9231\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 134us/step - loss: 0.2056 - acc: 0.9237\n",
      "2353/2353 [==============================] - 1s 243us/step\n",
      "4707/4707 [==============================] - 0s 70us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 398us/step - loss: 0.3603 - acc: 0.8757\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 131us/step - loss: 0.2326 - acc: 0.9152\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 137us/step - loss: 0.2213 - acc: 0.9214\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 117us/step - loss: 0.2149 - acc: 0.9207\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 138us/step - loss: 0.2099 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 162us/step - loss: 0.2054 - acc: 0.9256\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 147us/step - loss: 0.2003 - acc: 0.9269\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 198us/step - loss: 0.1971 - acc: 0.9299\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 193us/step - loss: 0.1922 - acc: 0.9299\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 142us/step - loss: 0.1900 - acc: 0.9314\n",
      "2354/2354 [==============================] - 1s 332us/step\n",
      "4706/4706 [==============================] - 0s 72us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 489us/step - loss: 0.3761 - acc: 0.8634\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2518 - acc: 0.9086\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 237us/step - loss: 0.2371 - acc: 0.9118\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 251us/step - loss: 0.2306 - acc: 0.9180\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 234us/step - loss: 0.2245 - acc: 0.9191\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 208us/step - loss: 0.2179 - acc: 0.9218\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 183us/step - loss: 0.2158 - acc: 0.9188\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 144us/step - loss: 0.2104 - acc: 0.9239\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 139us/step - loss: 0.2069 - acc: 0.9235\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 124us/step - loss: 0.2036 - acc: 0.9259\n",
      "2353/2353 [==============================] - 1s 269us/step\n",
      "4707/4707 [==============================] - 0s 63us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 420us/step - loss: 0.3650 - acc: 0.8617\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 130us/step - loss: 0.2389 - acc: 0.9129\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 187us/step - loss: 0.2286 - acc: 0.9146\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 146us/step - loss: 0.2236 - acc: 0.9201\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 222us/step - loss: 0.2167 - acc: 0.9188\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 188us/step - loss: 0.2140 - acc: 0.9220\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 179us/step - loss: 0.2091 - acc: 0.9237\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 136us/step - loss: 0.2064 - acc: 0.9254\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2029 - acc: 0.9265\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 182us/step - loss: 0.1998 - acc: 0.9259\n",
      "2353/2353 [==============================] - 1s 442us/step\n",
      "4707/4707 [==============================] - 1s 114us/step\n",
      "Epoch 1/10\n",
      "7060/7060 [==============================] - 3s 480us/step - loss: 0.3567 - acc: 0.8761\n",
      "Epoch 2/10\n",
      "7060/7060 [==============================] - 1s 117us/step - loss: 0.2384 - acc: 0.9146\n",
      "Epoch 3/10\n",
      "7060/7060 [==============================] - 1s 113us/step - loss: 0.2287 - acc: 0.9181\n",
      "Epoch 4/10\n",
      "7060/7060 [==============================] - 1s 114us/step - loss: 0.2242 - acc: 0.9193\n",
      "Epoch 5/10\n",
      "7060/7060 [==============================] - 1s 110us/step - loss: 0.2192 - acc: 0.9210\n",
      "Epoch 6/10\n",
      "7060/7060 [==============================] - 1s 112us/step - loss: 0.2149 - acc: 0.9228\n",
      "Epoch 7/10\n",
      "7060/7060 [==============================] - 1s 110us/step - loss: 0.2116 - acc: 0.9248\n",
      "Epoch 8/10\n",
      "7060/7060 [==============================] - 1s 109us/step - loss: 0.2094 - acc: 0.9251\n",
      "Epoch 9/10\n",
      "7060/7060 [==============================] - 1s 109us/step - loss: 0.2054 - acc: 0.9266\n",
      "Epoch 10/10\n",
      "7060/7060 [==============================] - 1s 108us/step - loss: 0.2041 - acc: 0.9269\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=new_model_nurons, epochs=10, batch_size=16, verbose=1)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30, 50, 90]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.915722 using {'neurons': 50}\n",
      "0.913598 (0.008167) with: {'neurons': 1}\n",
      "0.911756 (0.008153) with: {'neurons': 5}\n",
      "0.914589 (0.005568) with: {'neurons': 10}\n",
      "0.913739 (0.007296) with: {'neurons': 15}\n",
      "0.914306 (0.007792) with: {'neurons': 20}\n",
      "0.915156 (0.005858) with: {'neurons': 25}\n",
      "0.915297 (0.004127) with: {'neurons': 30}\n",
      "0.915722 (0.008514) with: {'neurons': 50}\n",
      "0.914164 (0.009006) with: {'neurons': 90}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning batch size and number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=35, kernel_initializer='normal', activation='relu'))\n",
    "    #if we want a hidden layer :\n",
    "    #model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 497us/step - loss: 0.3630 - acc: 0.8608\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 214us/step - loss: 0.2339 - acc: 0.9154\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 210us/step - loss: 0.2230 - acc: 0.9184\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 214us/step - loss: 0.2186 - acc: 0.9205\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 1s 200us/step - loss: 0.2135 - acc: 0.9231\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 1s 201us/step - loss: 0.2103 - acc: 0.9237\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 1s 202us/step - loss: 0.2069 - acc: 0.9261\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 1s 205us/step - loss: 0.2034 - acc: 0.9275\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 1s 226us/step - loss: 0.2008 - acc: 0.9258 0s - loss: 0.\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 1s 229us/step - loss: 0.1967 - acc: 0.9280\n",
      "2354/2354 [==============================] - 1s 372us/step\n",
      "4706/4706 [==============================] - 1s 130us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 501us/step - loss: 0.3767 - acc: 0.8579\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 204us/step - loss: 0.2502 - acc: 0.9069\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 204us/step - loss: 0.2380 - acc: 0.9118\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 277us/step - loss: 0.2321 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 1s 278us/step - loss: 0.2245 - acc: 0.9193\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 192us/step - loss: 0.2215 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 193us/step - loss: 0.2156 - acc: 0.9246\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 182us/step - loss: 0.2126 - acc: 0.9237\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 264us/step - loss: 0.2088 - acc: 0.9244\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 283us/step - loss: 0.2070 - acc: 0.9256\n",
      "2353/2353 [==============================] - 1s 353us/step\n",
      "4707/4707 [==============================] - 1s 122us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 3s 582us/step - loss: 0.3693 - acc: 0.8611\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 185us/step - loss: 0.2412 - acc: 0.9123\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 211us/step - loss: 0.2289 - acc: 0.9178\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 1s 247us/step - loss: 0.2244 - acc: 0.9169\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 2s 334us/step - loss: 0.2196 - acc: 0.9193\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 1s 248us/step - loss: 0.2162 - acc: 0.9225\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 1s 216us/step - loss: 0.2124 - acc: 0.9199\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 246us/step - loss: 0.2109 - acc: 0.9222\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 1s 304us/step - loss: 0.2070 - acc: 0.9252\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 2s 388us/step - loss: 0.2053 - acc: 0.9248\n",
      "2353/2353 [==============================] - 1s 582us/step\n",
      "4707/4707 [==============================] - 1s 277us/step\n",
      "Epoch 1/20\n",
      "4706/4706 [==============================] - 2s 505us/step - loss: 0.3654 - acc: 0.8672\n",
      "Epoch 2/20\n",
      "4706/4706 [==============================] - 1s 181us/step - loss: 0.2330 - acc: 0.9184\n",
      "Epoch 3/20\n",
      "4706/4706 [==============================] - 1s 180us/step - loss: 0.2225 - acc: 0.9212\n",
      "Epoch 4/20\n",
      "4706/4706 [==============================] - 1s 247us/step - loss: 0.2167 - acc: 0.9214\n",
      "Epoch 5/20\n",
      "4706/4706 [==============================] - 1s 212us/step - loss: 0.2116 - acc: 0.9241\n",
      "Epoch 6/20\n",
      "4706/4706 [==============================] - 1s 201us/step - loss: 0.2082 - acc: 0.9271\n",
      "Epoch 7/20\n",
      "4706/4706 [==============================] - 1s 184us/step - loss: 0.2042 - acc: 0.9250\n",
      "Epoch 8/20\n",
      "4706/4706 [==============================] - 1s 220us/step - loss: 0.2008 - acc: 0.9278\n",
      "Epoch 9/20\n",
      "4706/4706 [==============================] - 2s 351us/step - loss: 0.1974 - acc: 0.9292\n",
      "Epoch 10/20\n",
      "4706/4706 [==============================] - 1s 214us/step - loss: 0.1944 - acc: 0.9314\n",
      "Epoch 11/20\n",
      "4706/4706 [==============================] - 1s 251us/step - loss: 0.1912 - acc: 0.9312\n",
      "Epoch 12/20\n",
      "4706/4706 [==============================] - 1s 266us/step - loss: 0.1886 - acc: 0.9331\n",
      "Epoch 13/20\n",
      "4706/4706 [==============================] - 1s 181us/step - loss: 0.1854 - acc: 0.9333\n",
      "Epoch 14/20\n",
      "4706/4706 [==============================] - 1s 214us/step - loss: 0.1841 - acc: 0.9322\n",
      "Epoch 15/20\n",
      "4706/4706 [==============================] - 1s 305us/step - loss: 0.1809 - acc: 0.9350\n",
      "Epoch 16/20\n",
      "4706/4706 [==============================] - 2s 321us/step - loss: 0.1785 - acc: 0.9360\n",
      "Epoch 17/20\n",
      "4706/4706 [==============================] - 1s 265us/step - loss: 0.1771 - acc: 0.9343\n",
      "Epoch 18/20\n",
      "4706/4706 [==============================] - 1s 260us/step - loss: 0.1751 - acc: 0.9360\n",
      "Epoch 19/20\n",
      "4706/4706 [==============================] - 1s 255us/step - loss: 0.1734 - acc: 0.9384\n",
      "Epoch 20/20\n",
      "4706/4706 [==============================] - 1s 188us/step - loss: 0.1704 - acc: 0.9371\n",
      "2354/2354 [==============================] - 1s 317us/step\n",
      "4706/4706 [==============================] - 0s 98us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 3s 546us/step - loss: 0.3786 - acc: 0.8553\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 1s 295us/step - loss: 0.2507 - acc: 0.9086\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 1s 255us/step - loss: 0.2391 - acc: 0.9131\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 1s 225us/step - loss: 0.2312 - acc: 0.9159\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 1s 197us/step - loss: 0.2257 - acc: 0.9182\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 1s 229us/step - loss: 0.2216 - acc: 0.9210\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 1s 233us/step - loss: 0.2176 - acc: 0.9210\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 1s 194us/step - loss: 0.2141 - acc: 0.9239\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 1s 215us/step - loss: 0.2103 - acc: 0.9242\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 1s 218us/step - loss: 0.2074 - acc: 0.9254\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 1s 255us/step - loss: 0.2043 - acc: 0.9259\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 2s 353us/step - loss: 0.2010 - acc: 0.9267\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.1992 - acc: 0.9290\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 1s 181us/step - loss: 0.1964 - acc: 0.9299\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 1s 200us/step - loss: 0.1930 - acc: 0.9327\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 1s 215us/step - loss: 0.1911 - acc: 0.9299\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 1s 224us/step - loss: 0.1890 - acc: 0.9339 0s - loss: 0\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 2s 325us/step - loss: 0.1873 - acc: 0.9331\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 1s 259us/step - loss: 0.1845 - acc: 0.9324\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 1s 243us/step - loss: 0.1825 - acc: 0.9339\n",
      "2353/2353 [==============================] - 1s 374us/step\n",
      "4707/4707 [==============================] - 1s 137us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 2s 513us/step - loss: 0.3679 - acc: 0.8696\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 1s 233us/step - loss: 0.2407 - acc: 0.9133\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 1s 262us/step - loss: 0.2302 - acc: 0.9199\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 1s 212us/step - loss: 0.2257 - acc: 0.9188\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.2194 - acc: 0.9199\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 1s 241us/step - loss: 0.2172 - acc: 0.9195\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 1s 230us/step - loss: 0.2142 - acc: 0.9201\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 1s 223us/step - loss: 0.2109 - acc: 0.9220\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 1s 223us/step - loss: 0.2073 - acc: 0.9246\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.2052 - acc: 0.9256\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 1s 244us/step - loss: 0.2014 - acc: 0.9261\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.1989 - acc: 0.9286\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 1s 216us/step - loss: 0.1965 - acc: 0.9263\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 1s 231us/step - loss: 0.1939 - acc: 0.9305\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 1s 214us/step - loss: 0.1915 - acc: 0.9299\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 1s 227us/step - loss: 0.1901 - acc: 0.9299\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 1s 251us/step - loss: 0.1868 - acc: 0.9307\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 1s 205us/step - loss: 0.1849 - acc: 0.9310\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 1s 273us/step - loss: 0.1841 - acc: 0.9305\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 1s 224us/step - loss: 0.1815 - acc: 0.9341\n",
      "2353/2353 [==============================] - 1s 449us/step\n",
      "4707/4707 [==============================] - 1s 128us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 2s 520us/step - loss: 0.3645 - acc: 0.8680\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 1s 187us/step - loss: 0.2351 - acc: 0.9159\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 1s 186us/step - loss: 0.2239 - acc: 0.9193\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 1s 186us/step - loss: 0.2174 - acc: 0.9231\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 1s 187us/step - loss: 0.2125 - acc: 0.9246\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 1s 185us/step - loss: 0.2080 - acc: 0.9248\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 1s 186us/step - loss: 0.2060 - acc: 0.9265\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 1s 186us/step - loss: 0.2022 - acc: 0.9275\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 1s 199us/step - loss: 0.1992 - acc: 0.9271\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 1s 270us/step - loss: 0.1954 - acc: 0.9303\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 1s 231us/step - loss: 0.1928 - acc: 0.9295\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 1s 195us/step - loss: 0.1910 - acc: 0.9309\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 1s 215us/step - loss: 0.1886 - acc: 0.9333\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 1s 210us/step - loss: 0.1851 - acc: 0.9331\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 1s 187us/step - loss: 0.1838 - acc: 0.9343\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 1s 235us/step - loss: 0.1815 - acc: 0.9352\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 1s 241us/step - loss: 0.1789 - acc: 0.9356\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 1s 210us/step - loss: 0.1761 - acc: 0.9369\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 1s 212us/step - loss: 0.1743 - acc: 0.9356\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 1s 228us/step - loss: 0.1732 - acc: 0.9369\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 1s 256us/step - loss: 0.1720 - acc: 0.9403\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 1s 208us/step - loss: 0.1694 - acc: 0.9375\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 1s 181us/step - loss: 0.1682 - acc: 0.9394\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 1s 180us/step - loss: 0.1674 - acc: 0.9397\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 1s 184us/step - loss: 0.1650 - acc: 0.9392\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 1s 180us/step - loss: 0.1629 - acc: 0.9411\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 1s 183us/step - loss: 0.1618 - acc: 0.9418\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 1s 180us/step - loss: 0.1610 - acc: 0.9409\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 1s 180us/step - loss: 0.1592 - acc: 0.9416\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 1s 182us/step - loss: 0.1567 - acc: 0.9450\n",
      "2354/2354 [==============================] - 1s 322us/step\n",
      "4706/4706 [==============================] - 0s 103us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 712us/step - loss: 0.3736 - acc: 0.8719\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 1s 304us/step - loss: 0.2498 - acc: 0.9129\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 1s 246us/step - loss: 0.2380 - acc: 0.9140\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 1s 223us/step - loss: 0.2326 - acc: 0.9144\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 1s 283us/step - loss: 0.2263 - acc: 0.9169\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 1s 233us/step - loss: 0.2224 - acc: 0.9203\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 1s 198us/step - loss: 0.2182 - acc: 0.9210\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 1s 189us/step - loss: 0.2157 - acc: 0.9208\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 1s 187us/step - loss: 0.2117 - acc: 0.9222\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 1s 187us/step - loss: 0.2077 - acc: 0.9246\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 1s 186us/step - loss: 0.2050 - acc: 0.9259\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 1s 188us/step - loss: 0.2009 - acc: 0.9263\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 1s 189us/step - loss: 0.1990 - acc: 0.9278\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 1s 215us/step - loss: 0.1957 - acc: 0.9305\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 1s 250us/step - loss: 0.1948 - acc: 0.9269\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 1s 294us/step - loss: 0.1920 - acc: 0.9288\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 1s 246us/step - loss: 0.1885 - acc: 0.9314\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 1s 267us/step - loss: 0.1872 - acc: 0.9312\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 1s 223us/step - loss: 0.1862 - acc: 0.9339\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.1833 - acc: 0.9324\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 1s 296us/step - loss: 0.1815 - acc: 0.9344\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 1s 198us/step - loss: 0.1801 - acc: 0.9346\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 1s 191us/step - loss: 0.1782 - acc: 0.9365\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 1s 192us/step - loss: 0.1771 - acc: 0.9344\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 1s 189us/step - loss: 0.1741 - acc: 0.9386\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 1s 198us/step - loss: 0.1747 - acc: 0.9373\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 1s 195us/step - loss: 0.1713 - acc: 0.9382\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 1s 204us/step - loss: 0.1710 - acc: 0.9395\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 1s 222us/step - loss: 0.1686 - acc: 0.9388\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 1s 210us/step - loss: 0.1664 - acc: 0.9395\n",
      "2353/2353 [==============================] - 1s 356us/step\n",
      "4707/4707 [==============================] - 1s 127us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 702us/step - loss: 0.3757 - acc: 0.8557\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 2s 325us/step - loss: 0.2395 - acc: 0.9142\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 1s 287us/step - loss: 0.2300 - acc: 0.9148\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 1s 226us/step - loss: 0.2241 - acc: 0.9167\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 1s 265us/step - loss: 0.2196 - acc: 0.9195\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 1s 240us/step - loss: 0.2157 - acc: 0.9188\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 1s 272us/step - loss: 0.2126 - acc: 0.9205\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 1s 237us/step - loss: 0.2094 - acc: 0.9229\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 1s 306us/step - loss: 0.2074 - acc: 0.9252\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 1s 266us/step - loss: 0.2031 - acc: 0.9273\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 1s 247us/step - loss: 0.1999 - acc: 0.9290\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 1s 229us/step - loss: 0.1974 - acc: 0.9265\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 1s 278us/step - loss: 0.1950 - acc: 0.9293\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 1s 231us/step - loss: 0.1923 - acc: 0.9295\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 1s 299us/step - loss: 0.1915 - acc: 0.9297\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 2s 325us/step - loss: 0.1884 - acc: 0.9299\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 1s 250us/step - loss: 0.1866 - acc: 0.9303\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 1s 229us/step - loss: 0.1847 - acc: 0.9324\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 1s 288us/step - loss: 0.1823 - acc: 0.9322\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 1s 210us/step - loss: 0.1799 - acc: 0.9363\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 1s 215us/step - loss: 0.1788 - acc: 0.9346\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 1s 191us/step - loss: 0.1777 - acc: 0.9361\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 1s 182us/step - loss: 0.1772 - acc: 0.9358\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 1s 258us/step - loss: 0.1746 - acc: 0.9369\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 1s 268us/step - loss: 0.1720 - acc: 0.9386\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 1s 234us/step - loss: 0.1718 - acc: 0.9358\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 1s 188us/step - loss: 0.1688 - acc: 0.9380\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 1s 190us/step - loss: 0.1683 - acc: 0.9369\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 1s 273us/step - loss: 0.1664 - acc: 0.9388\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 1s 212us/step - loss: 0.1654 - acc: 0.9399\n",
      "2353/2353 [==============================] - 1s 378us/step\n",
      "4707/4707 [==============================] - 1s 111us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 3s 627us/step - loss: 0.4290 - acc: 0.8434\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 1s 121us/step - loss: 0.2480 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 1s 115us/step - loss: 0.2281 - acc: 0.9171\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 1s 121us/step - loss: 0.2221 - acc: 0.9212\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 0s 97us/step - loss: 0.2178 - acc: 0.9220\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 0s 97us/step - loss: 0.2132 - acc: 0.9241\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 0s 97us/step - loss: 0.2107 - acc: 0.9244\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 0s 98us/step - loss: 0.2072 - acc: 0.9271\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2051 - acc: 0.9246\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 0s 95us/step - loss: 0.2021 - acc: 0.9258\n",
      "2354/2354 [==============================] - 1s 312us/step\n",
      "4706/4706 [==============================] - 0s 57us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 421us/step - loss: 0.4376 - acc: 0.8354\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 100us/step - loss: 0.2636 - acc: 0.9055\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 95us/step - loss: 0.2456 - acc: 0.9099\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2371 - acc: 0.9159\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 99us/step - loss: 0.2311 - acc: 0.9163\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 101us/step - loss: 0.2276 - acc: 0.9178\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 96us/step - loss: 0.2253 - acc: 0.9188\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2206 - acc: 0.9195\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 95us/step - loss: 0.2176 - acc: 0.9199\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.2148 - acc: 0.9233\n",
      "2353/2353 [==============================] - 1s 347us/step\n",
      "4707/4707 [==============================] - 0s 56us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 445us/step - loss: 0.4577 - acc: 0.8045\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 99us/step - loss: 0.2615 - acc: 0.9108\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2387 - acc: 0.9137\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 100us/step - loss: 0.2300 - acc: 0.9167\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 96us/step - loss: 0.2250 - acc: 0.9203\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 99us/step - loss: 0.2214 - acc: 0.9182\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2182 - acc: 0.9210\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 1s 131us/step - loss: 0.2156 - acc: 0.9218\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.2129 - acc: 0.9212\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 1s 123us/step - loss: 0.2091 - acc: 0.9239\n",
      "2353/2353 [==============================] - 1s 334us/step\n",
      "4707/4707 [==============================] - 0s 57us/step\n",
      "Epoch 1/20\n",
      "4706/4706 [==============================] - 2s 458us/step - loss: 0.4339 - acc: 0.8351\n",
      "Epoch 2/20\n",
      "4706/4706 [==============================] - 0s 102us/step - loss: 0.2447 - acc: 0.9118\n",
      "Epoch 3/20\n",
      "4706/4706 [==============================] - 1s 127us/step - loss: 0.2280 - acc: 0.9180\n",
      "Epoch 4/20\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.2226 - acc: 0.9220\n",
      "Epoch 5/20\n",
      "4706/4706 [==============================] - 0s 101us/step - loss: 0.2172 - acc: 0.9220\n",
      "Epoch 6/20\n",
      "4706/4706 [==============================] - 1s 146us/step - loss: 0.2140 - acc: 0.9233\n",
      "Epoch 7/20\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.2109 - acc: 0.9250\n",
      "Epoch 8/20\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.2073 - acc: 0.9269\n",
      "Epoch 9/20\n",
      "4706/4706 [==============================] - 0s 103us/step - loss: 0.2040 - acc: 0.9265\n",
      "Epoch 10/20\n",
      "4706/4706 [==============================] - 0s 100us/step - loss: 0.2015 - acc: 0.9252\n",
      "Epoch 11/20\n",
      "4706/4706 [==============================] - 0s 101us/step - loss: 0.1985 - acc: 0.9282\n",
      "Epoch 12/20\n",
      "4706/4706 [==============================] - 0s 102us/step - loss: 0.1960 - acc: 0.9290\n",
      "Epoch 13/20\n",
      "4706/4706 [==============================] - 0s 99us/step - loss: 0.1936 - acc: 0.9305\n",
      "Epoch 14/20\n",
      "4706/4706 [==============================] - 0s 97us/step - loss: 0.1910 - acc: 0.9324\n",
      "Epoch 15/20\n",
      "4706/4706 [==============================] - 0s 96us/step - loss: 0.1890 - acc: 0.9322\n",
      "Epoch 16/20\n",
      "4706/4706 [==============================] - 1s 117us/step - loss: 0.1866 - acc: 0.9326\n",
      "Epoch 17/20\n",
      "4706/4706 [==============================] - 1s 110us/step - loss: 0.1847 - acc: 0.9341\n",
      "Epoch 18/20\n",
      "4706/4706 [==============================] - 0s 98us/step - loss: 0.1829 - acc: 0.9337\n",
      "Epoch 19/20\n",
      "4706/4706 [==============================] - 1s 112us/step - loss: 0.1812 - acc: 0.9352\n",
      "Epoch 20/20\n",
      "4706/4706 [==============================] - 1s 135us/step - loss: 0.1785 - acc: 0.9356\n",
      "2354/2354 [==============================] - 1s 335us/step\n",
      "4706/4706 [==============================] - 0s 64us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 2s 493us/step - loss: 0.4342 - acc: 0.8375\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 1s 124us/step - loss: 0.2627 - acc: 0.9048\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.2462 - acc: 0.9093\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2383 - acc: 0.9142\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.2329 - acc: 0.9142\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 1s 123us/step - loss: 0.2277 - acc: 0.9159\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 1s 116us/step - loss: 0.2249 - acc: 0.9191\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 1s 127us/step - loss: 0.2213 - acc: 0.9193\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2187 - acc: 0.9225\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2152 - acc: 0.9225\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2121 - acc: 0.9222\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 1s 106us/step - loss: 0.2100 - acc: 0.9237\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.2070 - acc: 0.9237\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.2055 - acc: 0.9235\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.2035 - acc: 0.9259\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 1s 133us/step - loss: 0.2019 - acc: 0.9248\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.1986 - acc: 0.9280\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.1973 - acc: 0.9252\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.1951 - acc: 0.9284\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.1939 - acc: 0.9280\n",
      "2353/2353 [==============================] - 1s 349us/step\n",
      "4707/4707 [==============================] - 0s 68us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 2s 494us/step - loss: 0.4285 - acc: 0.8504\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.2508 - acc: 0.9101\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.2352 - acc: 0.9123\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.2276 - acc: 0.9180\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2232 - acc: 0.9182\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 1s 123us/step - loss: 0.2180 - acc: 0.9201\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.2151 - acc: 0.9203\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2123 - acc: 0.9220\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.2088 - acc: 0.9246\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.2079 - acc: 0.9229\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2053 - acc: 0.9235\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 1s 122us/step - loss: 0.2024 - acc: 0.9259\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 1s 116us/step - loss: 0.2008 - acc: 0.9250\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.1997 - acc: 0.9280\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.1965 - acc: 0.9278\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 1s 119us/step - loss: 0.1943 - acc: 0.9303\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.1931 - acc: 0.9305\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.1921 - acc: 0.9314\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.1899 - acc: 0.9316\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.1875 - acc: 0.9327\n",
      "2353/2353 [==============================] - 1s 340us/step\n",
      "4707/4707 [==============================] - 0s 71us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 2s 477us/step - loss: 0.4411 - acc: 0.8326\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 1s 123us/step - loss: 0.2492 - acc: 0.9091\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.2298 - acc: 0.9178\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 1s 108us/step - loss: 0.2219 - acc: 0.9214\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.2175 - acc: 0.9207\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 1s 112us/step - loss: 0.2124 - acc: 0.9237\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.2104 - acc: 0.9235\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 1s 108us/step - loss: 0.2071 - acc: 0.9258\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.2031 - acc: 0.9252\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 1s 117us/step - loss: 0.2014 - acc: 0.9265\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 1s 125us/step - loss: 0.1994 - acc: 0.9265\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 1s 112us/step - loss: 0.1962 - acc: 0.9286\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 1s 128us/step - loss: 0.1938 - acc: 0.9282\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.1913 - acc: 0.9297\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 1s 116us/step - loss: 0.1899 - acc: 0.9288\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 1s 123us/step - loss: 0.1874 - acc: 0.9320\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 1s 123us/step - loss: 0.1854 - acc: 0.9326\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 1s 120us/step - loss: 0.1819 - acc: 0.9335\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 1s 116us/step - loss: 0.1810 - acc: 0.9358\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 1s 114us/step - loss: 0.1792 - acc: 0.9350\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.1776 - acc: 0.9375\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 1s 123us/step - loss: 0.1761 - acc: 0.9350\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 1s 118us/step - loss: 0.1733 - acc: 0.9371\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 1s 119us/step - loss: 0.1718 - acc: 0.9392\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 1s 113us/step - loss: 0.1710 - acc: 0.9390\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 1s 121us/step - loss: 0.1702 - acc: 0.9392\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 1s 111us/step - loss: 0.1681 - acc: 0.9397\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 1s 119us/step - loss: 0.1661 - acc: 0.9401\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 1s 117us/step - loss: 0.1650 - acc: 0.9424\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 1s 120us/step - loss: 0.1636 - acc: 0.9407\n",
      "2354/2354 [==============================] - 1s 370us/step\n",
      "4706/4706 [==============================] - 0s 79us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 2s 487us/step - loss: 0.4466 - acc: 0.8294\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2646 - acc: 0.9038\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2470 - acc: 0.9091\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2386 - acc: 0.9112\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.2332 - acc: 0.9133\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.2292 - acc: 0.9165\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 1s 119us/step - loss: 0.2246 - acc: 0.9182\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 1s 121us/step - loss: 0.2228 - acc: 0.9201\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 1s 132us/step - loss: 0.2199 - acc: 0.9201\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2167 - acc: 0.9214\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.2142 - acc: 0.9199\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 1s 112us/step - loss: 0.2111 - acc: 0.9239\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.2089 - acc: 0.9244\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 1s 114us/step - loss: 0.2051 - acc: 0.9265\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.2041 - acc: 0.9246\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2023 - acc: 0.9278\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.1995 - acc: 0.9273\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.1974 - acc: 0.9273\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 1s 115us/step - loss: 0.1955 - acc: 0.9284\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 1s 128us/step - loss: 0.1936 - acc: 0.9293\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 1s 121us/step - loss: 0.1924 - acc: 0.9297\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.1912 - acc: 0.9314\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 1s 123us/step - loss: 0.1888 - acc: 0.9297\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 1s 120us/step - loss: 0.1868 - acc: 0.9327\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 1s 136us/step - loss: 0.1854 - acc: 0.9331\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 1s 117us/step - loss: 0.1839 - acc: 0.9329\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.1825 - acc: 0.9329\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.1805 - acc: 0.9344\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.1795 - acc: 0.9335\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.1782 - acc: 0.9354\n",
      "2353/2353 [==============================] - 1s 360us/step\n",
      "4707/4707 [==============================] - 0s 66us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 2s 515us/step - loss: 0.4311 - acc: 0.8432\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 1s 129us/step - loss: 0.2523 - acc: 0.9091\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 1s 125us/step - loss: 0.2338 - acc: 0.9148\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 1s 128us/step - loss: 0.2264 - acc: 0.9171\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.2220 - acc: 0.9205\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.2190 - acc: 0.9184\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2155 - acc: 0.9205\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2138 - acc: 0.9227\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 1s 109us/step - loss: 0.2115 - acc: 0.9218\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.2079 - acc: 0.9239\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.2061 - acc: 0.9261\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.2046 - acc: 0.9233\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.2011 - acc: 0.9276\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.1984 - acc: 0.9265\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.1962 - acc: 0.9290\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.1956 - acc: 0.9290\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.1940 - acc: 0.9278\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 1s 106us/step - loss: 0.1916 - acc: 0.9322\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.1899 - acc: 0.9305\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.1874 - acc: 0.9320\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 1s 106us/step - loss: 0.1872 - acc: 0.9301\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.1848 - acc: 0.9314\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 1s 108us/step - loss: 0.1836 - acc: 0.9337\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.1812 - acc: 0.9333\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 1s 106us/step - loss: 0.1809 - acc: 0.9337\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.1801 - acc: 0.9333\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.1779 - acc: 0.9333\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.1766 - acc: 0.9344\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.1759 - acc: 0.9348\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.1739 - acc: 0.9386\n",
      "2353/2353 [==============================] - 1s 343us/step\n",
      "4707/4707 [==============================] - 0s 68us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 437us/step - loss: 0.4857 - acc: 0.8230\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2638 - acc: 0.9061\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2335 - acc: 0.9173\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2241 - acc: 0.9216\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2189 - acc: 0.9216\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2153 - acc: 0.9222\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2126 - acc: 0.9229\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2096 - acc: 0.9241\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2067 - acc: 0.9252\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2041 - acc: 0.9263\n",
      "2354/2354 [==============================] - 1s 341us/step\n",
      "4706/4706 [==============================] - 0s 45us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 424us/step - loss: 0.4943 - acc: 0.8033\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2885 - acc: 0.8970\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2537 - acc: 0.9086\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2425 - acc: 0.9135\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2367 - acc: 0.9148\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2322 - acc: 0.9163\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2286 - acc: 0.9165\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2256 - acc: 0.9184\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2228 - acc: 0.9197\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2206 - acc: 0.9191\n",
      "2353/2353 [==============================] - 1s 340us/step\n",
      "4707/4707 [==============================] - 0s 49us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 491us/step - loss: 0.4867 - acc: 0.8116\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 1s 154us/step - loss: 0.2690 - acc: 0.9055\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 1s 141us/step - loss: 0.2385 - acc: 0.9123\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2296 - acc: 0.9144\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2248 - acc: 0.9180\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.2213 - acc: 0.9176\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.2179 - acc: 0.9216\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2168 - acc: 0.9195\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2136 - acc: 0.9222\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2124 - acc: 0.9229\n",
      "2353/2353 [==============================] - 1s 407us/step\n",
      "4707/4707 [==============================] - 0s 56us/step\n",
      "Epoch 1/20\n",
      "4706/4706 [==============================] - 3s 566us/step - loss: 0.4745 - acc: 0.8241\n",
      "Epoch 2/20\n",
      "4706/4706 [==============================] - 0s 84us/step - loss: 0.2606 - acc: 0.9105\n",
      "Epoch 3/20\n",
      "4706/4706 [==============================] - 0s 87us/step - loss: 0.2331 - acc: 0.9161\n",
      "Epoch 4/20\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2249 - acc: 0.9210\n",
      "Epoch 5/20\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.2201 - acc: 0.9227\n",
      "Epoch 6/20\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2157 - acc: 0.9244\n",
      "Epoch 7/20\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2135 - acc: 0.9239\n",
      "Epoch 8/20\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2104 - acc: 0.9252\n",
      "Epoch 9/20\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2079 - acc: 0.9258\n",
      "Epoch 10/20\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2063 - acc: 0.9258\n",
      "Epoch 11/20\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2049 - acc: 0.9290\n",
      "Epoch 12/20\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2025 - acc: 0.9292\n",
      "Epoch 13/20\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2009 - acc: 0.9290\n",
      "Epoch 14/20\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.1986 - acc: 0.9292\n",
      "Epoch 15/20\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.1966 - acc: 0.9295\n",
      "Epoch 16/20\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.1957 - acc: 0.9288\n",
      "Epoch 17/20\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.1936 - acc: 0.9316\n",
      "Epoch 18/20\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.1914 - acc: 0.9320\n",
      "Epoch 19/20\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.1900 - acc: 0.9324\n",
      "Epoch 20/20\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.1879 - acc: 0.9333\n",
      "2354/2354 [==============================] - 1s 349us/step\n",
      "4706/4706 [==============================] - 0s 43us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 2s 478us/step - loss: 0.4981 - acc: 0.8003\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2868 - acc: 0.9025\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2540 - acc: 0.9086\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2428 - acc: 0.9131\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2370 - acc: 0.9161\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2331 - acc: 0.9142\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2281 - acc: 0.9186\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2256 - acc: 0.9180\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2219 - acc: 0.9182\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2197 - acc: 0.9210\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2160 - acc: 0.9237\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2136 - acc: 0.9227\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2123 - acc: 0.9225\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2097 - acc: 0.9237\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2078 - acc: 0.9242\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2057 - acc: 0.9256\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2038 - acc: 0.9259\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2013 - acc: 0.9286\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1999 - acc: 0.9278\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.1978 - acc: 0.9276: 0s - loss: 0.1942 - acc: 0.\n",
      "2353/2353 [==============================] - 1s 327us/step\n",
      "4707/4707 [==============================] - 0s 42us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 2s 458us/step - loss: 0.4891 - acc: 0.8092\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2765 - acc: 0.9040\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2423 - acc: 0.9142\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2325 - acc: 0.9165\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2281 - acc: 0.9159\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2235 - acc: 0.9180\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2207 - acc: 0.9184\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2176 - acc: 0.9205\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2158 - acc: 0.9222\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2138 - acc: 0.9231\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2120 - acc: 0.9231\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2089 - acc: 0.9246\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2076 - acc: 0.9248\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2067 - acc: 0.9244\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 0s 91us/step - loss: 0.2047 - acc: 0.9280\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 1s 156us/step - loss: 0.2027 - acc: 0.9246\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 1s 287us/step - loss: 0.2003 - acc: 0.9267\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 1s 150us/step - loss: 0.1989 - acc: 0.9284\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 1s 118us/step - loss: 0.1970 - acc: 0.9280\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.1953 - acc: 0.9310\n",
      "2353/2353 [==============================] - 1s 347us/step\n",
      "4707/4707 [==============================] - 0s 39us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 2s 472us/step - loss: 0.4757 - acc: 0.8187\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2684 - acc: 0.9084\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2363 - acc: 0.9146\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2277 - acc: 0.9193\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2223 - acc: 0.9224\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2184 - acc: 0.9214\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2152 - acc: 0.9227\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2121 - acc: 0.9224\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.2101 - acc: 0.9250\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2082 - acc: 0.9254\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2053 - acc: 0.9258\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2042 - acc: 0.9256\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2012 - acc: 0.9269\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.1984 - acc: 0.9295\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1969 - acc: 0.9288\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.1944 - acc: 0.9295\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1929 - acc: 0.9299\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.1921 - acc: 0.9286\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 83us/step - loss: 0.1888 - acc: 0.9309\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 91us/step - loss: 0.1874 - acc: 0.9335\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.1856 - acc: 0.9326\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 96us/step - loss: 0.1845 - acc: 0.9337\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.1816 - acc: 0.9350\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 80us/step - loss: 0.1811 - acc: 0.9335\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.1793 - acc: 0.9352\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.1767 - acc: 0.9358\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.1754 - acc: 0.9365\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1756 - acc: 0.9377\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.1723 - acc: 0.9377\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.1711 - acc: 0.9380\n",
      "2354/2354 [==============================] - 1s 351us/step\n",
      "4706/4706 [==============================] - 0s 40us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 543us/step - loss: 0.5073 - acc: 0.7969\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2856 - acc: 0.8987\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2538 - acc: 0.9069\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2421 - acc: 0.9116\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 99us/step - loss: 0.2367 - acc: 0.9123\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 89us/step - loss: 0.2324 - acc: 0.9180\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 89us/step - loss: 0.2277 - acc: 0.9157\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2246 - acc: 0.9178\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2208 - acc: 0.9205\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2184 - acc: 0.9218\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 91us/step - loss: 0.2159 - acc: 0.9216\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2140 - acc: 0.9227\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2107 - acc: 0.9239\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2088 - acc: 0.9237\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2068 - acc: 0.9256\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 1s 107us/step - loss: 0.2052 - acc: 0.9256\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2032 - acc: 0.9261\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2015 - acc: 0.9282\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.1990 - acc: 0.9280\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.1976 - acc: 0.9295\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.1948 - acc: 0.9301\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.1939 - acc: 0.9301\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 91us/step - loss: 0.1922 - acc: 0.9286\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 99us/step - loss: 0.1899 - acc: 0.9312\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 100us/step - loss: 0.1890 - acc: 0.9312\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.1877 - acc: 0.9305\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 1s 111us/step - loss: 0.1855 - acc: 0.9327\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.1845 - acc: 0.9324\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.1839 - acc: 0.9327\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.1811 - acc: 0.9333\n",
      "2353/2353 [==============================] - 1s 400us/step\n",
      "4707/4707 [==============================] - 0s 42us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 551us/step - loss: 0.4741 - acc: 0.8392\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2704 - acc: 0.9040\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2402 - acc: 0.9120\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2314 - acc: 0.9154\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2260 - acc: 0.9182\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2221 - acc: 0.9193\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2194 - acc: 0.9159\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2177 - acc: 0.9216\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2149 - acc: 0.9218\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2127 - acc: 0.9231\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2110 - acc: 0.9220\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2090 - acc: 0.9250\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2070 - acc: 0.9242\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2056 - acc: 0.9254\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2043 - acc: 0.9246\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2029 - acc: 0.9263\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2007 - acc: 0.9286\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.1994 - acc: 0.9288\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 92us/step - loss: 0.1974 - acc: 0.9297\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.1964 - acc: 0.9299\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.1942 - acc: 0.9303\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 100us/step - loss: 0.1927 - acc: 0.9286\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.1913 - acc: 0.9331\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.1900 - acc: 0.9322\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.1889 - acc: 0.9310\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.1876 - acc: 0.9314\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1859 - acc: 0.9356\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.1846 - acc: 0.9350\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.1832 - acc: 0.9348\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1816 - acc: 0.9352\n",
      "2353/2353 [==============================] - 1s 399us/step\n",
      "4707/4707 [==============================] - 0s 52us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 3s 534us/step - loss: 0.5435 - acc: 0.7779\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 0s 79us/step - loss: 0.3000 - acc: 0.8972\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2441 - acc: 0.9139\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2299 - acc: 0.9195\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2229 - acc: 0.9205\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 0s 51us/step - loss: 0.2188 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2162 - acc: 0.9218\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 0s 83us/step - loss: 0.2136 - acc: 0.9224\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.2118 - acc: 0.9256\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 0s 55us/step - loss: 0.2089 - acc: 0.9216\n",
      "2354/2354 [==============================] - 1s 383us/step\n",
      "4706/4706 [==============================] - 0s 33us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 3s 549us/step - loss: 0.5257 - acc: 0.7740\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.3121 - acc: 0.8927\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2610 - acc: 0.9082\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2464 - acc: 0.9112\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2397 - acc: 0.9142\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 55us/step - loss: 0.2335 - acc: 0.9150\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 52us/step - loss: 0.2303 - acc: 0.9167\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 52us/step - loss: 0.2274 - acc: 0.9184\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 53us/step - loss: 0.2240 - acc: 0.9208\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 51us/step - loss: 0.2216 - acc: 0.9210\n",
      "2353/2353 [==============================] - 1s 355us/step\n",
      "4707/4707 [==============================] - 0s 30us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 2s 502us/step - loss: 0.5090 - acc: 0.8235\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2897 - acc: 0.9016\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 54us/step - loss: 0.2457 - acc: 0.9091\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2344 - acc: 0.9137\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 54us/step - loss: 0.2292 - acc: 0.9142\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2248 - acc: 0.9154\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 54us/step - loss: 0.2228 - acc: 0.9195\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2196 - acc: 0.9197\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2171 - acc: 0.9210\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 55us/step - loss: 0.2146 - acc: 0.9237\n",
      "2353/2353 [==============================] - 1s 433us/step\n",
      "4707/4707 [==============================] - 0s 40us/step\n",
      "Epoch 1/20\n",
      "4706/4706 [==============================] - 3s 586us/step - loss: 0.5400 - acc: 0.7956\n",
      "Epoch 2/20\n",
      "4706/4706 [==============================] - 0s 85us/step - loss: 0.3000 - acc: 0.8969\n",
      "Epoch 3/20\n",
      "4706/4706 [==============================] - 0s 56us/step - loss: 0.2435 - acc: 0.9142\n",
      "Epoch 4/20\n",
      "4706/4706 [==============================] - 0s 52us/step - loss: 0.2298 - acc: 0.9173\n",
      "Epoch 5/20\n",
      "4706/4706 [==============================] - 0s 95us/step - loss: 0.2231 - acc: 0.9193: 0s - loss: 0.2459 - acc\n",
      "Epoch 6/20\n",
      "4706/4706 [==============================] - 0s 53us/step - loss: 0.2188 - acc: 0.9199\n",
      "Epoch 7/20\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2151 - acc: 0.9231\n",
      "Epoch 8/20\n",
      "4706/4706 [==============================] - 0s 53us/step - loss: 0.2119 - acc: 0.9237\n",
      "Epoch 9/20\n",
      "4706/4706 [==============================] - 0s 56us/step - loss: 0.2094 - acc: 0.9275\n",
      "Epoch 10/20\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2074 - acc: 0.9254\n",
      "Epoch 11/20\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2040 - acc: 0.9278\n",
      "Epoch 12/20\n",
      "4706/4706 [==============================] - 0s 55us/step - loss: 0.2017 - acc: 0.9271\n",
      "Epoch 13/20\n",
      "4706/4706 [==============================] - 0s 80us/step - loss: 0.2005 - acc: 0.9288\n",
      "Epoch 14/20\n",
      "4706/4706 [==============================] - 0s 57us/step - loss: 0.1976 - acc: 0.9286\n",
      "Epoch 15/20\n",
      "4706/4706 [==============================] - 0s 52us/step - loss: 0.1960 - acc: 0.9299\n",
      "Epoch 16/20\n",
      "4706/4706 [==============================] - 0s 53us/step - loss: 0.1935 - acc: 0.9307\n",
      "Epoch 17/20\n",
      "4706/4706 [==============================] - 0s 53us/step - loss: 0.1924 - acc: 0.9316\n",
      "Epoch 18/20\n",
      "4706/4706 [==============================] - 0s 54us/step - loss: 0.1902 - acc: 0.9309\n",
      "Epoch 19/20\n",
      "4706/4706 [==============================] - 0s 52us/step - loss: 0.1876 - acc: 0.9318\n",
      "Epoch 20/20\n",
      "4706/4706 [==============================] - 0s 53us/step - loss: 0.1869 - acc: 0.9316\n",
      "2354/2354 [==============================] - 1s 374us/step\n",
      "4706/4706 [==============================] - 0s 43us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 3s 552us/step - loss: 0.5405 - acc: 0.7831\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.3141 - acc: 0.8929\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2617 - acc: 0.9050\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2465 - acc: 0.9097\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2396 - acc: 0.9129\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2348 - acc: 0.9161\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2302 - acc: 0.9176\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.2269 - acc: 0.9195\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2237 - acc: 0.9208\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2217 - acc: 0.9193\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2182 - acc: 0.9229\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2165 - acc: 0.9220\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2134 - acc: 0.9248\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2117 - acc: 0.9244\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2092 - acc: 0.9225\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2070 - acc: 0.9267\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2053 - acc: 0.9242\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2039 - acc: 0.9254\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2021 - acc: 0.9259\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1993 - acc: 0.9265\n",
      "2353/2353 [==============================] - 1s 472us/step\n",
      "4707/4707 [==============================] - 0s 43us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 3s 563us/step - loss: 0.5225 - acc: 0.8065\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2950 - acc: 0.8970\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2467 - acc: 0.9125\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2345 - acc: 0.9163\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2282 - acc: 0.9174\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2245 - acc: 0.9186\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2215 - acc: 0.9218\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2201 - acc: 0.9174\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2175 - acc: 0.9216\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2153 - acc: 0.9208\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2145 - acc: 0.9199\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2120 - acc: 0.9214\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2109 - acc: 0.9216\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2093 - acc: 0.9239\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2090 - acc: 0.9244\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2069 - acc: 0.9263\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2057 - acc: 0.9269\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2039 - acc: 0.9235\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2034 - acc: 0.9248\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2019 - acc: 0.9269\n",
      "2353/2353 [==============================] - 1s 472us/step\n",
      "4707/4707 [==============================] - 0s 45us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 594us/step - loss: 0.5192 - acc: 0.7850\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2981 - acc: 0.8999\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2451 - acc: 0.9139\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2311 - acc: 0.9190\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2243 - acc: 0.9203\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2188 - acc: 0.9205\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2158 - acc: 0.9244\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2134 - acc: 0.9250\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2098 - acc: 0.9254\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2081 - acc: 0.9252\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2054 - acc: 0.9252\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2035 - acc: 0.9254\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2014 - acc: 0.9286\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.1996 - acc: 0.9282\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.1990 - acc: 0.9267\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.1967 - acc: 0.9280\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1946 - acc: 0.9292\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.1931 - acc: 0.9299\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.1912 - acc: 0.9301\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1893 - acc: 0.9309\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1880 - acc: 0.9309\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1869 - acc: 0.9314\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.1844 - acc: 0.9329\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1839 - acc: 0.9316\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.1816 - acc: 0.9333\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.1808 - acc: 0.9350\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 58us/step - loss: 0.1792 - acc: 0.9348\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1775 - acc: 0.9348\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1761 - acc: 0.9354\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.1745 - acc: 0.9373\n",
      "2354/2354 [==============================] - 1s 409us/step\n",
      "4706/4706 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 537us/step - loss: 0.5335 - acc: 0.7610\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.3143 - acc: 0.8946\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2622 - acc: 0.9080\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2471 - acc: 0.9112\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2401 - acc: 0.9146\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2352 - acc: 0.9116\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2311 - acc: 0.9159\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2277 - acc: 0.9182\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2259 - acc: 0.9201\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2231 - acc: 0.9212\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2203 - acc: 0.9199\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2182 - acc: 0.9231\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2170 - acc: 0.9227\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2148 - acc: 0.9225\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2130 - acc: 0.9227\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2114 - acc: 0.9229\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2091 - acc: 0.9235\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2060 - acc: 0.9254\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2055 - acc: 0.9256\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2037 - acc: 0.9254\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2020 - acc: 0.9248\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2011 - acc: 0.9263\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 54us/step - loss: 0.1993 - acc: 0.9267\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 53us/step - loss: 0.1981 - acc: 0.9276\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 54us/step - loss: 0.1963 - acc: 0.9269\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 53us/step - loss: 0.1955 - acc: 0.9280\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1938 - acc: 0.9288\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.1924 - acc: 0.9299\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1910 - acc: 0.9301\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1904 - acc: 0.9297\n",
      "2353/2353 [==============================] - 1s 421us/step\n",
      "4707/4707 [==============================] - 0s 54us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 638us/step - loss: 0.5345 - acc: 0.7818\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.3037 - acc: 0.8950\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2492 - acc: 0.9101\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2358 - acc: 0.9148\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2291 - acc: 0.9167\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2259 - acc: 0.9180\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2222 - acc: 0.9201\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2192 - acc: 0.9208\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2174 - acc: 0.9201\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2154 - acc: 0.9199\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2130 - acc: 0.9225\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2110 - acc: 0.9239\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 89us/step - loss: 0.2086 - acc: 0.9214\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2075 - acc: 0.9239\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2056 - acc: 0.9259\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2035 - acc: 0.9248\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2043 - acc: 0.9265\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2009 - acc: 0.9269\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.1998 - acc: 0.9267\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.1980 - acc: 0.9282\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.1968 - acc: 0.9299\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1950 - acc: 0.9288\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.1934 - acc: 0.9278\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.1927 - acc: 0.9290\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.1907 - acc: 0.9295\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.1895 - acc: 0.9316\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.1889 - acc: 0.9305\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1868 - acc: 0.9307\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.1860 - acc: 0.9320\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.1843 - acc: 0.9322\n",
      "2353/2353 [==============================] - 1s 423us/step\n",
      "4707/4707 [==============================] - 0s 32us/step\n",
      "Epoch 1/10\n",
      "4706/4706 [==============================] - 2s 529us/step - loss: 0.5675 - acc: 0.7864\n",
      "Epoch 2/10\n",
      "4706/4706 [==============================] - 0s 54us/step - loss: 0.3513 - acc: 0.8785\n",
      "Epoch 3/10\n",
      "4706/4706 [==============================] - 0s 40us/step - loss: 0.2626 - acc: 0.9091\n",
      "Epoch 4/10\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2381 - acc: 0.9173\n",
      "Epoch 5/10\n",
      "4706/4706 [==============================] - 0s 54us/step - loss: 0.2285 - acc: 0.9195\n",
      "Epoch 6/10\n",
      "4706/4706 [==============================] - 0s 51us/step - loss: 0.2244 - acc: 0.9207\n",
      "Epoch 7/10\n",
      "4706/4706 [==============================] - 0s 47us/step - loss: 0.2202 - acc: 0.9233\n",
      "Epoch 8/10\n",
      "4706/4706 [==============================] - 0s 38us/step - loss: 0.2180 - acc: 0.9216\n",
      "Epoch 9/10\n",
      "4706/4706 [==============================] - 0s 38us/step - loss: 0.2158 - acc: 0.9244\n",
      "Epoch 10/10\n",
      "4706/4706 [==============================] - 0s 46us/step - loss: 0.2137 - acc: 0.9241\n",
      "2354/2354 [==============================] - 1s 432us/step\n",
      "4706/4706 [==============================] - 0s 24us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 3s 543us/step - loss: 0.5857 - acc: 0.7663\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.3709 - acc: 0.8730\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2813 - acc: 0.9029\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2565 - acc: 0.9108\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2470 - acc: 0.9108\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 46us/step - loss: 0.2408 - acc: 0.9133\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 48us/step - loss: 0.2373 - acc: 0.9129\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2343 - acc: 0.9120\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 48us/step - loss: 0.2310 - acc: 0.9137\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 54us/step - loss: 0.2284 - acc: 0.9176\n",
      "2353/2353 [==============================] - 1s 455us/step\n",
      "4707/4707 [==============================] - 0s 44us/step\n",
      "Epoch 1/10\n",
      "4707/4707 [==============================] - 3s 603us/step - loss: 0.5698 - acc: 0.7888\n",
      "Epoch 2/10\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.3461 - acc: 0.8846\n",
      "Epoch 3/10\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2655 - acc: 0.9061\n",
      "Epoch 4/10\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2427 - acc: 0.9108\n",
      "Epoch 5/10\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2346 - acc: 0.9133\n",
      "Epoch 6/10\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2296 - acc: 0.9146\n",
      "Epoch 7/10\n",
      "4707/4707 [==============================] - 0s 47us/step - loss: 0.2260 - acc: 0.9161\n",
      "Epoch 8/10\n",
      "4707/4707 [==============================] - 0s 47us/step - loss: 0.2230 - acc: 0.9180\n",
      "Epoch 9/10\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2205 - acc: 0.9186\n",
      "Epoch 10/10\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2181 - acc: 0.9195\n",
      "2353/2353 [==============================] - 1s 418us/step\n",
      "4707/4707 [==============================] - 0s 30us/step\n",
      "Epoch 1/20\n",
      "4706/4706 [==============================] - 3s 538us/step - loss: 0.5669 - acc: 0.7631\n",
      "Epoch 2/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.3476 - acc: 0.8814\n",
      "Epoch 3/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2639 - acc: 0.9080\n",
      "Epoch 4/20\n",
      "4706/4706 [==============================] - 0s 40us/step - loss: 0.2398 - acc: 0.9159\n",
      "Epoch 5/20\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2291 - acc: 0.9229\n",
      "Epoch 6/20\n",
      "4706/4706 [==============================] - 0s 43us/step - loss: 0.2233 - acc: 0.9222\n",
      "Epoch 7/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2195 - acc: 0.9224\n",
      "Epoch 8/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 9/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2139 - acc: 0.9254\n",
      "Epoch 10/20\n",
      "4706/4706 [==============================] - 0s 40us/step - loss: 0.2121 - acc: 0.9252\n",
      "Epoch 11/20\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2096 - acc: 0.9252\n",
      "Epoch 12/20\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2080 - acc: 0.9265\n",
      "Epoch 13/20\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2057 - acc: 0.9256\n",
      "Epoch 14/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2044 - acc: 0.9271\n",
      "Epoch 15/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2027 - acc: 0.9269: 0s - loss: 0.2008 - acc: 0.928\n",
      "Epoch 16/20\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2023 - acc: 0.9267\n",
      "Epoch 17/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2000 - acc: 0.9278\n",
      "Epoch 18/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1981 - acc: 0.9278\n",
      "Epoch 19/20\n",
      "4706/4706 [==============================] - 0s 43us/step - loss: 0.1969 - acc: 0.9284\n",
      "Epoch 20/20\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1949 - acc: 0.9297\n",
      "2354/2354 [==============================] - 1s 404us/step\n",
      "4706/4706 [==============================] - 0s 25us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 3s 537us/step - loss: 0.5867 - acc: 0.7338\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.3738 - acc: 0.8657\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2832 - acc: 0.9004\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2576 - acc: 0.9074\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 0s 47us/step - loss: 0.2469 - acc: 0.9118\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2412 - acc: 0.9120\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2363 - acc: 0.9133\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2337 - acc: 0.9127\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2304 - acc: 0.9157\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2277 - acc: 0.9188\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2259 - acc: 0.9205\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2229 - acc: 0.9201\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2203 - acc: 0.9218\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2187 - acc: 0.9218\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2175 - acc: 0.9216\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2152 - acc: 0.9233\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2131 - acc: 0.9222\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2119 - acc: 0.9229\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2090 - acc: 0.9242\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2081 - acc: 0.9250\n",
      "2353/2353 [==============================] - 1s 404us/step\n",
      "4707/4707 [==============================] - 0s 24us/step\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 3s 538us/step - loss: 0.5648 - acc: 0.7820\n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 0s 53us/step - loss: 0.3590 - acc: 0.8810\n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2731 - acc: 0.9050\n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2479 - acc: 0.9123\n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2371 - acc: 0.9127\n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 0s 37us/step - loss: 0.2322 - acc: 0.9150\n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2283 - acc: 0.9167\n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2250 - acc: 0.9195\n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 0s 37us/step - loss: 0.2230 - acc: 0.9184\n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2211 - acc: 0.9188\n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2189 - acc: 0.9212\n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 0s 37us/step - loss: 0.2175 - acc: 0.9184\n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2158 - acc: 0.9210\n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2143 - acc: 0.9227\n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2133 - acc: 0.9220\n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2111 - acc: 0.9235\n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2111 - acc: 0.9242\n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2097 - acc: 0.9239\n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 0s 46us/step - loss: 0.2081 - acc: 0.9244\n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 0s 49us/step - loss: 0.2078 - acc: 0.9244\n",
      "2353/2353 [==============================] - 1s 463us/step\n",
      "4707/4707 [==============================] - 0s 24us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 562us/step - loss: 0.5657 - acc: 0.7646\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.3425 - acc: 0.8842\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 43us/step - loss: 0.2595 - acc: 0.9103\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2365 - acc: 0.9167\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2276 - acc: 0.9199\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2222 - acc: 0.9216\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2179 - acc: 0.9235\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 43us/step - loss: 0.2161 - acc: 0.9241\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2136 - acc: 0.9246\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2115 - acc: 0.9220\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2098 - acc: 0.9231\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2085 - acc: 0.9237\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2065 - acc: 0.9239\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2050 - acc: 0.9252\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.2032 - acc: 0.9244\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 43us/step - loss: 0.2016 - acc: 0.9278\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.2005 - acc: 0.9271\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1996 - acc: 0.9282\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.1971 - acc: 0.9290\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 40us/step - loss: 0.1963 - acc: 0.9290\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 43us/step - loss: 0.1947 - acc: 0.9301\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.1937 - acc: 0.9295\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1920 - acc: 0.9301\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1907 - acc: 0.9295\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1903 - acc: 0.9305\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.1880 - acc: 0.9331\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.1868 - acc: 0.9341\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1863 - acc: 0.9314\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 42us/step - loss: 0.1844 - acc: 0.9341\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 41us/step - loss: 0.1839 - acc: 0.9352\n",
      "2354/2354 [==============================] - 1s 423us/step\n",
      "4706/4706 [==============================] - 0s 27us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 841us/step - loss: 0.5710 - acc: 0.7708\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.3639 - acc: 0.8740\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2826 - acc: 0.9014\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2580 - acc: 0.9080\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2471 - acc: 0.9123\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2411 - acc: 0.9129\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2372 - acc: 0.9140\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2333 - acc: 0.9142\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2310 - acc: 0.9182\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.2285 - acc: 0.9165\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2264 - acc: 0.9182\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2239 - acc: 0.9201\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2226 - acc: 0.9199\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2209 - acc: 0.9212\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2189 - acc: 0.9214\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2179 - acc: 0.9214\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2161 - acc: 0.9225\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2150 - acc: 0.9233\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2120 - acc: 0.9235\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2111 - acc: 0.9242\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2097 - acc: 0.9250\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 38us/step - loss: 0.2081 - acc: 0.9254\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 46us/step - loss: 0.2067 - acc: 0.9256\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2048 - acc: 0.9248\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2036 - acc: 0.9261\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 39us/step - loss: 0.2025 - acc: 0.9250\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 53us/step - loss: 0.2010 - acc: 0.9265\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 47us/step - loss: 0.1995 - acc: 0.9261\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.1980 - acc: 0.9265\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 40us/step - loss: 0.1971 - acc: 0.9278\n",
      "2353/2353 [==============================] - 1s 517us/step\n",
      "4707/4707 [==============================] - 0s 47us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 617us/step - loss: 0.5711 - acc: 0.7761\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.3626 - acc: 0.8732\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2746 - acc: 0.9055\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2475 - acc: 0.9110\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 47us/step - loss: 0.2361 - acc: 0.9142\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2302 - acc: 0.9161\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2269 - acc: 0.9176\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2242 - acc: 0.9182\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 43us/step - loss: 0.2218 - acc: 0.9182\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2201 - acc: 0.9203\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2187 - acc: 0.9184\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2165 - acc: 0.9214\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 45us/step - loss: 0.2156 - acc: 0.9208\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2138 - acc: 0.9210\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2122 - acc: 0.9225\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2103 - acc: 0.9244\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 43us/step - loss: 0.2097 - acc: 0.9222\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 50us/step - loss: 0.2088 - acc: 0.9229\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 46us/step - loss: 0.2070 - acc: 0.9237\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 43us/step - loss: 0.2057 - acc: 0.9246\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 41us/step - loss: 0.2047 - acc: 0.9252\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 42us/step - loss: 0.2041 - acc: 0.9256\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 51us/step - loss: 0.2024 - acc: 0.9278\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 44us/step - loss: 0.2020 - acc: 0.9286\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 43us/step - loss: 0.2004 - acc: 0.9286\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 43us/step - loss: 0.1990 - acc: 0.9271\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 47us/step - loss: 0.1977 - acc: 0.9286\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 47us/step - loss: 0.1969 - acc: 0.9286\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 43us/step - loss: 0.1960 - acc: 0.9293\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 43us/step - loss: 0.1949 - acc: 0.9284\n",
      "2353/2353 [==============================] - 1s 438us/step\n",
      "4707/4707 [==============================] - 0s 30us/step\n",
      "Epoch 1/30\n",
      "7060/7060 [==============================] - 3s 398us/step - loss: 0.4627 - acc: 0.8215\n",
      "Epoch 2/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2589 - acc: 0.9084\n",
      "Epoch 3/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2380 - acc: 0.9140\n",
      "Epoch 4/30\n",
      "7060/7060 [==============================] - 1s 72us/step - loss: 0.2309 - acc: 0.9154\n",
      "Epoch 5/30\n",
      "7060/7060 [==============================] - 1s 74us/step - loss: 0.2260 - acc: 0.9176\n",
      "Epoch 6/30\n",
      "7060/7060 [==============================] - 0s 67us/step - loss: 0.2226 - acc: 0.9191\n",
      "Epoch 7/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.2204 - acc: 0.9195\n",
      "Epoch 8/30\n",
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.2167 - acc: 0.9220\n",
      "Epoch 9/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2149 - acc: 0.9227\n",
      "Epoch 10/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2121 - acc: 0.9234\n",
      "Epoch 11/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2100 - acc: 0.9238\n",
      "Epoch 12/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2085 - acc: 0.9246\n",
      "Epoch 13/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2061 - acc: 0.9266\n",
      "Epoch 14/30\n",
      "7060/7060 [==============================] - 0s 65us/step - loss: 0.2046 - acc: 0.9261\n",
      "Epoch 15/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2025 - acc: 0.9273\n",
      "Epoch 16/30\n",
      "7060/7060 [==============================] - 0s 64us/step - loss: 0.2009 - acc: 0.9285\n",
      "Epoch 17/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.1994 - acc: 0.9303\n",
      "Epoch 18/30\n",
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.1979 - acc: 0.9288\n",
      "Epoch 19/30\n",
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.1954 - acc: 0.9314\n",
      "Epoch 20/30\n",
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.1938 - acc: 0.9295\n",
      "Epoch 21/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1926 - acc: 0.9313\n",
      "Epoch 22/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.1914 - acc: 0.9317\n",
      "Epoch 23/30\n",
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.1895 - acc: 0.9317\n",
      "Epoch 24/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.1890 - acc: 0.9320\n",
      "Epoch 25/30\n",
      "7060/7060 [==============================] - 0s 65us/step - loss: 0.1876 - acc: 0.9327\n",
      "Epoch 26/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.1863 - acc: 0.9336\n",
      "Epoch 27/30\n",
      "7060/7060 [==============================] - 0s 65us/step - loss: 0.1857 - acc: 0.9336\n",
      "Epoch 28/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.1840 - acc: 0.9326: 0s - loss: 0.1990 - acc:\n",
      "Epoch 29/30\n",
      "7060/7060 [==============================] - 0s 65us/step - loss: 0.1838 - acc: 0.9331\n",
      "Epoch 30/30\n",
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.1823 - acc: 0.9353\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=new_model, verbose=1)\n",
    "# define the grid search parameters\n",
    "batch_size = [10,20,30,40,60]\n",
    "epochs = [10,20,30]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.916856 using {'batch_size': 40, 'epochs': 30}\n",
      "0.914164 (0.006410) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.916431 (0.007130) with: {'batch_size': 10, 'epochs': 20}\n",
      "0.915864 (0.006064) with: {'batch_size': 10, 'epochs': 30}\n",
      "0.914589 (0.004678) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.915156 (0.006960) with: {'batch_size': 20, 'epochs': 20}\n",
      "0.914448 (0.007476) with: {'batch_size': 20, 'epochs': 30}\n",
      "0.914873 (0.007077) with: {'batch_size': 30, 'epochs': 10}\n",
      "0.914873 (0.009388) with: {'batch_size': 30, 'epochs': 20}\n",
      "0.916006 (0.006435) with: {'batch_size': 30, 'epochs': 30}\n",
      "0.914164 (0.007156) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.915297 (0.007879) with: {'batch_size': 40, 'epochs': 20}\n",
      "0.916856 (0.007133) with: {'batch_size': 40, 'epochs': 30}\n",
      "0.912465 (0.007936) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.911898 (0.007214) with: {'batch_size': 60, 'epochs': 20}\n",
      "0.915297 (0.005711) with: {'batch_size': 60, 'epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Training Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model_opt(optimizer):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=35, kernel_initializer='normal', activation='relu'))\n",
    "    #if we want a hidden layer :\n",
    "    #model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 565us/step - loss: 0.6820 - acc: 0.6477\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.6273 - acc: 0.8330\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.5522 - acc: 0.8572\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.4758 - acc: 0.8731\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.4144 - acc: 0.8878\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.3680 - acc: 0.8940\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.3345 - acc: 0.8995\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.3105 - acc: 0.9014\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2933 - acc: 0.9031\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2806 - acc: 0.9046\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2712 - acc: 0.9061\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2638 - acc: 0.9082\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2581 - acc: 0.9091: 0s - loss: 0.2527 - acc: \n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2533 - acc: 0.9114\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2494 - acc: 0.9135\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2462 - acc: 0.9135\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2434 - acc: 0.9142\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2410 - acc: 0.9152\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2390 - acc: 0.9148\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2372 - acc: 0.9161\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2355 - acc: 0.9167\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2340 - acc: 0.9176\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2326 - acc: 0.9171\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2314 - acc: 0.9171\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2303 - acc: 0.9176\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2293 - acc: 0.9173\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2283 - acc: 0.9184\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2274 - acc: 0.9182\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.2265 - acc: 0.9184\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2258 - acc: 0.9186\n",
      "2354/2354 [==============================] - 1s 449us/step\n",
      "4706/4706 [==============================] - 0s 54us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 602us/step - loss: 0.6738 - acc: 0.6563\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.6229 - acc: 0.7712\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.5577 - acc: 0.8364\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.4940 - acc: 0.8591\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.4408 - acc: 0.8764\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.3985 - acc: 0.8829\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.3660 - acc: 0.8872\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.3414 - acc: 0.8887\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.3230 - acc: 0.8921\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.3090 - acc: 0.8938\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2982 - acc: 0.8965\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2899 - acc: 0.8959\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2831 - acc: 0.8984\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2775 - acc: 0.9014\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2729 - acc: 0.9033\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2689 - acc: 0.9050\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2656 - acc: 0.9055\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2627 - acc: 0.9067\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2602 - acc: 0.9080\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2579 - acc: 0.9076\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2560 - acc: 0.9078\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2542 - acc: 0.9089\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2525 - acc: 0.9091\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2511 - acc: 0.9089\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2496 - acc: 0.9106\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2484 - acc: 0.9103\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2472 - acc: 0.9108\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2461 - acc: 0.9093\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2451 - acc: 0.9099\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2441 - acc: 0.9110\n",
      "2353/2353 [==============================] - 1s 443us/step\n",
      "4707/4707 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 555us/step - loss: 0.6825 - acc: 0.6363\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.6296 - acc: 0.8156\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.5586 - acc: 0.8398\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.4873 - acc: 0.8617\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.4291 - acc: 0.8789: 0s - loss: 0.4462 - acc: 0.88 - ETA: 0s - loss: 0.4355 - acc: 0.8\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.3836 - acc: 0.8893\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.3494 - acc: 0.8946\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.3245 - acc: 0.8974\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.3065 - acc: 0.8999\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2932 - acc: 0.9035\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2831 - acc: 0.9046\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2753 - acc: 0.9067\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2691 - acc: 0.9084\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2640 - acc: 0.9091\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2599 - acc: 0.9091\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2564 - acc: 0.9103\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2534 - acc: 0.9103\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2509 - acc: 0.9112\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2486 - acc: 0.9110\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2467 - acc: 0.9118\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.2449 - acc: 0.9120\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2432 - acc: 0.9125\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2418 - acc: 0.9123\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2406 - acc: 0.9118\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 53us/step - loss: 0.2393 - acc: 0.9135\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2381 - acc: 0.9125\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2373 - acc: 0.9135\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2362 - acc: 0.9148\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2354 - acc: 0.9154\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2345 - acc: 0.9144\n",
      "2353/2353 [==============================] - 1s 452us/step\n",
      "4707/4707 [==============================] - 0s 38us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 611us/step - loss: 0.4948 - acc: 0.8275\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2929 - acc: 0.8989\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2440 - acc: 0.9120\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.2304 - acc: 0.9165\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.2241 - acc: 0.9188\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2197 - acc: 0.9233\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2161 - acc: 0.9227\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2134 - acc: 0.9244\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2106 - acc: 0.9237\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2093 - acc: 0.9246\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2071 - acc: 0.9254\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2043 - acc: 0.9280\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2038 - acc: 0.9271\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2014 - acc: 0.9265\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.1999 - acc: 0.9278\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.1974 - acc: 0.9290\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 93us/step - loss: 0.1960 - acc: 0.9280\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.1948 - acc: 0.9288\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.1929 - acc: 0.9307\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.1911 - acc: 0.9312\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 86us/step - loss: 0.1905 - acc: 0.9307\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 91us/step - loss: 0.1894 - acc: 0.9312\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.1882 - acc: 0.9331\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.1866 - acc: 0.9341\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1850 - acc: 0.9341\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 82us/step - loss: 0.1845 - acc: 0.9312\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 84us/step - loss: 0.1835 - acc: 0.9337\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.1813 - acc: 0.9343\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 89us/step - loss: 0.1809 - acc: 0.9337\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.1797 - acc: 0.9360\n",
      "2354/2354 [==============================] - 1s 511us/step\n",
      "4706/4706 [==============================] - 0s 42us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 619us/step - loss: 0.5052 - acc: 0.8194\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.3024 - acc: 0.8942\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2586 - acc: 0.9050\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2468 - acc: 0.9095\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2414 - acc: 0.9112\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2360 - acc: 0.9140\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2328 - acc: 0.9144\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2297 - acc: 0.9144\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2269 - acc: 0.9169\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2248 - acc: 0.9178\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2226 - acc: 0.9214\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2201 - acc: 0.9210\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2183 - acc: 0.9210\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2164 - acc: 0.9201\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2139 - acc: 0.9227\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.2129 - acc: 0.9220\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2108 - acc: 0.9235\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2098 - acc: 0.9252\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2080 - acc: 0.9242\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2069 - acc: 0.9246\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2049 - acc: 0.9263\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2038 - acc: 0.9252\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2019 - acc: 0.9263\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2015 - acc: 0.9269\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 102us/step - loss: 0.1996 - acc: 0.9271\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 95us/step - loss: 0.1990 - acc: 0.9280\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.1974 - acc: 0.9280\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 1s 124us/step - loss: 0.1958 - acc: 0.9297\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.1948 - acc: 0.9278\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.1939 - acc: 0.9284\n",
      "2353/2353 [==============================] - 1s 633us/step\n",
      "4707/4707 [==============================] - 0s 59us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 631us/step - loss: 0.4960 - acc: 0.8292\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2934 - acc: 0.8976\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2475 - acc: 0.9112\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2358 - acc: 0.9142\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2307 - acc: 0.9150\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2270 - acc: 0.9174\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2233 - acc: 0.9186\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2208 - acc: 0.9193\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2188 - acc: 0.9212\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2168 - acc: 0.9222\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2149 - acc: 0.9231\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2136 - acc: 0.9239\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2116 - acc: 0.9237\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2099 - acc: 0.9252\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2082 - acc: 0.9259\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2065 - acc: 0.9276\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2050 - acc: 0.9278\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2033 - acc: 0.9273\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2025 - acc: 0.9297\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2012 - acc: 0.9288\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1997 - acc: 0.9295\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.1978 - acc: 0.9295\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.1971 - acc: 0.9320\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.1957 - acc: 0.9301\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.1948 - acc: 0.9320\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.1931 - acc: 0.9324\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.1921 - acc: 0.9316\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.1911 - acc: 0.9318\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.1897 - acc: 0.9299\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.1883 - acc: 0.9307\n",
      "2353/2353 [==============================] - 1s 484us/step\n",
      "4707/4707 [==============================] - 0s 39us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 595us/step - loss: 0.3739 - acc: 0.8674\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2564 - acc: 0.9071\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2387 - acc: 0.9165\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2312 - acc: 0.9184\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2269 - acc: 0.9212\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2235 - acc: 0.9216\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2212 - acc: 0.9235\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2193 - acc: 0.9231\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.2178 - acc: 0.9235\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.2163 - acc: 0.9250\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2151 - acc: 0.9248\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2142 - acc: 0.9254\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2132 - acc: 0.9250: 0s - loss: 0.2103 - acc: 0.9\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 92us/step - loss: 0.2124 - acc: 0.9256\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2116 - acc: 0.9258\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 97us/step - loss: 0.2107 - acc: 0.9263\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2103 - acc: 0.9252\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2097 - acc: 0.9265\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 59us/step - loss: 0.2090 - acc: 0.9263\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 59us/step - loss: 0.2085 - acc: 0.9273\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 59us/step - loss: 0.2079 - acc: 0.9278\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 59us/step - loss: 0.2073 - acc: 0.9278\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.2069 - acc: 0.9275\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2065 - acc: 0.9282\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.2059 - acc: 0.9282\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2056 - acc: 0.9275\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 1s 123us/step - loss: 0.2051 - acc: 0.9286\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 1s 121us/step - loss: 0.2046 - acc: 0.9286\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2041 - acc: 0.9295\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.2038 - acc: 0.9292\n",
      "2354/2354 [==============================] - 1s 503us/step\n",
      "4706/4706 [==============================] - 0s 43us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 661us/step - loss: 0.3722 - acc: 0.8740\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2662 - acc: 0.9046\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2522 - acc: 0.9086\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 1s 106us/step - loss: 0.2454 - acc: 0.9108\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2413 - acc: 0.9116\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2382 - acc: 0.9114\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2356 - acc: 0.9131\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2337 - acc: 0.9135\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2322 - acc: 0.9137\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2306 - acc: 0.9152\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2294 - acc: 0.9161\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2284 - acc: 0.9150\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2274 - acc: 0.9157\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2263 - acc: 0.9165\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2256 - acc: 0.9186\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2247 - acc: 0.9169\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2240 - acc: 0.9182\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2232 - acc: 0.9188\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2225 - acc: 0.9193\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2220 - acc: 0.9199\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2213 - acc: 0.9201\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2207 - acc: 0.9201\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2202 - acc: 0.9208\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2197 - acc: 0.9201\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2192 - acc: 0.9214\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2186 - acc: 0.9216\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2181 - acc: 0.9225\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 89us/step - loss: 0.2176 - acc: 0.9225\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 91us/step - loss: 0.2172 - acc: 0.9222\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2167 - acc: 0.9225\n",
      "2353/2353 [==============================] - 1s 485us/step\n",
      "4707/4707 [==============================] - 0s 42us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 627us/step - loss: 0.3750 - acc: 0.8693\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2627 - acc: 0.9091\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2441 - acc: 0.9125\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2369 - acc: 0.9146\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2324 - acc: 0.9154\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2297 - acc: 0.9161\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2274 - acc: 0.9161\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2257 - acc: 0.9184\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2243 - acc: 0.9169\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2230 - acc: 0.9178\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2220 - acc: 0.9193\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2210 - acc: 0.9186\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2203 - acc: 0.9199\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2195 - acc: 0.9210\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2187 - acc: 0.9203\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2182 - acc: 0.9205\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2175 - acc: 0.9216\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2171 - acc: 0.9205\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2166 - acc: 0.9205\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2160 - acc: 0.9210\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2156 - acc: 0.9227\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2150 - acc: 0.9227\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2147 - acc: 0.9220\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2143 - acc: 0.9227\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2140 - acc: 0.9222\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2136 - acc: 0.9222\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2132 - acc: 0.9237\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2129 - acc: 0.9233\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2125 - acc: 0.9222\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2123 - acc: 0.9244\n",
      "2353/2353 [==============================] - 1s 496us/step\n",
      "4707/4707 [==============================] - 0s 39us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 676us/step - loss: 0.6000 - acc: 0.7707\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.3780 - acc: 0.8774\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2783 - acc: 0.9054\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.2506 - acc: 0.9116\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2391 - acc: 0.9148\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2331 - acc: 0.9169\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2296 - acc: 0.9176\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.2269 - acc: 0.9186\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2248 - acc: 0.9203\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2232 - acc: 0.9197\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2216 - acc: 0.9203\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2203 - acc: 0.9207\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2191 - acc: 0.9207\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2179 - acc: 0.9210\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2168 - acc: 0.9227\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2159 - acc: 0.9222\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2148 - acc: 0.9229\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2140 - acc: 0.9224\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2131 - acc: 0.9233\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2124 - acc: 0.9237\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2116 - acc: 0.9256\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2111 - acc: 0.9248\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2101 - acc: 0.9244\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2097 - acc: 0.9248\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2089 - acc: 0.9256\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2084 - acc: 0.9252\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2077 - acc: 0.9256\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2072 - acc: 0.9254\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2064 - acc: 0.9258\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2060 - acc: 0.9265\n",
      "2354/2354 [==============================] - 1s 589us/step\n",
      "4706/4706 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 639us/step - loss: 0.6092 - acc: 0.7395\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.4110 - acc: 0.8653\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.3013 - acc: 0.8953\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2671 - acc: 0.9035\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2550 - acc: 0.9057\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2487 - acc: 0.9097\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2447 - acc: 0.9110\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2421 - acc: 0.9127\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2401 - acc: 0.9125\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2383 - acc: 0.9142\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2368 - acc: 0.9142\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2354 - acc: 0.9140\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2342 - acc: 0.9154\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2330 - acc: 0.9140\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2320 - acc: 0.9165\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2310 - acc: 0.9146\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2302 - acc: 0.9165\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2292 - acc: 0.9163\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2282 - acc: 0.9161\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2274 - acc: 0.9167\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2268 - acc: 0.9169\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2258 - acc: 0.9171\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2250 - acc: 0.9171\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2245 - acc: 0.9174\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2237 - acc: 0.9171\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2230 - acc: 0.9184\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2222 - acc: 0.9182\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2217 - acc: 0.9191\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2209 - acc: 0.9199\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2202 - acc: 0.9197\n",
      "2353/2353 [==============================] - 1s 553us/step\n",
      "4707/4707 [==============================] - 0s 69us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 646us/step - loss: 0.6083 - acc: 0.7876\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.3698 - acc: 0.8829\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2741 - acc: 0.9055\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2497 - acc: 0.9093\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2404 - acc: 0.9123\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2355 - acc: 0.9133\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2325 - acc: 0.9152\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2300 - acc: 0.9146\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2284 - acc: 0.9163\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2272 - acc: 0.9178\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2259 - acc: 0.9165\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2249 - acc: 0.9191\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2239 - acc: 0.9188\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2229 - acc: 0.9178\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2221 - acc: 0.9199\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2215 - acc: 0.9188\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2206 - acc: 0.9186\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2197 - acc: 0.9188\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2192 - acc: 0.9218\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2185 - acc: 0.9201\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2177 - acc: 0.9208\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2171 - acc: 0.9203\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2165 - acc: 0.9216\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2159 - acc: 0.9220\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2154 - acc: 0.9222\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2147 - acc: 0.9231\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2142 - acc: 0.9239\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2136 - acc: 0.9239\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2129 - acc: 0.9246\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2125 - acc: 0.9242\n",
      "2353/2353 [==============================] - 1s 486us/step\n",
      "4707/4707 [==============================] - 0s 43us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 646us/step - loss: 0.5180 - acc: 0.8058\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2933 - acc: 0.8993\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2439 - acc: 0.9127\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2311 - acc: 0.9197\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2244 - acc: 0.9212\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2199 - acc: 0.9212\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2174 - acc: 0.9231\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2136 - acc: 0.9267\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 84us/step - loss: 0.2114 - acc: 0.9246\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2093 - acc: 0.9237\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2079 - acc: 0.9246\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2052 - acc: 0.9280\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2034 - acc: 0.9267\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2009 - acc: 0.9297\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2002 - acc: 0.9273\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.1972 - acc: 0.9290\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.1968 - acc: 0.9286\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.1947 - acc: 0.9301\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 84us/step - loss: 0.1929 - acc: 0.9320\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1919 - acc: 0.9301\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 83us/step - loss: 0.1902 - acc: 0.9301\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.1888 - acc: 0.9318\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 83us/step - loss: 0.1872 - acc: 0.9326\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1855 - acc: 0.9326\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.1851 - acc: 0.9324\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.1835 - acc: 0.9339\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.1817 - acc: 0.9333\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.1808 - acc: 0.9343\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.1794 - acc: 0.9360\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.1776 - acc: 0.9360\n",
      "2354/2354 [==============================] - 1s 503us/step\n",
      "4706/4706 [==============================] - 0s 41us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 648us/step - loss: 0.5356 - acc: 0.7527\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.3125 - acc: 0.8950\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2614 - acc: 0.9061\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2476 - acc: 0.9097\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2388 - acc: 0.9135\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2359 - acc: 0.9135\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2316 - acc: 0.9142\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2285 - acc: 0.9174\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2269 - acc: 0.9171\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.2240 - acc: 0.9167\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2220 - acc: 0.9180\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2201 - acc: 0.9199\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 91us/step - loss: 0.2183 - acc: 0.9208\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2161 - acc: 0.9208\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2141 - acc: 0.9225\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2120 - acc: 0.9227\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2098 - acc: 0.9212\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2080 - acc: 0.9227\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2066 - acc: 0.9216\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2041 - acc: 0.9269\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2021 - acc: 0.9265\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2008 - acc: 0.9248\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.1990 - acc: 0.9248\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.1973 - acc: 0.9284\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.1966 - acc: 0.9288\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.1949 - acc: 0.9297\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.1933 - acc: 0.9288\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.1917 - acc: 0.9295\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.1898 - acc: 0.9301\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.1890 - acc: 0.9310\n",
      "2353/2353 [==============================] - 1s 586us/step\n",
      "4707/4707 [==============================] - 0s 39us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 635us/step - loss: 0.5161 - acc: 0.8073\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2931 - acc: 0.8970\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2461 - acc: 0.9110\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2338 - acc: 0.9148\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2292 - acc: 0.9159\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2252 - acc: 0.9178\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2222 - acc: 0.9186\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2208 - acc: 0.9191\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2182 - acc: 0.9193\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2160 - acc: 0.9203\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2133 - acc: 0.9218\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2128 - acc: 0.9205\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2107 - acc: 0.9222\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2087 - acc: 0.9233\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2070 - acc: 0.9242\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2063 - acc: 0.9242\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2054 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2036 - acc: 0.9248\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2017 - acc: 0.9269\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2007 - acc: 0.9259\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.1991 - acc: 0.9273\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.1973 - acc: 0.9259\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.1958 - acc: 0.9299\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.1943 - acc: 0.9284\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.1934 - acc: 0.9280\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.1912 - acc: 0.9290\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1900 - acc: 0.9284\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.1884 - acc: 0.9301\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.1879 - acc: 0.9295\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.1864 - acc: 0.9314\n",
      "2353/2353 [==============================] - 1s 508us/step\n",
      "4707/4707 [==============================] - 0s 41us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 647us/step - loss: 0.4971 - acc: 0.8183\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2980 - acc: 0.9014\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2519 - acc: 0.9097\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2372 - acc: 0.9156\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2303 - acc: 0.9161\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2253 - acc: 0.9180\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 79us/step - loss: 0.2223 - acc: 0.9210\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 82us/step - loss: 0.2196 - acc: 0.9205\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2178 - acc: 0.9224\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2163 - acc: 0.9220\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2139 - acc: 0.9233\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 59us/step - loss: 0.2128 - acc: 0.9231\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.2117 - acc: 0.9218\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2097 - acc: 0.9246\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.2086 - acc: 0.9265\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.2072 - acc: 0.9250\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 87us/step - loss: 0.2063 - acc: 0.9256\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2049 - acc: 0.9261\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2042 - acc: 0.9252\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2025 - acc: 0.9258\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 96us/step - loss: 0.2014 - acc: 0.9275\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2004 - acc: 0.9288\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.1994 - acc: 0.9269\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1989 - acc: 0.9278\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.1978 - acc: 0.9286\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 60us/step - loss: 0.1963 - acc: 0.9288\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4706/4706 [==============================] - 0s 61us/step - loss: 0.1958 - acc: 0.9278\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 80us/step - loss: 0.1949 - acc: 0.9292\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.1937 - acc: 0.9286\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1931 - acc: 0.9303\n",
      "2354/2354 [==============================] - 1s 538us/step\n",
      "4706/4706 [==============================] - 0s 55us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 730us/step - loss: 0.5204 - acc: 0.7931\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.3299 - acc: 0.8885\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2749 - acc: 0.9018\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2574 - acc: 0.9076\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2489 - acc: 0.9101\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2436 - acc: 0.9112\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2405 - acc: 0.9127\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2368 - acc: 0.9142\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2343 - acc: 0.9161\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 101us/step - loss: 0.2316 - acc: 0.9157\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2300 - acc: 0.9165\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2279 - acc: 0.9157\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2266 - acc: 0.9176\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2244 - acc: 0.9188\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2230 - acc: 0.9205\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2214 - acc: 0.9214\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2201 - acc: 0.9212\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2190 - acc: 0.9201\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 59us/step - loss: 0.2182 - acc: 0.9212\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2167 - acc: 0.9227\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2152 - acc: 0.9220\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2145 - acc: 0.9210\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2132 - acc: 0.9250\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2120 - acc: 0.9237\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2115 - acc: 0.9237\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2103 - acc: 0.9239\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2091 - acc: 0.9244\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2088 - acc: 0.9225\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2074 - acc: 0.9244\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2066 - acc: 0.9244\n",
      "2353/2353 [==============================] - 1s 484us/step\n",
      "4707/4707 [==============================] - 0s 38us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 873us/step - loss: 0.5243 - acc: 0.7922\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.3208 - acc: 0.8897\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2622 - acc: 0.9082\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2450 - acc: 0.9129\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2373 - acc: 0.9133\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2324 - acc: 0.9161\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2289 - acc: 0.9169\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2271 - acc: 0.9157\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2241 - acc: 0.9169\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2230 - acc: 0.9167\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2211 - acc: 0.9163\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - ETA: 0s - loss: 0.2167 - acc: 0.923 - 0s 98us/step - loss: 0.2194 - acc: 0.9199\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 91us/step - loss: 0.2180 - acc: 0.9201\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2171 - acc: 0.9180\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2159 - acc: 0.9203\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2150 - acc: 0.9214\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2131 - acc: 0.9220\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2125 - acc: 0.9235\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2119 - acc: 0.9229\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2106 - acc: 0.9216\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2100 - acc: 0.9256\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2088 - acc: 0.9244\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2087 - acc: 0.9250\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2073 - acc: 0.9256\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2067 - acc: 0.9242\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2062 - acc: 0.9254\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 58us/step - loss: 0.2045 - acc: 0.9267\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 56us/step - loss: 0.2043 - acc: 0.9256\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 60us/step - loss: 0.2035 - acc: 0.9250\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 57us/step - loss: 0.2021 - acc: 0.9244\n",
      "2353/2353 [==============================] - 1s 553us/step\n",
      "4707/4707 [==============================] - 0s 41us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 4s 792us/step - loss: 0.4281 - acc: 0.8438\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 99us/step - loss: 0.2395 - acc: 0.9133\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 93us/step - loss: 0.2236 - acc: 0.9201\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2170 - acc: 0.9231\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2132 - acc: 0.9241\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 93us/step - loss: 0.2085 - acc: 0.9246\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 100us/step - loss: 0.2060 - acc: 0.9263\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 84us/step - loss: 0.2011 - acc: 0.9297\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 92us/step - loss: 0.1985 - acc: 0.9284\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 93us/step - loss: 0.1950 - acc: 0.9290\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 88us/step - loss: 0.1924 - acc: 0.9292\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.1885 - acc: 0.9333\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 105us/step - loss: 0.1864 - acc: 0.9322\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.1836 - acc: 0.9335\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 101us/step - loss: 0.1810 - acc: 0.9352\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 93us/step - loss: 0.1789 - acc: 0.9356\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 85us/step - loss: 0.1765 - acc: 0.9377\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 97us/step - loss: 0.1741 - acc: 0.9354\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 85us/step - loss: 0.1721 - acc: 0.9371\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 90us/step - loss: 0.1708 - acc: 0.9394\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 93us/step - loss: 0.1688 - acc: 0.9384\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1677 - acc: 0.9399\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 98us/step - loss: 0.1657 - acc: 0.9411\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1647 - acc: 0.9403\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1621 - acc: 0.9416\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.1613 - acc: 0.9416\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.1592 - acc: 0.9420\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.1582 - acc: 0.9441\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.1573 - acc: 0.9439\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.1548 - acc: 0.9465\n",
      "2354/2354 [==============================] - 1s 572us/step\n",
      "4706/4706 [==============================] - 0s 64us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 751us/step - loss: 0.4286 - acc: 0.8300\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2579 - acc: 0.9061\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2418 - acc: 0.9114\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2340 - acc: 0.9163\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2275 - acc: 0.9159\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - ETA: 0s - loss: 0.2242 - acc: 0.918 - 0s 88us/step - loss: 0.2233 - acc: 0.9188\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2199 - acc: 0.9208\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2155 - acc: 0.9208\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2113 - acc: 0.9225\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2080 - acc: 0.9239\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2039 - acc: 0.9267\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2009 - acc: 0.9276\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.1988 - acc: 0.9267\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.1960 - acc: 0.9273\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1931 - acc: 0.9284\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.1907 - acc: 0.9278\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.1887 - acc: 0.9293\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.1864 - acc: 0.9331\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.1840 - acc: 0.9329\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.1817 - acc: 0.9339\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.1798 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1776 - acc: 0.9371\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1766 - acc: 0.9380\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.1755 - acc: 0.9373\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1728 - acc: 0.9371\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.1713 - acc: 0.9371\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.1704 - acc: 0.9373\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.1685 - acc: 0.9388\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.1672 - acc: 0.9369\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.1654 - acc: 0.9395\n",
      "2353/2353 [==============================] - 1s 588us/step\n",
      "4707/4707 [==============================] - 0s 50us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 736us/step - loss: 0.4176 - acc: 0.8443\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2439 - acc: 0.9110\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2306 - acc: 0.9146\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2248 - acc: 0.9154\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2185 - acc: 0.9199\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2163 - acc: 0.9186\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2118 - acc: 0.9216\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2101 - acc: 0.9231\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2065 - acc: 0.9254\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2026 - acc: 0.9263\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2016 - acc: 0.9271\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.1991 - acc: 0.9282\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.1957 - acc: 0.9290\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.1934 - acc: 0.9310\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.1897 - acc: 0.9316\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.1888 - acc: 0.9322\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.1853 - acc: 0.9329\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.1845 - acc: 0.9339\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.1834 - acc: 0.9331\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 1s 113us/step - loss: 0.1811 - acc: 0.9331\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 98us/step - loss: 0.1796 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.1772 - acc: 0.9356\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.1752 - acc: 0.9333\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.1740 - acc: 0.9354\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.1724 - acc: 0.9365\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.1703 - acc: 0.9365\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.1684 - acc: 0.9361\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.1674 - acc: 0.9367\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.1660 - acc: 0.9361\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1643 - acc: 0.9399\n",
      "2353/2353 [==============================] - 1s 631us/step\n",
      "4707/4707 [==============================] - 0s 47us/step\n",
      "Epoch 1/30\n",
      "7060/7060 [==============================] - 3s 481us/step - loss: 0.4721 - acc: 0.8059\n",
      "Epoch 2/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.2695 - acc: 0.9051\n",
      "Epoch 3/30\n",
      "7060/7060 [==============================] - 1s 72us/step - loss: 0.2418 - acc: 0.9129\n",
      "Epoch 4/30\n",
      "7060/7060 [==============================] - 1s 73us/step - loss: 0.2334 - acc: 0.9171\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.2288 - acc: 0.9156\n",
      "Epoch 6/30\n",
      "7060/7060 [==============================] - 0s 65us/step - loss: 0.2256 - acc: 0.9180\n",
      "Epoch 7/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.2225 - acc: 0.9186\n",
      "Epoch 8/30\n",
      "7060/7060 [==============================] - 1s 79us/step - loss: 0.2213 - acc: 0.9211\n",
      "Epoch 9/30\n",
      "7060/7060 [==============================] - 1s 76us/step - loss: 0.2186 - acc: 0.9203\n",
      "Epoch 10/30\n",
      "7060/7060 [==============================] - 0s 67us/step - loss: 0.2156 - acc: 0.9224\n",
      "Epoch 11/30\n",
      "7060/7060 [==============================] - 1s 79us/step - loss: 0.2139 - acc: 0.9237\n",
      "Epoch 12/30\n",
      "7060/7060 [==============================] - 1s 78us/step - loss: 0.2118 - acc: 0.9248\n",
      "Epoch 13/30\n",
      "7060/7060 [==============================] - 1s 72us/step - loss: 0.2101 - acc: 0.9251\n",
      "Epoch 14/30\n",
      "7060/7060 [==============================] - 1s 78us/step - loss: 0.2075 - acc: 0.9256\n",
      "Epoch 15/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.2071 - acc: 0.9254\n",
      "Epoch 16/30\n",
      "7060/7060 [==============================] - 1s 75us/step - loss: 0.2040 - acc: 0.9265\n",
      "Epoch 17/30\n",
      "7060/7060 [==============================] - 1s 73us/step - loss: 0.2027 - acc: 0.9262\n",
      "Epoch 18/30\n",
      "7060/7060 [==============================] - 1s 76us/step - loss: 0.2008 - acc: 0.9280\n",
      "Epoch 19/30\n",
      "7060/7060 [==============================] - 1s 75us/step - loss: 0.1990 - acc: 0.9278\n",
      "Epoch 20/30\n",
      "7060/7060 [==============================] - 1s 74us/step - loss: 0.1979 - acc: 0.9273\n",
      "Epoch 21/30\n",
      "7060/7060 [==============================] - 1s 71us/step - loss: 0.1962 - acc: 0.9279\n",
      "Epoch 22/30\n",
      "7060/7060 [==============================] - 1s 76us/step - loss: 0.1949 - acc: 0.9295\n",
      "Epoch 23/30\n",
      "7060/7060 [==============================] - 1s 74us/step - loss: 0.1933 - acc: 0.9297\n",
      "Epoch 24/30\n",
      "7060/7060 [==============================] - 1s 76us/step - loss: 0.1919 - acc: 0.9297\n",
      "Epoch 25/30\n",
      "7060/7060 [==============================] - 1s 82us/step - loss: 0.1913 - acc: 0.9295\n",
      "Epoch 26/30\n",
      "7060/7060 [==============================] - 1s 83us/step - loss: 0.1890 - acc: 0.9317\n",
      "Epoch 27/30\n",
      "7060/7060 [==============================] - 1s 82us/step - loss: 0.1877 - acc: 0.9305\n",
      "Epoch 28/30\n",
      "7060/7060 [==============================] - ETA: 0s - loss: 0.1874 - acc: 0.928 - 1s 73us/step - loss: 0.1874 - acc: 0.9295\n",
      "Epoch 29/30\n",
      "7060/7060 [==============================] - 1s 74us/step - loss: 0.1851 - acc: 0.9317\n",
      "Epoch 30/30\n",
      "7060/7060 [==============================] - 1s 71us/step - loss: 0.1842 - acc: 0.9320\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=new_model_opt, epochs=30, batch_size=40, verbose=1)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.917564 using {'optimizer': 'Adam'}\n",
      "0.911473 (0.008547) with: {'optimizer': 'SGD'}\n",
      "0.917564 (0.006231) with: {'optimizer': 'RMSprop'}\n",
      "0.914164 (0.006605) with: {'optimizer': 'Adagrad'}\n",
      "0.913598 (0.008215) with: {'optimizer': 'Adadelta'}\n",
      "0.917564 (0.006243) with: {'optimizer': 'Adam'}\n",
      "0.914589 (0.007988) with: {'optimizer': 'Adamax'}\n",
      "0.913739 (0.005718) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Neuron Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model_act(activation):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=35, kernel_initializer='normal', activation=activation))\n",
    "    #if we want a hidden layer :\n",
    "    #model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 709us/step - loss: 0.6829 - acc: 0.7384\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 82us/step - loss: 0.6414 - acc: 0.8417\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.5806 - acc: 0.8825\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 80us/step - loss: 0.5181 - acc: 0.8991\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.4668 - acc: 0.9067\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.4271 - acc: 0.9101\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 79us/step - loss: 0.3961 - acc: 0.9137: 0s - loss: 0.4115 - acc: \n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.3707 - acc: 0.9176\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 80us/step - loss: 0.3499 - acc: 0.9193\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.3322 - acc: 0.9199\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.3174 - acc: 0.9229\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.3047 - acc: 0.9229\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2937 - acc: 0.9261\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 83us/step - loss: 0.2842 - acc: 0.9250\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2758 - acc: 0.9265\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 82us/step - loss: 0.2688 - acc: 0.9271\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.2624 - acc: 0.9275\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 89us/step - loss: 0.2568 - acc: 0.9280\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 88us/step - loss: 0.2518 - acc: 0.9286\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 87us/step - loss: 0.2472 - acc: 0.9292\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 1s 123us/step - loss: 0.2432 - acc: 0.9297\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 105us/step - loss: 0.2393 - acc: 0.9297\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 88us/step - loss: 0.2358 - acc: 0.9292\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.2327 - acc: 0.9305\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2299 - acc: 0.9303\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2274 - acc: 0.9301\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2249 - acc: 0.9316\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2228 - acc: 0.9312\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 83us/step - loss: 0.2206 - acc: 0.9329\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2186 - acc: 0.9329\n",
      "2354/2354 [==============================] - 2s 695us/step\n",
      "4706/4706 [==============================] - 0s 86us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 794us/step - loss: 0.6843 - acc: 0.6841\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.6442 - acc: 0.8311\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.5872 - acc: 0.8804\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.5319 - acc: 0.8967\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.4870 - acc: 0.9027\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.4506 - acc: 0.9067\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.4208 - acc: 0.9084\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.3961 - acc: 0.9112\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 98us/step - loss: 0.3751 - acc: 0.9129\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.3568 - acc: 0.9144\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.3410 - acc: 0.9154\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.3269 - acc: 0.9167\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.3144 - acc: 0.9193\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 106us/step - loss: 0.3036 - acc: 0.9184\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2942 - acc: 0.9199\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2862 - acc: 0.9203\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2792 - acc: 0.9210\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2732 - acc: 0.9210\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2680 - acc: 0.9225\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2630 - acc: 0.9229\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2588 - acc: 0.9239\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2548 - acc: 0.9248\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2512 - acc: 0.9259\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2477 - acc: 0.9254\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2446 - acc: 0.9263\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2413 - acc: 0.9271\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2383 - acc: 0.9276\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2357 - acc: 0.9263\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2331 - acc: 0.9267\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.2308 - acc: 0.9267\n",
      "2353/2353 [==============================] - 2s 649us/step\n",
      "4707/4707 [==============================] - 0s 47us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 769us/step - loss: 0.6823 - acc: 0.7374\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.6397 - acc: 0.8398\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.5822 - acc: 0.8753\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.5249 - acc: 0.8974\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.4752 - acc: 0.9033\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.4359 - acc: 0.9067\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.4046 - acc: 0.9097\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.3790 - acc: 0.9131\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.3579 - acc: 0.9152\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.3402 - acc: 0.9161\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.3251 - acc: 0.9174\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.3123 - acc: 0.9180\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.3013 - acc: 0.9186\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2918 - acc: 0.9193\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2836 - acc: 0.9195\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2763 - acc: 0.9210\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2698 - acc: 0.9218\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2638 - acc: 0.9218\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2586 - acc: 0.9222\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2538 - acc: 0.9235\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2495 - acc: 0.9229\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2456 - acc: 0.9248\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2419 - acc: 0.9248\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2386 - acc: 0.9263\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2357 - acc: 0.9259\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2328 - acc: 0.9261\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2302 - acc: 0.9276\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2278 - acc: 0.9269\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2259 - acc: 0.9282\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2236 - acc: 0.9273\n",
      "2353/2353 [==============================] - 1s 630us/step\n",
      "4707/4707 [==============================] - 0s 49us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 4s 773us/step - loss: 0.5508 - acc: 0.7903\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.3405 - acc: 0.8804\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2597 - acc: 0.9103\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2400 - acc: 0.9159\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2336 - acc: 0.9150\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2312 - acc: 0.9178\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2295 - acc: 0.9203\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2281 - acc: 0.9178\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2267 - acc: 0.9210\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2258 - acc: 0.9201\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2239 - acc: 0.9218\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2232 - acc: 0.9210\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2222 - acc: 0.9197\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2220 - acc: 0.9218\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2203 - acc: 0.9224\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2199 - acc: 0.9214\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2189 - acc: 0.9201\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2186 - acc: 0.9218\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2182 - acc: 0.9231\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2170 - acc: 0.9224\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2172 - acc: 0.9220\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2153 - acc: 0.9222\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2148 - acc: 0.9224\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2145 - acc: 0.9205\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2140 - acc: 0.9229\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2131 - acc: 0.9233\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2124 - acc: 0.9239\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2121 - acc: 0.9222\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2107 - acc: 0.9241\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 85us/step - loss: 0.2104 - acc: 0.9227\n",
      "2354/2354 [==============================] - 1s 580us/step\n",
      "4706/4706 [==============================] - 0s 45us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 719us/step - loss: 0.5574 - acc: 0.7512\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.3510 - acc: 0.8791\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2794 - acc: 0.9014\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2600 - acc: 0.9059\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2547 - acc: 0.9067\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2506 - acc: 0.9091\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2486 - acc: 0.9097\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2470 - acc: 0.9108\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2444 - acc: 0.9093\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2429 - acc: 0.9114\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2411 - acc: 0.9106\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2399 - acc: 0.9099\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2390 - acc: 0.9108\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2375 - acc: 0.9131\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 89us/step - loss: 0.2370 - acc: 0.9114\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2352 - acc: 0.9129\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2339 - acc: 0.9133\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2332 - acc: 0.9120\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2322 - acc: 0.9108\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2316 - acc: 0.9137\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2305 - acc: 0.9144\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2297 - acc: 0.9152\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2291 - acc: 0.9133\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2280 - acc: 0.9140\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2277 - acc: 0.9161\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2264 - acc: 0.9150\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 92us/step - loss: 0.2260 - acc: 0.9159\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2244 - acc: 0.9171\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.2240 - acc: 0.9165\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 96us/step - loss: 0.2229 - acc: 0.9193\n",
      "2353/2353 [==============================] - 1s 605us/step\n",
      "4707/4707 [==============================] - 0s 67us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 784us/step - loss: 0.5494 - acc: 0.7752\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.3411 - acc: 0.8821\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2645 - acc: 0.9061\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2462 - acc: 0.9106\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2399 - acc: 0.9118\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2372 - acc: 0.9118\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2352 - acc: 0.9101\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2333 - acc: 0.9148\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2319 - acc: 0.9146\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2311 - acc: 0.9159\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2298 - acc: 0.9131\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2286 - acc: 0.9161\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2278 - acc: 0.9154\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2268 - acc: 0.9157\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2258 - acc: 0.9154\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2245 - acc: 0.9146\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2236 - acc: 0.9174\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2234 - acc: 0.9167\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2229 - acc: 0.9161\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2215 - acc: 0.9191\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2211 - acc: 0.9180\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2200 - acc: 0.9169\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 92us/step - loss: 0.2194 - acc: 0.9186\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2186 - acc: 0.9186\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2183 - acc: 0.9188\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2171 - acc: 0.9205\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2165 - acc: 0.9197\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2160 - acc: 0.9201\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2150 - acc: 0.9208\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2147 - acc: 0.9216\n",
      "2353/2353 [==============================] - 1s 604us/step\n",
      "4707/4707 [==============================] - 0s 47us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 4s 849us/step - loss: 0.5084 - acc: 0.8047\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 86us/step - loss: 0.2955 - acc: 0.8978\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2496 - acc: 0.9110\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2398 - acc: 0.9163\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2339 - acc: 0.9190\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2322 - acc: 0.9207\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2303 - acc: 0.9207\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2290 - acc: 0.9210\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2276 - acc: 0.9201\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2267 - acc: 0.9203\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2251 - acc: 0.9227\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2245 - acc: 0.9205\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2233 - acc: 0.9229\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2221 - acc: 0.9218\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2211 - acc: 0.9216\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2197 - acc: 0.9222\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2196 - acc: 0.9235\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2184 - acc: 0.9248\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2169 - acc: 0.9235\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2168 - acc: 0.9248\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 97us/step - loss: 0.2152 - acc: 0.9244\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 105us/step - loss: 0.2145 - acc: 0.9244\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2139 - acc: 0.9235\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2134 - acc: 0.9244\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 82us/step - loss: 0.2115 - acc: 0.9248\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2101 - acc: 0.9237\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 62us/step - loss: 0.2096 - acc: 0.9239\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2095 - acc: 0.9250\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 63us/step - loss: 0.2078 - acc: 0.9256\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2066 - acc: 0.9265\n",
      "2354/2354 [==============================] - 1s 539us/step\n",
      "4706/4706 [==============================] - 0s 42us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 713us/step - loss: 0.5216 - acc: 0.7916\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.3163 - acc: 0.8876\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2695 - acc: 0.9042\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2584 - acc: 0.9074\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2541 - acc: 0.9078\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2515 - acc: 0.9103\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2497 - acc: 0.9101\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2472 - acc: 0.9127\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2464 - acc: 0.9129\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2451 - acc: 0.9127\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2438 - acc: 0.9135\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2429 - acc: 0.9144\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2413 - acc: 0.9144\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2404 - acc: 0.9140\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2389 - acc: 0.9135\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2383 - acc: 0.9157\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2379 - acc: 0.9137\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2360 - acc: 0.9146\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2353 - acc: 0.9161\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2342 - acc: 0.9188\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2328 - acc: 0.9169\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2330 - acc: 0.9163\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2311 - acc: 0.9163\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2303 - acc: 0.9182: 0s - loss: 0.2301 - acc: 0\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2295 - acc: 0.9191\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2286 - acc: 0.9201\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2268 - acc: 0.9199\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2268 - acc: 0.9201\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2258 - acc: 0.9182\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2245 - acc: 0.9193\n",
      "2353/2353 [==============================] - 1s 574us/step\n",
      "4707/4707 [==============================] - 0s 42us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 3s 718us/step - loss: 0.5089 - acc: 0.7988\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2994 - acc: 0.8967\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2543 - acc: 0.9084\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2436 - acc: 0.9123\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2396 - acc: 0.9140\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2373 - acc: 0.9161\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2354 - acc: 0.9159\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2341 - acc: 0.9131\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2325 - acc: 0.9167\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2311 - acc: 0.9167\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2303 - acc: 0.9171\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2292 - acc: 0.9159\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2282 - acc: 0.9174\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2278 - acc: 0.9169\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2270 - acc: 0.9176\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2256 - acc: 0.9210\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2259 - acc: 0.9184\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2250 - acc: 0.9191\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2240 - acc: 0.9186\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2226 - acc: 0.9199\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2216 - acc: 0.9195\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2219 - acc: 0.9218\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2210 - acc: 0.9210\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2200 - acc: 0.9205\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2193 - acc: 0.9216\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2192 - acc: 0.9220\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2180 - acc: 0.9231\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2170 - acc: 0.9222\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2160 - acc: 0.9229\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2164 - acc: 0.9242\n",
      "2353/2353 [==============================] - 1s 568us/step\n",
      "4707/4707 [==============================] - 0s 43us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 711us/step - loss: 0.5196 - acc: 0.7794\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.3050 - acc: 0.9001\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2524 - acc: 0.9129\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2337 - acc: 0.9216\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2260 - acc: 0.9224\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2223 - acc: 0.9222\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2176 - acc: 0.9233\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2142 - acc: 0.9246\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2129 - acc: 0.9246\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2095 - acc: 0.9269\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2067 - acc: 0.9269\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2049 - acc: 0.9284\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2032 - acc: 0.9288\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2008 - acc: 0.9290\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1985 - acc: 0.9297\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1961 - acc: 0.9295\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1948 - acc: 0.9312\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1922 - acc: 0.9303\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1911 - acc: 0.9307\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1880 - acc: 0.9339\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1871 - acc: 0.9333\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1846 - acc: 0.9335\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1847 - acc: 0.9360\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.1814 - acc: 0.9339\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.1799 - acc: 0.9363\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1787 - acc: 0.9350\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.1765 - acc: 0.9373\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.1750 - acc: 0.9375\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.1729 - acc: 0.9375\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.1721 - acc: 0.9382\n",
      "2354/2354 [==============================] - 1s 613us/step\n",
      "4706/4706 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 790us/step - loss: 0.5299 - acc: 0.8105\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.3093 - acc: 0.8904\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2613 - acc: 0.9063\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2477 - acc: 0.9086\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2410 - acc: 0.9114\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2359 - acc: 0.9133\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2320 - acc: 0.9129\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2291 - acc: 0.9163\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2257 - acc: 0.9182\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2239 - acc: 0.9188\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2210 - acc: 0.9191\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2189 - acc: 0.9210\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2166 - acc: 0.9208\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2145 - acc: 0.9218\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2122 - acc: 0.9231\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2105 - acc: 0.9252\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2090 - acc: 0.9222\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2059 - acc: 0.9235\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2051 - acc: 0.9254\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2035 - acc: 0.9252\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2013 - acc: 0.9250\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2001 - acc: 0.9269\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1991 - acc: 0.9282\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1976 - acc: 0.9263\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1955 - acc: 0.9280\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.1943 - acc: 0.9280\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.1930 - acc: 0.9295\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1910 - acc: 0.9301\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.1901 - acc: 0.9297\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.1891 - acc: 0.9305\n",
      "2353/2353 [==============================] - 2s 646us/step\n",
      "4707/4707 [==============================] - 0s 63us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 811us/step - loss: 0.5333 - acc: 0.7801\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.3035 - acc: 0.8978\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2487 - acc: 0.9123\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2355 - acc: 0.9150\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2292 - acc: 0.9137\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2248 - acc: 0.9169\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2219 - acc: 0.9208\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2195 - acc: 0.9182\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2177 - acc: 0.9199\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2159 - acc: 0.9222\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2134 - acc: 0.9218\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2127 - acc: 0.9218\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2108 - acc: 0.9220\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2091 - acc: 0.9246\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2077 - acc: 0.9227\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2064 - acc: 0.9261\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2047 - acc: 0.9252\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2037 - acc: 0.9273\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2019 - acc: 0.9261\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.2016 - acc: 0.9248\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.1993 - acc: 0.9299\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1985 - acc: 0.9284\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.1971 - acc: 0.9282\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1958 - acc: 0.9278\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1941 - acc: 0.9295\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1926 - acc: 0.9290\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.1914 - acc: 0.9299\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1899 - acc: 0.9327\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1882 - acc: 0.9329\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 65us/step - loss: 0.1869 - acc: 0.9320\n",
      "2353/2353 [==============================] - 1s 578us/step\n",
      "4707/4707 [==============================] - 0s 43us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 3s 714us/step - loss: 0.4868 - acc: 0.8124\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2846 - acc: 0.8986\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2462 - acc: 0.9154\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2405 - acc: 0.9173\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2385 - acc: 0.9161\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2369 - acc: 0.9197\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2343 - acc: 0.9205\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2338 - acc: 0.9207\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2339 - acc: 0.9180\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2309 - acc: 0.9214\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2293 - acc: 0.9193\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 77us/step - loss: 0.2299 - acc: 0.9207\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 86us/step - loss: 0.2281 - acc: 0.9203\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2269 - acc: 0.9210\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2261 - acc: 0.9218\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2255 - acc: 0.9210\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2242 - acc: 0.9205\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2221 - acc: 0.9239\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 84us/step - loss: 0.2209 - acc: 0.9235\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2207 - acc: 0.9222\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.2190 - acc: 0.9235\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2177 - acc: 0.9224\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.2165 - acc: 0.9222\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 82us/step - loss: 0.2164 - acc: 0.9237\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2147 - acc: 0.9256\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.2137 - acc: 0.9246\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 83us/step - loss: 0.2121 - acc: 0.9224\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2116 - acc: 0.9248\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 79us/step - loss: 0.2101 - acc: 0.9261\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2091 - acc: 0.9248\n",
      "2354/2354 [==============================] - 2s 722us/step\n",
      "4706/4706 [==============================] - 0s 59us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - ETA: 0s - loss: 0.5100 - acc: 0.778 - 4s 858us/step - loss: 0.4938 - acc: 0.7890\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.3005 - acc: 0.8938\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2667 - acc: 0.9052\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2602 - acc: 0.9052\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2576 - acc: 0.9072\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2554 - acc: 0.9076\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2529 - acc: 0.9099\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2515 - acc: 0.9097\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2499 - acc: 0.9103\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2495 - acc: 0.9086\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2488 - acc: 0.9065\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2464 - acc: 0.9095\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2449 - acc: 0.9106: 0s - loss: 0.2815 - acc: 0.894 - ETA: 0s - loss: 0.2595 - acc: 0\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2440 - acc: 0.9103\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2433 - acc: 0.9131\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2414 - acc: 0.9133\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2398 - acc: 0.9157\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2391 - acc: 0.9146\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2379 - acc: 0.9137\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2365 - acc: 0.9152\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2362 - acc: 0.9131\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2335 - acc: 0.9163\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2332 - acc: 0.9142\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2316 - acc: 0.9159\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2311 - acc: 0.9176\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2307 - acc: 0.9163\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2281 - acc: 0.9188\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.2272 - acc: 0.9186\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2259 - acc: 0.9178\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2245 - acc: 0.9188\n",
      "2353/2353 [==============================] - 2s 690us/step\n",
      "4707/4707 [==============================] - 0s 68us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 881us/step - loss: 0.4885 - acc: 0.7994\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2907 - acc: 0.8989\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2529 - acc: 0.9097\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2458 - acc: 0.9120\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2426 - acc: 0.9137\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2410 - acc: 0.9137\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2391 - acc: 0.9137\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2367 - acc: 0.9127\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2360 - acc: 0.9163\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2341 - acc: 0.9159\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2332 - acc: 0.9140\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2315 - acc: 0.9169\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2308 - acc: 0.9137\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2283 - acc: 0.9174\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2274 - acc: 0.9140\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2257 - acc: 0.9163\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2243 - acc: 0.9197\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2240 - acc: 0.9178\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2222 - acc: 0.9186\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2208 - acc: 0.9182\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2202 - acc: 0.9218\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2191 - acc: 0.9227\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2176 - acc: 0.9216\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2165 - acc: 0.9205\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2150 - acc: 0.9227\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2139 - acc: 0.9220\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2129 - acc: 0.9244\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2118 - acc: 0.9214\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2111 - acc: 0.9248\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2098 - acc: 0.9229\n",
      "2353/2353 [==============================] - 1s 592us/step\n",
      "4707/4707 [==============================] - 0s 51us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 4s 844us/step - loss: 0.6235 - acc: 0.7295\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.4293 - acc: 0.8538\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.3108 - acc: 0.9008\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2653 - acc: 0.9122\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2492 - acc: 0.9169\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2436 - acc: 0.9161\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2412 - acc: 0.9148\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2391 - acc: 0.9167\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2378 - acc: 0.9152\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2371 - acc: 0.9173\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2361 - acc: 0.9184\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2353 - acc: 0.9188\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2347 - acc: 0.9190\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2349 - acc: 0.9193\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2338 - acc: 0.9205\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2335 - acc: 0.9201\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2330 - acc: 0.9201\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2322 - acc: 0.9188\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2316 - acc: 0.9193\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2312 - acc: 0.9205\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 79us/step - loss: 0.2310 - acc: 0.9205\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.2303 - acc: 0.9195\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 81us/step - loss: 0.2299 - acc: 0.9188\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2298 - acc: 0.9199\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.2283 - acc: 0.9205\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2283 - acc: 0.9218\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2277 - acc: 0.9212\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2267 - acc: 0.9197\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2262 - acc: 0.9224\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2255 - acc: 0.9201\n",
      "2354/2354 [==============================] - 1s 636us/step\n",
      "4706/4706 [==============================] - 0s 41us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 757us/step - loss: 0.6197 - acc: 0.7340\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.4385 - acc: 0.8443\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.3292 - acc: 0.8893\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2856 - acc: 0.9021\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2709 - acc: 0.9031\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2650 - acc: 0.9042\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2620 - acc: 0.9055\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2614 - acc: 0.9057\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2590 - acc: 0.9061\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2579 - acc: 0.9074\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2566 - acc: 0.9093\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2560 - acc: 0.9074\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2547 - acc: 0.9103\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2544 - acc: 0.9086\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 64us/step - loss: 0.2536 - acc: 0.9093\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2528 - acc: 0.9089\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2519 - acc: 0.9095\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2506 - acc: 0.9089\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2500 - acc: 0.9112\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2497 - acc: 0.9116\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2486 - acc: 0.9101\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 61us/step - loss: 0.2479 - acc: 0.9103\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2474 - acc: 0.9118\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2462 - acc: 0.9120\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2460 - acc: 0.9112\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2452 - acc: 0.9099\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2443 - acc: 0.9116\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2438 - acc: 0.9129\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 63us/step - loss: 0.2432 - acc: 0.9110\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 62us/step - loss: 0.2425 - acc: 0.9118\n",
      "2353/2353 [==============================] - 1s 609us/step\n",
      "4707/4707 [==============================] - 0s 53us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 900us/step - loss: 0.6084 - acc: 0.7589\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 92us/step - loss: 0.4266 - acc: 0.8551\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 1s 110us/step - loss: 0.3165 - acc: 0.8991\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 97us/step - loss: 0.2707 - acc: 0.9097\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 104us/step - loss: 0.2562 - acc: 0.9080\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2498 - acc: 0.9103\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2466 - acc: 0.9112\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2449 - acc: 0.9114\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2436 - acc: 0.9116\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 105us/step - loss: 0.2427 - acc: 0.9125\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 93us/step - loss: 0.2412 - acc: 0.9116\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2407 - acc: 0.9142\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2396 - acc: 0.9135\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2385 - acc: 0.9137\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2381 - acc: 0.9142\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2370 - acc: 0.9148\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2362 - acc: 0.9144\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 66us/step - loss: 0.2351 - acc: 0.9127\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2343 - acc: 0.9127\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2338 - acc: 0.9157\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2325 - acc: 0.9142\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2319 - acc: 0.9144\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 91us/step - loss: 0.2314 - acc: 0.9140\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 67us/step - loss: 0.2308 - acc: 0.9154\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2301 - acc: 0.9150\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2294 - acc: 0.9129\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2292 - acc: 0.9154\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2283 - acc: 0.9163\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2279 - acc: 0.9161\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2277 - acc: 0.9137\n",
      "2353/2353 [==============================] - 1s 593us/step\n",
      "4707/4707 [==============================] - 0s 43us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 4s 772us/step - loss: 0.6240 - acc: 0.7367\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 80us/step - loss: 0.4412 - acc: 0.8377\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.3273 - acc: 0.8872\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2741 - acc: 0.9071\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 64us/step - loss: 0.2526 - acc: 0.9139\n",
      "Epoch 6/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2441 - acc: 0.9148\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2395 - acc: 0.9137\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 80us/step - loss: 0.2370 - acc: 0.9173\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 79us/step - loss: 0.2360 - acc: 0.9176\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2342 - acc: 0.9184\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2331 - acc: 0.9176\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2327 - acc: 0.9188\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2320 - acc: 0.9193\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2315 - acc: 0.9180\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2313 - acc: 0.9199\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2307 - acc: 0.9212\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2303 - acc: 0.9203\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2301 - acc: 0.9195\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 68us/step - loss: 0.2291 - acc: 0.9195\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2294 - acc: 0.9210\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2295 - acc: 0.9212\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2286 - acc: 0.9212\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 66us/step - loss: 0.2284 - acc: 0.9201\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 65us/step - loss: 0.2279 - acc: 0.9197\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2282 - acc: 0.9222\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2275 - acc: 0.9203\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 69us/step - loss: 0.2274 - acc: 0.9216\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 67us/step - loss: 0.2268 - acc: 0.9205\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2267 - acc: 0.9207\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2268 - acc: 0.9218\n",
      "2354/2354 [==============================] - 2s 661us/step\n",
      "4706/4706 [==============================] - 0s 53us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 919us/step - loss: 0.6172 - acc: 0.7187\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.4404 - acc: 0.8349\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.3386 - acc: 0.8838\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2935 - acc: 0.8995\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2746 - acc: 0.9029\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2663 - acc: 0.9042\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2622 - acc: 0.9052\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2598 - acc: 0.9074\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2584 - acc: 0.9050\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2560 - acc: 0.9069\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2551 - acc: 0.9103\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2537 - acc: 0.9089\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2528 - acc: 0.9082\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2517 - acc: 0.9093\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2517 - acc: 0.9086\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2509 - acc: 0.9080\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2495 - acc: 0.9108\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2489 - acc: 0.9091\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2485 - acc: 0.9099\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2475 - acc: 0.9097\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2472 - acc: 0.9114\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2466 - acc: 0.9091\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2464 - acc: 0.9103\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2454 - acc: 0.9103\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2450 - acc: 0.9091\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2448 - acc: 0.9099\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2440 - acc: 0.9114\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2437 - acc: 0.9106\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2427 - acc: 0.9114\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2430 - acc: 0.9110\n",
      "2353/2353 [==============================] - 2s 639us/step\n",
      "4707/4707 [==============================] - 0s 48us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 861us/step - loss: 0.6176 - acc: 0.7429\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.4340 - acc: 0.8436\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.3249 - acc: 0.8902\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2767 - acc: 0.9052\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2578 - acc: 0.9097\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2495 - acc: 0.9110\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2456 - acc: 0.9110\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2422 - acc: 0.9116\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2406 - acc: 0.9116\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2389 - acc: 0.9125\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2376 - acc: 0.9129\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2366 - acc: 0.9129\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2359 - acc: 0.9150\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2351 - acc: 0.9137\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2344 - acc: 0.9165\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2339 - acc: 0.9142\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2333 - acc: 0.9148\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2330 - acc: 0.9165\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2323 - acc: 0.9159\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2317 - acc: 0.9174\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2315 - acc: 0.9165\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2308 - acc: 0.9144\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2306 - acc: 0.9159\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2297 - acc: 0.9152\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2293 - acc: 0.9167\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2292 - acc: 0.9176\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2289 - acc: 0.9163\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2287 - acc: 0.9161\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2284 - acc: 0.9161\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 75us/step - loss: 0.2273 - acc: 0.9174\n",
      "2353/2353 [==============================] - 2s 642us/step\n",
      "4707/4707 [==============================] - 0s 47us/step\n",
      "Epoch 1/30\n",
      "4706/4706 [==============================] - 4s 799us/step - loss: 0.4823 - acc: 0.8064\n",
      "Epoch 2/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2860 - acc: 0.9010\n",
      "Epoch 3/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2486 - acc: 0.9125\n",
      "Epoch 4/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2436 - acc: 0.9144\n",
      "Epoch 5/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2416 - acc: 0.9144\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2415 - acc: 0.9167: 0s - loss: 0.2297 - acc: 0\n",
      "Epoch 7/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2405 - acc: 0.9186\n",
      "Epoch 8/30\n",
      "4706/4706 [==============================] - 0s 71us/step - loss: 0.2411 - acc: 0.9173\n",
      "Epoch 9/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2422 - acc: 0.9180\n",
      "Epoch 10/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2406 - acc: 0.9180\n",
      "Epoch 11/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2403 - acc: 0.9188\n",
      "Epoch 12/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2407 - acc: 0.9169\n",
      "Epoch 13/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2400 - acc: 0.9186\n",
      "Epoch 14/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2407 - acc: 0.9165\n",
      "Epoch 15/30\n",
      "4706/4706 [==============================] - 0s 70us/step - loss: 0.2404 - acc: 0.9184\n",
      "Epoch 16/30\n",
      "4706/4706 [==============================] - 0s 72us/step - loss: 0.2404 - acc: 0.9169\n",
      "Epoch 17/30\n",
      "4706/4706 [==============================] - 1s 109us/step - loss: 0.2400 - acc: 0.9188\n",
      "Epoch 18/30\n",
      "4706/4706 [==============================] - 0s 88us/step - loss: 0.2402 - acc: 0.9188\n",
      "Epoch 19/30\n",
      "4706/4706 [==============================] - 0s 78us/step - loss: 0.2406 - acc: 0.9182\n",
      "Epoch 20/30\n",
      "4706/4706 [==============================] - 0s 92us/step - loss: 0.2399 - acc: 0.9197\n",
      "Epoch 21/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2396 - acc: 0.9176\n",
      "Epoch 22/30\n",
      "4706/4706 [==============================] - 0s 98us/step - loss: 0.2396 - acc: 0.9203\n",
      "Epoch 23/30\n",
      "4706/4706 [==============================] - 0s 87us/step - loss: 0.2402 - acc: 0.9182\n",
      "Epoch 24/30\n",
      "4706/4706 [==============================] - 0s 76us/step - loss: 0.2391 - acc: 0.9197\n",
      "Epoch 25/30\n",
      "4706/4706 [==============================] - 0s 84us/step - loss: 0.2410 - acc: 0.9159\n",
      "Epoch 26/30\n",
      "4706/4706 [==============================] - 0s 75us/step - loss: 0.2396 - acc: 0.9184\n",
      "Epoch 27/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2400 - acc: 0.9182\n",
      "Epoch 28/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2393 - acc: 0.9188\n",
      "Epoch 29/30\n",
      "4706/4706 [==============================] - 0s 73us/step - loss: 0.2402 - acc: 0.9207\n",
      "Epoch 30/30\n",
      "4706/4706 [==============================] - 0s 74us/step - loss: 0.2400 - acc: 0.9169\n",
      "2354/2354 [==============================] - 2s 671us/step\n",
      "4706/4706 [==============================] - 0s 54us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 832us/step - loss: 0.4930 - acc: 0.7939\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.3057 - acc: 0.8923\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 92us/step - loss: 0.2707 - acc: 0.9014\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2653 - acc: 0.9065\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2638 - acc: 0.9069\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 68us/step - loss: 0.2642 - acc: 0.9076\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2621 - acc: 0.9099\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2614 - acc: 0.9080\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2616 - acc: 0.9076\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 69us/step - loss: 0.2604 - acc: 0.9069\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2606 - acc: 0.9059\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2614 - acc: 0.9091\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 70us/step - loss: 0.2610 - acc: 0.9076\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 103us/step - loss: 0.2600 - acc: 0.9089\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 94us/step - loss: 0.2601 - acc: 0.9078\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 71us/step - loss: 0.2603 - acc: 0.9076\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2604 - acc: 0.9078\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2596 - acc: 0.9069\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 89us/step - loss: 0.2600 - acc: 0.9074\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2603 - acc: 0.9101\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2607 - acc: 0.9057\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2608 - acc: 0.9095\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2605 - acc: 0.9093\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 74us/step - loss: 0.2591 - acc: 0.9093\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2601 - acc: 0.9063\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 72us/step - loss: 0.2607 - acc: 0.9110\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2611 - acc: 0.9084\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2599 - acc: 0.9095\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 73us/step - loss: 0.2603 - acc: 0.9078\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2598 - acc: 0.9055\n",
      "2353/2353 [==============================] - 2s 700us/step\n",
      "4707/4707 [==============================] - 0s 61us/step\n",
      "Epoch 1/30\n",
      "4707/4707 [==============================] - 4s 855us/step - loss: 0.5086 - acc: 0.7680\n",
      "Epoch 2/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2994 - acc: 0.9001\n",
      "Epoch 3/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2588 - acc: 0.9091\n",
      "Epoch 4/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2529 - acc: 0.9112\n",
      "Epoch 5/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2504 - acc: 0.9118\n",
      "Epoch 6/30\n",
      "4707/4707 [==============================] - 0s 88us/step - loss: 0.2500 - acc: 0.9127\n",
      "Epoch 7/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2507 - acc: 0.9123\n",
      "Epoch 8/30\n",
      "4707/4707 [==============================] - 0s 83us/step - loss: 0.2509 - acc: 0.9112\n",
      "Epoch 9/30\n",
      "4707/4707 [==============================] - 0s 89us/step - loss: 0.2494 - acc: 0.9112\n",
      "Epoch 10/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2494 - acc: 0.9112\n",
      "Epoch 11/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2491 - acc: 0.9127\n",
      "Epoch 12/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2495 - acc: 0.9110\n",
      "Epoch 13/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2495 - acc: 0.9123\n",
      "Epoch 14/30\n",
      "4707/4707 [==============================] - 0s 82us/step - loss: 0.2492 - acc: 0.9106\n",
      "Epoch 15/30\n",
      "4707/4707 [==============================] - 0s 80us/step - loss: 0.2482 - acc: 0.9131\n",
      "Epoch 16/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2489 - acc: 0.9120\n",
      "Epoch 17/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2478 - acc: 0.9135\n",
      "Epoch 18/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2486 - acc: 0.9114\n",
      "Epoch 19/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2481 - acc: 0.9118\n",
      "Epoch 20/30\n",
      "4707/4707 [==============================] - 0s 81us/step - loss: 0.2474 - acc: 0.9148\n",
      "Epoch 21/30\n",
      "4707/4707 [==============================] - 0s 84us/step - loss: 0.2480 - acc: 0.9112\n",
      "Epoch 22/30\n",
      "4707/4707 [==============================] - 0s 85us/step - loss: 0.2483 - acc: 0.9120\n",
      "Epoch 23/30\n",
      "4707/4707 [==============================] - 0s 86us/step - loss: 0.2479 - acc: 0.9116\n",
      "Epoch 24/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2481 - acc: 0.9120\n",
      "Epoch 25/30\n",
      "4707/4707 [==============================] - 0s 77us/step - loss: 0.2469 - acc: 0.9091\n",
      "Epoch 26/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2482 - acc: 0.9146\n",
      "Epoch 27/30\n",
      "4707/4707 [==============================] - 0s 76us/step - loss: 0.2487 - acc: 0.9123\n",
      "Epoch 28/30\n",
      "4707/4707 [==============================] - 0s 78us/step - loss: 0.2484 - acc: 0.9125\n",
      "Epoch 29/30\n",
      "4707/4707 [==============================] - 0s 79us/step - loss: 0.2471 - acc: 0.9137\n",
      "Epoch 30/30\n",
      "4707/4707 [==============================] - 0s 87us/step - loss: 0.2479 - acc: 0.9101\n",
      "2353/2353 [==============================] - 2s 656us/step\n",
      "4707/4707 [==============================] - 0s 46us/step\n",
      "Epoch 1/30\n",
      "7060/7060 [==============================] - 4s 585us/step - loss: 0.4522 - acc: 0.8407\n",
      "Epoch 2/30\n",
      "7060/7060 [==============================] - 0s 66us/step - loss: 0.2569 - acc: 0.9075\n",
      "Epoch 3/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.2369 - acc: 0.9133\n",
      "Epoch 4/30\n",
      "7060/7060 [==============================] - 1s 72us/step - loss: 0.2307 - acc: 0.9153\n",
      "Epoch 5/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.2257 - acc: 0.9191\n",
      "Epoch 6/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.2223 - acc: 0.9186\n",
      "Epoch 7/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.2193 - acc: 0.9221\n",
      "Epoch 8/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.2171 - acc: 0.9215\n",
      "Epoch 9/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.2141 - acc: 0.9229\n",
      "Epoch 10/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.2121 - acc: 0.9232\n",
      "Epoch 11/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.2102 - acc: 0.9239\n",
      "Epoch 12/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.2083 - acc: 0.9241\n",
      "Epoch 13/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.2063 - acc: 0.9259\n",
      "Epoch 14/30\n",
      "7060/7060 [==============================] - 0s 67us/step - loss: 0.2047 - acc: 0.9248\n",
      "Epoch 15/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.2023 - acc: 0.9279\n",
      "Epoch 16/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.2005 - acc: 0.9272\n",
      "Epoch 17/30\n",
      "7060/7060 [==============================] - 0s 70us/step - loss: 0.1992 - acc: 0.9271\n",
      "Epoch 18/30\n",
      "7060/7060 [==============================] - 0s 69us/step - loss: 0.1975 - acc: 0.9288\n",
      "Epoch 19/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1958 - acc: 0.9285\n",
      "Epoch 20/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1942 - acc: 0.9280\n",
      "Epoch 21/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1924 - acc: 0.9322\n",
      "Epoch 22/30\n",
      "7060/7060 [==============================] - 1s 73us/step - loss: 0.1908 - acc: 0.9289\n",
      "Epoch 23/30\n",
      "7060/7060 [==============================] - 1s 116us/step - loss: 0.1906 - acc: 0.9313\n",
      "Epoch 24/30\n",
      "7060/7060 [==============================] - 1s 84us/step - loss: 0.1886 - acc: 0.9317\n",
      "Epoch 25/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1876 - acc: 0.9303\n",
      "Epoch 26/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1870 - acc: 0.9296\n",
      "Epoch 27/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1869 - acc: 0.9319\n",
      "Epoch 28/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1849 - acc: 0.9316\n",
      "Epoch 29/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1838 - acc: 0.9317\n",
      "Epoch 30/30\n",
      "7060/7060 [==============================] - 0s 68us/step - loss: 0.1830 - acc: 0.9322\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=new_model_act, epochs=30, batch_size=40, verbose=1)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.918130 using {'activation': 'relu'}\n",
      "0.913173 (0.010280) with: {'activation': 'softmax'}\n",
      "0.913739 (0.009300) with: {'activation': 'softplus'}\n",
      "0.914023 (0.010233) with: {'activation': 'softsign'}\n",
      "0.918130 (0.005206) with: {'activation': 'relu'}\n",
      "0.916856 (0.007404) with: {'activation': 'tanh'}\n",
      "0.914731 (0.007351) with: {'activation': 'sigmoid'}\n",
      "0.912890 (0.008579) with: {'activation': 'hard_sigmoid'}\n",
      "0.911190 (0.006001) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model_hl():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=35, kernel_initializer='normal', activation='relu'))\n",
    "    #if we want a hidden layer :\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "70598/70598 [==============================] - 9s 129us/step - loss: 0.2550 - acc: 0.9051\n",
      "Epoch 2/30\n",
      "70598/70598 [==============================] - 6s 80us/step - loss: 0.2095 - acc: 0.9240\n",
      "Epoch 3/30\n",
      "70598/70598 [==============================] - 6s 81us/step - loss: 0.2041 - acc: 0.9255\n",
      "Epoch 4/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.2011 - acc: 0.9261\n",
      "Epoch 5/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1991 - acc: 0.9274\n",
      "Epoch 6/30\n",
      "70598/70598 [==============================] - 6s 80us/step - loss: 0.1975 - acc: 0.9272\n",
      "Epoch 7/30\n",
      "70598/70598 [==============================] - 6s 80us/step - loss: 0.1959 - acc: 0.9278\n",
      "Epoch 8/30\n",
      "70598/70598 [==============================] - 6s 82us/step - loss: 0.1946 - acc: 0.9279\n",
      "Epoch 9/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1937 - acc: 0.9283\n",
      "Epoch 10/30\n",
      "70598/70598 [==============================] - 6s 83us/step - loss: 0.1924 - acc: 0.9288\n",
      "Epoch 11/30\n",
      "70598/70598 [==============================] - 6s 84us/step - loss: 0.1915 - acc: 0.9290\n",
      "Epoch 12/30\n",
      "70598/70598 [==============================] - 6s 86us/step - loss: 0.1905 - acc: 0.9286\n",
      "Epoch 13/30\n",
      "70598/70598 [==============================] - 6s 82us/step - loss: 0.1897 - acc: 0.9291\n",
      "Epoch 14/30\n",
      "70598/70598 [==============================] - 6s 81us/step - loss: 0.1891 - acc: 0.9296\n",
      "Epoch 15/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1883 - acc: 0.9295\n",
      "Epoch 16/30\n",
      "70598/70598 [==============================] - 6s 83us/step - loss: 0.1875 - acc: 0.9294\n",
      "Epoch 17/30\n",
      "70598/70598 [==============================] - 6s 83us/step - loss: 0.1865 - acc: 0.9302\n",
      "Epoch 18/30\n",
      "70598/70598 [==============================] - 6s 84us/step - loss: 0.1860 - acc: 0.9304\n",
      "Epoch 19/30\n",
      "70598/70598 [==============================] - 6s 84us/step - loss: 0.1853 - acc: 0.9301\n",
      "Epoch 20/30\n",
      "70598/70598 [==============================] - 6s 83us/step - loss: 0.1848 - acc: 0.9305\n",
      "Epoch 21/30\n",
      "70598/70598 [==============================] - 6s 82us/step - loss: 0.1844 - acc: 0.9301\n",
      "Epoch 22/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1839 - acc: 0.9308\n",
      "Epoch 23/30\n",
      "70598/70598 [==============================] - 5s 75us/step - loss: 0.1832 - acc: 0.9309\n",
      "Epoch 24/30\n",
      "70598/70598 [==============================] - 5s 75us/step - loss: 0.1827 - acc: 0.9308\n",
      "Epoch 25/30\n",
      "70598/70598 [==============================] - 5s 76us/step - loss: 0.1820 - acc: 0.9307\n",
      "Epoch 26/30\n",
      "70598/70598 [==============================] - 5s 75us/step - loss: 0.1817 - acc: 0.9312\n",
      "Epoch 27/30\n",
      "70598/70598 [==============================] - 5s 76us/step - loss: 0.1810 - acc: 0.9314\n",
      "Epoch 28/30\n",
      "70598/70598 [==============================] - 6s 78us/step - loss: 0.1805 - acc: 0.9319\n",
      "Epoch 29/30\n",
      "70598/70598 [==============================] - 5s 74us/step - loss: 0.1798 - acc: 0.9322\n",
      "Epoch 30/30\n",
      "70598/70598 [==============================] - 5s 75us/step - loss: 0.1790 - acc: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c99ceb278>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=new_model_hl()\n",
    "model.fit(X_train_no_corr, y_train,epochs=30, batch_size=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0220709 24841\n",
      "    1 1068 16225\n",
      "\n",
      "Accuracy Score:\n",
      "0.901427848564\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.94    245550\n",
      "          1       0.40      0.94      0.56     17293\n",
      "\n",
      "avg / total       0.96      0.90      0.92    262843\n",
      "\n",
      "Log Loss:\n",
      "0.214895750254\n",
      "AUC Score:\n",
      "0.970539598374\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model,X_test_no_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model according to parameter tuning\n",
    "Chosen configuration:\n",
    "- input dimensions: 35 after removing correlated features\n",
    "- activation function: Relu\n",
    "- optimizer: Adam\n",
    "- hidden layer: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model_final():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=35, kernel_initializer='normal', activation='relu'))\n",
    "    #if we want a hidden layer :\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "70598/70598 [==============================] - 10s 140us/step - loss: 0.2503 - acc: 0.9101\n",
      "Epoch 2/30\n",
      "70598/70598 [==============================] - 7s 96us/step - loss: 0.2082 - acc: 0.9246\n",
      "Epoch 3/30\n",
      "70598/70598 [==============================] - 6s 88us/step - loss: 0.2033 - acc: 0.9264\n",
      "Epoch 4/30\n",
      "70598/70598 [==============================] - 6s 88us/step - loss: 0.2004 - acc: 0.9273\n",
      "Epoch 5/30\n",
      "70598/70598 [==============================] - 6s 88us/step - loss: 0.1980 - acc: 0.9276\n",
      "Epoch 6/30\n",
      "70598/70598 [==============================] - 6s 87us/step - loss: 0.1961 - acc: 0.9282\n",
      "Epoch 7/30\n",
      "70598/70598 [==============================] - 6s 80us/step - loss: 0.1949 - acc: 0.9281\n",
      "Epoch 8/30\n",
      "70598/70598 [==============================] - 6s 80us/step - loss: 0.1932 - acc: 0.9286\n",
      "Epoch 9/30\n",
      "70598/70598 [==============================] - 6s 90us/step - loss: 0.1919 - acc: 0.9287\n",
      "Epoch 10/30\n",
      "70598/70598 [==============================] - 5s 74us/step - loss: 0.1909 - acc: 0.9292\n",
      "Epoch 11/30\n",
      "70598/70598 [==============================] - 6s 86us/step - loss: 0.1900 - acc: 0.9289\n",
      "Epoch 12/30\n",
      "70598/70598 [==============================] - 6s 86us/step - loss: 0.1890 - acc: 0.9301\n",
      "Epoch 13/30\n",
      "70598/70598 [==============================] - 6s 89us/step - loss: 0.1879 - acc: 0.9300\n",
      "Epoch 14/30\n",
      "70598/70598 [==============================] - 5s 77us/step - loss: 0.1875 - acc: 0.9298\n",
      "Epoch 15/30\n",
      "70598/70598 [==============================] - 6s 88us/step - loss: 0.1863 - acc: 0.9301\n",
      "Epoch 16/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1858 - acc: 0.9301\n",
      "Epoch 17/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1848 - acc: 0.9308\n",
      "Epoch 18/30\n",
      "70598/70598 [==============================] - 7s 96us/step - loss: 0.1839 - acc: 0.9312\n",
      "Epoch 19/30\n",
      "70598/70598 [==============================] - 6s 87us/step - loss: 0.1836 - acc: 0.9312\n",
      "Epoch 20/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1827 - acc: 0.9315\n",
      "Epoch 21/30\n",
      "70598/70598 [==============================] - 5s 72us/step - loss: 0.1823 - acc: 0.9312\n",
      "Epoch 22/30\n",
      "70598/70598 [==============================] - 5s 73us/step - loss: 0.1815 - acc: 0.9316\n",
      "Epoch 23/30\n",
      "70598/70598 [==============================] - 6s 86us/step - loss: 0.1810 - acc: 0.9321\n",
      "Epoch 24/30\n",
      "70598/70598 [==============================] - 6s 85us/step - loss: 0.1807 - acc: 0.9321\n",
      "Epoch 25/30\n",
      "70598/70598 [==============================] - 5s 76us/step - loss: 0.1801 - acc: 0.9323\n",
      "Epoch 26/30\n",
      "70598/70598 [==============================] - 5s 76us/step - loss: 0.1798 - acc: 0.9328\n",
      "Epoch 27/30\n",
      "70598/70598 [==============================] - 5s 76us/step - loss: 0.1792 - acc: 0.9326\n",
      "Epoch 28/30\n",
      "70598/70598 [==============================] - 6s 78us/step - loss: 0.1788 - acc: 0.9326\n",
      "Epoch 29/30\n",
      "70598/70598 [==============================] - 7s 99us/step - loss: 0.1784 - acc: 0.9327\n",
      "Epoch 30/30\n",
      "70598/70598 [==============================] - 6s 82us/step - loss: 0.1782 - acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca45c0668>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final=new_model_final()\n",
    "model_final.fit(X_train_no_corr, y_train,epochs=30, batch_size=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0222852 22698\n",
      "    1 1242 16051\n",
      "\n",
      "Accuracy Score:\n",
      "0.90891901249\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95    245550\n",
      "          1       0.41      0.93      0.57     17293\n",
      "\n",
      "avg / total       0.96      0.91      0.92    262843\n",
      "\n",
      "Log Loss:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdoneva/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/Users/sdoneva/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "AUC Score:\n",
      "0.970319632205\n"
     ]
    }
   ],
   "source": [
    "analytics(y_test,model_final,X_test_no_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdoneva/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def stat_logit(data_target,data_indepen):\n",
    "    logit_model=sm.Logit(data_target,data_indepen)\n",
    "    result=logit_model.fit()\n",
    "    return print(result.summary())\n",
    "\n",
    "def train_logistic_regression(data_target,data_indepen):\n",
    "    # Initialize logistic regression model\n",
    "    log_model = linear_model.LogisticRegression()\n",
    "    # Train the model\n",
    "    log_model.fit(X =data_indepen,y = data_target)\n",
    "    return log_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def confusion_matrix_report(y_true, y_pred):    \n",
    "    cm, labels = confusion_matrix(y_true, y_pred), unique_labels(y_true, y_pred)\n",
    "    column_width = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n",
    "    report = \" \" * column_width + \" \" + \"{:_^{}}\".format(\"Prediction\", column_width * len(labels))+ \"\\n\"\n",
    "    report += \" \" * column_width + \" \".join([\"{:>{}}\".format(label, column_width) for label in labels]) + \"\\n\"\n",
    "    for i, label1 in enumerate(labels):\n",
    "        report += \"{:>{}}\".format(label1, column_width) + \" \".join([\"{:{}d}\".format(cm[i, j], column_width) for j in range(len(labels))]) + \"\\n\"\n",
    "    return report\n",
    "\n",
    "def loggloss(target_test, model, data_test):\n",
    "    probabilities=model.predict_proba(data_test)\n",
    "    value=log_loss(target_test, probabilities)\n",
    "    return value\n",
    "\n",
    "def AUC(target_test, model, data_test):\n",
    "    values=model.predict_proba(data_test) #[:,1]\n",
    "    auc_score=roc_auc_score(target_test, values)\n",
    "    return auc_score\n",
    "    \n",
    "\n",
    "def analytics(target_test, model, data_test):#target of the test data #predictions as 0,1 #model (classifier) #data_test\n",
    "    y_pred=model.predict_classes(data_test) #changed for ANN\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix_report(target_test,y_pred))\n",
    "    print(\"Accuracy Score:\")\n",
    "    print(accuracy_score(target_test,y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(target_test,y_pred))\n",
    "    print(\"Log Loss:\")\n",
    "    print(loggloss(target_test, model, data_test))\n",
    "    print(\"AUC Score:\")\n",
    "    print(AUC(target_test, model, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
