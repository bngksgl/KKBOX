{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('final_train_data_StdSc.csv')\n",
    "test_data=pd.read_csv('final_test_data_StdSc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_all=train_data.drop(['msno','is_churn','Unnamed: 0'],axis=1)#this dataset shouldn't include msno and in_churn\n",
    "train_target=train_data['is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70598, 154)\n",
      "(70598,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_all.shape)\n",
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         bd  num_25_sum  num_50_sum  num_75_sum  num_985_sum  num_100_sum  \\\n",
      "0  1.005242    1.447979    1.855278    2.181346     1.498299     4.279500   \n",
      "1  1.067876    1.812864    0.403297    0.338342     0.218478     1.165877   \n",
      "2 -0.811134    0.691709    2.526819    1.119776     0.976891     0.145719   \n",
      "3  1.130510   -0.669986   -0.476966   -0.413604    -0.563636    -0.450727   \n",
      "4 -0.811134    1.466325    1.773604    0.367830     0.254028    -0.497478   \n",
      "\n",
      "   num_unq_sum  num_totalsec_sum  num_25_mean  num_50_mean        ...          \\\n",
      "0     4.180203          4.400011     0.677988     0.887971        ...           \n",
      "1     1.489773          1.256013     1.233600    -0.025824        ...           \n",
      "2     0.624301          0.297107     0.118161     1.404949        ...           \n",
      "3    -0.443168         -0.440912    -0.749262    -0.341240        ...           \n",
      "4     0.216546         -0.404540     1.081068     1.258413        ...           \n",
      "\n",
      "    city_21   city_22  gender_0  gender_1  gender_2  registered_via_3  \\\n",
      "0 -0.077186 -0.222218 -0.508672  1.847228 -1.146185         -0.357804   \n",
      "1 -0.077186 -0.222218  1.965905 -0.541352 -1.146185         -0.357804   \n",
      "2 -0.077186 -0.222218 -0.508672 -0.541352  0.872460         -0.357804   \n",
      "3 -0.077186 -0.222218 -0.508672  1.847228 -1.146185         -0.357804   \n",
      "4 -0.077186 -0.222218 -0.508672 -0.541352  0.872460         -0.357804   \n",
      "\n",
      "   registered_via_4  registered_via_7  registered_via_9  registered_via_13  \n",
      "0          -0.23291         -1.157510          1.691552           -0.05888  \n",
      "1          -0.23291         -1.157510          1.691552           -0.05888  \n",
      "2          -0.23291          0.863924         -0.591173           -0.05888  \n",
      "3          -0.23291         -1.157510          1.691552           -0.05888  \n",
      "4          -0.23291          0.863924         -0.591173           -0.05888  \n",
      "\n",
      "[5 rows x 154 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: is_churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data_all.head())\n",
    "print(train_target.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'bd', 'num_25_sum', 'num_50_sum', 'num_75_sum',\n",
       "       'num_985_sum', 'num_100_sum', 'num_unq_sum', 'num_totalsec_sum',\n",
       "       'num_25_mean',\n",
       "       ...\n",
       "       'gender_0', 'gender_1', 'gender_2', 'registered_via_3',\n",
       "       'registered_via_4', 'registered_via_7', 'registered_via_9',\n",
       "       'registered_via_13', 'msno', 'is_churn'],\n",
       "      dtype='object', length=157)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262843,)\n",
      "(262843, 154)\n"
     ]
    }
   ],
   "source": [
    "test_target=test_data['is_churn']\n",
    "test_data=test_data.drop(['msno','is_churn','Unnamed: 0'],axis=1)#this dataset shouldn't include msno and in_churn\n",
    "print(test_target.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: is_churn, dtype: int64\n",
      "         bd  num_25_sum  num_50_sum  num_75_sum  num_985_sum  num_100_sum  \\\n",
      "0 -0.840527   -0.522259   -0.602739   -0.584220    -0.377952    -0.114536   \n",
      "1  0.792488   -0.581050   -0.640079   -0.575303    -0.433727    -0.338979   \n",
      "2 -0.840527    2.572062    0.634802    1.011987     0.525592     1.136128   \n",
      "3  1.106529   -0.337487   -0.261348   -0.236443    -0.271981    -0.261964   \n",
      "4  1.671803   -0.207907   -0.111990   -0.067013     0.034778    -0.332928   \n",
      "\n",
      "   num_unq_sum  num_totalsec_sum  num_25_mean  num_50_mean        ...          \\\n",
      "0    -0.192430         -0.146375    -0.703467    -0.759848        ...           \n",
      "1    -0.497846         -0.337333    -0.665328    -0.703208        ...           \n",
      "2     1.511263          1.035867     1.827277     0.159349        ...           \n",
      "3    -0.285715         -0.268519    -0.503196    -0.407678        ...           \n",
      "4    -0.290694         -0.320169    -0.297483    -0.177535        ...           \n",
      "\n",
      "    city_21   city_22  gender_0  gender_1  gender_2  registered_via_3  \\\n",
      "0 -0.078554 -0.225343 -0.524053 -0.556615  0.908187          2.711588   \n",
      "1 -0.078554 -0.225343  1.908205 -0.556615 -1.101094         -0.368788   \n",
      "2 -0.078554 -0.225343 -0.524053 -0.556615  0.908187         -0.368788   \n",
      "3 -0.078554 -0.225343 -0.524053  1.796573 -1.101094         -0.368788   \n",
      "4 -0.078554 -0.225343 -0.524053  1.796573 -1.101094          2.711588   \n",
      "\n",
      "   registered_via_4  registered_via_7  registered_via_9  registered_via_13  \n",
      "0         -0.243489         -1.105817         -0.608882          -0.061113  \n",
      "1         -0.243489         -1.105817          1.642354          -0.061113  \n",
      "2         -0.243489          0.904309         -0.608882          -0.061113  \n",
      "3         -0.243489          0.904309         -0.608882          -0.061113  \n",
      "4         -0.243489         -1.105817         -0.608882          -0.061113  \n",
      "\n",
      "[5 rows x 154 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_target.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#writing the functions\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Metrics on Test\n",
    "def confusion_matrix_report(y_true, y_pred):\n",
    "    cm, labels = confusion_matrix(y_true, y_pred), unique_labels(y_true, y_pred)\n",
    "    column_width = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n",
    "    report = \" \" * column_width + \" \" + \"{:_^{}}\".format(\"Prediction\", column_width * len(labels))+ \"\\n\"\n",
    "    report += \" \" * column_width + \" \".join([\"{:>{}}\".format(label, column_width) for label in labels]) + \"\\n\"\n",
    "    for i, label1 in enumerate(labels):\n",
    "        report += \"{:>{}}\".format(label1, column_width) + \" \".join([\"{:{}d}\".format(cm[i, j], column_width) for j in range(len(labels))]) + \"\\n\"\n",
    "    return report\n",
    "\n",
    "def loggloss(target_test, model, data_test):\n",
    "    probabilities=model.predict_proba(data_test)\n",
    "    value=log_loss(target_test, probabilities)\n",
    "    return value\n",
    "    \n",
    "def AUC(target_test, model, data_test):\n",
    "    values=model.predict_proba(data_test)[:,1]\n",
    "    auc_score=roc_auc_score(target_test, values)\n",
    "    return auc_score\n",
    "    \n",
    "def analytics(target_test, model, data_test):#target of the test data #predictions as 0,1 #model (knnclassifier) #data_test\n",
    "    y_pred=model.predict(data_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix_report(target_test,y_pred))\n",
    "    print(\"Accuracy Score:\")\n",
    "    print(accuracy_score(target_test,y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(target_test,y_pred))\n",
    "    print(\"Log Loss:\")\n",
    "    print(loggloss(target_test, model, data_test))\n",
    "    print(\"AUC Score:\")\n",
    "    print(AUC(target_test, model, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#special functions for logistic regression\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def stat_logit(data_target,data_indepen):\n",
    "    logit_model=sm.Logit(data_target,data_indepen)\n",
    "    result=logit_model.fit()\n",
    "    return print(result.summary())\n",
    "\n",
    "def train_logistic_regression(data_target,data_indepen):\n",
    "    # Initialize logistic regression model\n",
    "    log_model = linear_model.LogisticRegression()\n",
    "    # Train the model\n",
    "    log_model.fit(X =data_indepen,y = data_target)\n",
    "    return log_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Logistic modeling with all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.408385\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bengi\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Bengi\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1029: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.diag(self.cov_params()))\n",
      "C:\\Users\\Bengi\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Bengi\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Bengi\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               is_churn   No. Observations:                70598\n",
      "Model:                          Logit   Df Residuals:                    70459\n",
      "Method:                           MLE   Df Model:                          138\n",
      "Date:                Thu, 30 Nov 2017   Pseudo R-squ.:                  0.4108\n",
      "Time:                        12:17:19   Log-Likelihood:                -28831.\n",
      "converged:                      False   LL-Null:                       -48935.\n",
      "                                        LLR p-value:                     0.000\n",
      "=====================================================================================================\n",
      "                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "bd                                    0.0149      0.023      0.632      0.527      -0.031       0.061\n",
      "num_25_sum                            0.0351    2.4e+05   1.46e-07      1.000    -4.7e+05     4.7e+05\n",
      "num_50_sum                           -0.0308   4.27e+04  -7.22e-07      1.000   -8.37e+04    8.37e+04\n",
      "num_75_sum                            0.0311   1.37e+04   2.27e-06      1.000   -2.69e+04    2.69e+04\n",
      "num_985_sum                           0.0419   1.71e+04   2.46e-06      1.000   -3.34e+04    3.34e+04\n",
      "num_100_sum                           0.0887   4.07e+05   2.18e-07      1.000   -7.97e+05    7.97e+05\n",
      "num_unq_sum                          -0.0336      0.121     -0.278      0.781      -0.271       0.204\n",
      "num_totalsec_sum                     -0.4063      0.344     -1.180      0.238      -1.081       0.269\n",
      "num_25_mean                          -0.0536      0.048     -1.113      0.266      -0.148       0.041\n",
      "num_50_mean                           0.0325      0.042      0.779      0.436      -0.049       0.114\n",
      "num_75_mean                          -0.0250      0.037     -0.680      0.496      -0.097       0.047\n",
      "num_985_mean                         -0.0608      0.042     -1.452      0.146      -0.143       0.021\n",
      "num_100_mean                          0.1458      0.243      0.600      0.548      -0.330       0.622\n",
      "num_unq_mean                          0.1052      0.096      1.097      0.273      -0.083       0.293\n",
      "num_totalsec_mean                    -0.1676      0.251     -0.667      0.505      -0.660       0.325\n",
      "num_25_med                            0.0032      0.030      0.106      0.916      -0.056       0.062\n",
      "num_50_med                           -0.0272      0.020     -1.338      0.181      -0.067       0.013\n",
      "num_75_med                            0.0065      0.018      0.353      0.724      -0.030       0.043\n",
      "num_985_med                           0.0182      0.020      0.924      0.356      -0.020       0.057\n",
      "num_100_med                          -0.1679      0.116     -1.441      0.150      -0.396       0.060\n",
      "num_unq_med                          -0.0417      0.053     -0.788      0.431      -0.146       0.062\n",
      "num_totalsec_med                      0.1329      0.120      1.106      0.269      -0.103       0.368\n",
      "num_25_max                           -0.0078      0.016     -0.476      0.634      -0.040       0.024\n",
      "num_50_max                           -0.0198      0.022     -0.917      0.359      -0.062       0.023\n",
      "num_75_max                           -0.0082      0.019     -0.443      0.658      -0.045       0.028\n",
      "num_985_max                          -0.0161      0.018     -0.877      0.381      -0.052       0.020\n",
      "num_100_max                          -0.0298      0.060     -0.495      0.620      -0.148       0.088\n",
      "num_unq_max                           0.0137      0.027      0.498      0.619      -0.040       0.067\n",
      "num_totalsec_max                      0.0147      0.061      0.238      0.812      -0.106       0.135\n",
      "num_25_min                            0.0020      0.020      0.100      0.920      -0.037       0.041\n",
      "num_50_min                           -0.0068      0.017     -0.414      0.679      -0.039       0.026\n",
      "num_75_min                            0.0169      0.015      1.113      0.266      -0.013       0.047\n",
      "num_985_min                           0.0041      0.011      0.375      0.708      -0.017       0.025\n",
      "num_100_min                           0.0218      0.034      0.644      0.520      -0.045       0.088\n",
      "num_unq_min                           0.0070      0.025      0.278      0.781      -0.042       0.056\n",
      "num_totalsec_min                     -0.0157      0.039     -0.408      0.683      -0.091       0.060\n",
      "number_of_days_listened               0.9804      0.059     16.609      0.000       0.865       1.096\n",
      "num_25_201702_sum                     0.1282   1.46e+05   8.77e-07      1.000   -2.87e+05    2.87e+05\n",
      "num_50_201702_sum                    -0.1029   1.98e+05   -5.2e-07      1.000   -3.88e+05    3.88e+05\n",
      "num_75_201702_sum                     0.2810        nan        nan        nan         nan         nan\n",
      "num_985_201702_sum                    0.0753   4.89e+05   1.54e-07      1.000   -9.59e+05    9.59e+05\n",
      "num_100_201702_sum                    1.4664   8.92e+04   1.64e-05      1.000   -1.75e+05    1.75e+05\n",
      "num_unq_201702_sum                   -0.0104        nan        nan        nan         nan         nan\n",
      "num_totalsec_201702_sum              -1.0108    2.9e+05  -3.49e-06      1.000   -5.68e+05    5.68e+05\n",
      "num_25_201702_mean                    0.0148      0.033      0.443      0.658      -0.051       0.080\n",
      "num_50_201702_mean                   -0.0240      0.031     -0.785      0.433      -0.084       0.036\n",
      "num_75_201702_mean                   -0.0363      0.032     -1.119      0.263      -0.100       0.027\n",
      "num_985_201702_mean                   0.0275      0.035      0.776      0.438      -0.042       0.097\n",
      "num_100_201702_mean                  -0.1594      0.187     -0.850      0.395      -0.527       0.208\n",
      "num_unq_201702_mean                  -0.1250      0.075     -1.672      0.095      -0.272       0.022\n",
      "num_totalsec_201702_mean              0.0667      0.194      0.344      0.731      -0.314       0.447\n",
      "number_of_days_201702_listened       -1.2332      3e+05  -4.11e-06      1.000   -5.89e+05    5.89e+05\n",
      "num_25_201701_sum                     0.0189   1.71e+05    1.1e-07      1.000   -3.35e+05    3.35e+05\n",
      "num_50_201701_sum                    -0.0106   2.19e+05  -4.83e-08      1.000   -4.29e+05    4.29e+05\n",
      "num_75_201701_sum                     0.1358        nan        nan        nan         nan         nan\n",
      "num_985_201701_sum                    0.1787   5.69e+05   3.14e-07      1.000   -1.12e+06    1.12e+06\n",
      "num_100_201701_sum                    1.8549   8.52e+04   2.18e-05      1.000   -1.67e+05    1.67e+05\n",
      "num_unq_201701_sum                    0.1957        nan        nan        nan         nan         nan\n",
      "num_totalsec_201701_sum              -1.7021   2.99e+05   -5.7e-06      1.000   -5.85e+05    5.85e+05\n",
      "num_25_201701_mean                    0.0252      0.040      0.632      0.527      -0.053       0.103\n",
      "num_50_201701_mean                   -0.0142      0.036     -0.390      0.696      -0.086       0.057\n",
      "num_75_201701_mean                   -0.0097      0.037     -0.265      0.791      -0.082       0.062\n",
      "num_985_201701_mean                   0.0121      0.037      0.327      0.744      -0.060       0.085\n",
      "num_100_201701_mean                  -0.2907      0.251     -1.158      0.247      -0.782       0.201\n",
      "num_unq_201701_mean                  -0.1861      0.088     -2.103      0.035      -0.359      -0.013\n",
      "num_totalsec_201701_mean              0.3997      0.265      1.508      0.131      -0.120       0.919\n",
      "number_of_days_201701_listened       -0.4908   3.26e+05   -1.5e-06      1.000   -6.39e+05    6.39e+05\n",
      "num_25_201612_sum                    -0.0230    1.9e+05  -1.21e-07      1.000   -3.73e+05    3.73e+05\n",
      "num_50_201612_sum                    -0.0096   2.49e+05  -3.85e-08      1.000   -4.87e+05    4.87e+05\n",
      "num_75_201612_sum                    -0.0357        nan        nan        nan         nan         nan\n",
      "num_985_201612_sum                   -0.0542   5.84e+05  -9.28e-08      1.000   -1.14e+06    1.14e+06\n",
      "num_100_201612_sum                   -0.3116   1.11e+05  -2.82e-06      1.000   -2.17e+05    2.17e+05\n",
      "num_unq_201612_sum                   -0.0005        nan        nan        nan         nan         nan\n",
      "num_totalsec_201612_sum               0.2303   3.37e+05   6.83e-07      1.000   -6.61e+05    6.61e+05\n",
      "num_25_201612_mean                    0.0108      0.036      0.298      0.766      -0.060       0.082\n",
      "num_50_201612_mean                   -0.0014      0.029     -0.047      0.962      -0.059       0.056\n",
      "num_75_201612_mean                    0.0066      0.034      0.194      0.846      -0.060       0.073\n",
      "num_985_201612_mean                   0.0387      0.032      1.195      0.232      -0.025       0.102\n",
      "num_100_201612_mean                  -0.0857      0.217     -0.395      0.693      -0.511       0.340\n",
      "num_unq_201612_mean                  -0.0041      0.076     -0.054      0.957      -0.154       0.145\n",
      "num_totalsec_201612_mean              0.1521      0.228      0.667      0.505      -0.295       0.599\n",
      "number_of_days_201612_listened        0.0357   3.32e+05   1.07e-07      1.000   -6.51e+05    6.51e+05\n",
      "num_25_lasttwo_sum                   -0.1604      0.403     -0.398      0.691      -0.951       0.630\n",
      "num_50_lasttwo_sum                    0.0817      0.290      0.282      0.778      -0.486       0.649\n",
      "num_75_lasttwo_sum                   -0.4706      0.347     -1.355      0.175      -1.151       0.210\n",
      "num_985_lasttwo_sum                  -0.2992      0.345     -0.868      0.386      -0.975       0.377\n",
      "num_100_lasttwo_sum                  -3.9084      2.426     -1.611      0.107      -8.662       0.845\n",
      "num_unq_lasttwo_sum                  -0.1954      1.022     -0.191      0.848      -2.198       1.807\n",
      "num_totalsec_lasttwo_sum              3.4648      2.657      1.304      0.192      -1.743       8.672\n",
      "num_25_lasttwo_mean                  -0.0152      0.065     -0.233      0.816      -0.143       0.113\n",
      "num_50_lasttwo_mean                   0.0516      0.053      0.968      0.333      -0.053       0.156\n",
      "num_75_lasttwo_mean                   0.0822      0.055      1.498      0.134      -0.025       0.190\n",
      "num_985_lasttwo_mean                 -0.0418      0.059     -0.703      0.482      -0.158       0.075\n",
      "num_100_lasttwo_mean                  0.5207      0.384      1.354      0.176      -0.233       1.274\n",
      "num_unq_lasttwo_mean                  0.2476      0.147      1.689      0.091      -0.040       0.535\n",
      "num_totalsec_lasttwo_mean            -0.5650      0.391     -1.445      0.149      -1.332       0.201\n",
      "number_of_days_lasttwo_listened       1.0679      0.593      1.802      0.071      -0.093       2.229\n",
      "num_25_lastthree_sum                  0.0415    4.5e+05   9.22e-08      1.000   -8.83e+05    8.83e+05\n",
      "num_50_lastthree_sum                 -0.0448    5.6e+05     -8e-08      1.000    -1.1e+06     1.1e+06\n",
      "num_75_lastthree_sum                  0.1340        nan        nan        nan         nan         nan\n",
      "num_985_lastthree_sum                 0.0739   1.46e+06   5.06e-08      1.000   -2.86e+06    2.86e+06\n",
      "num_100_lastthree_sum                 1.0710   2.53e+05   4.23e-06      1.000   -4.96e+05    4.96e+05\n",
      "num_unq_lastthree_sum                 0.0689        nan        nan        nan         nan         nan\n",
      "num_totalsec_lastthree_sum           -0.8876   8.22e+05  -1.08e-06      1.000   -1.61e+06    1.61e+06\n",
      "num_25_lastthree_mean                -0.0380      0.062     -0.615      0.539      -0.159       0.083\n",
      "num_50_lastthree_mean                -0.0355      0.048     -0.742      0.458      -0.129       0.058\n",
      "num_75_lastthree_mean                -0.0422      0.053     -0.795      0.427      -0.146       0.062\n",
      "num_985_lastthree_mean                0.0022      0.050      0.043      0.965      -0.096       0.101\n",
      "num_100_lastthree_mean               -0.0691      0.349     -0.198      0.843      -0.754       0.615\n",
      "num_unq_lastthree_mean               -0.1103      0.135     -0.815      0.415      -0.375       0.155\n",
      "num_totalsec_lastthree_mean           0.0891      0.349      0.255      0.799      -0.595       0.774\n",
      "number_of_days_lastthree_listened    -0.5713   8.81e+05  -6.48e-07      1.000   -1.73e+06    1.73e+06\n",
      "most_fq_payment_method_id             0.1144      0.014      8.179      0.000       0.087       0.142\n",
      "most_frq_payment_plan_days            0.0345      0.015      2.368      0.018       0.006       0.063\n",
      "total_churn                           0.0018      0.012      0.154      0.878      -0.022       0.025\n",
      "is_auto_renew                        -0.6416      0.011    -57.135      0.000      -0.664      -0.620\n",
      "total_cancel                          0.6297      0.010     66.012      0.000       0.611       0.648\n",
      "active_days                          -0.8472      0.013    -65.344      0.000      -0.873      -0.822\n",
      "avg_plan_list_price                   0.0283        nan        nan        nan         nan         nan\n",
      "avg_actual_amount_paid                0.0290        nan        nan        nan         nan         nan\n",
      "payment_different                     0.0172        nan        nan        nan         nan         nan\n",
      "num_below_50_sum                      0.0239   4.85e+05   4.93e-08      1.000   -9.51e+05    9.51e+05\n",
      "num_above_50_sum                      0.0877   3.51e+05    2.5e-07      1.000   -6.88e+05    6.88e+05\n",
      "total_songs_listened                  0.0807    9.1e+05   8.87e-08      1.000   -1.78e+06    1.78e+06\n",
      "proportion_songs_above_50            -0.0353      0.017     -2.077      0.038      -0.069      -0.002\n",
      "city_1                                0.0298   1.99e+05    1.5e-07      1.000   -3.89e+05    3.89e+05\n",
      "city_3                                0.0133   5.02e+04   2.64e-07      1.000   -9.85e+04    9.85e+04\n",
      "city_4                               -0.0164   1.09e+05   -1.5e-07      1.000   -2.15e+05    2.15e+05\n",
      "city_5                                0.0076   1.64e+05   4.61e-08      1.000   -3.22e+05    3.22e+05\n",
      "city_6                               -0.0226    9.5e+04  -2.38e-07      1.000   -1.86e+05    1.86e+05\n",
      "city_7                               -0.0037   3.15e+04  -1.16e-07      1.000   -6.18e+04    6.18e+04\n",
      "city_8                                0.0172   5.18e+04   3.31e-07      1.000   -1.02e+05    1.02e+05\n",
      "city_9                               -0.0008   5.07e+04  -1.53e-08      1.000   -9.93e+04    9.93e+04\n",
      "city_10                               0.0080   4.69e+04   1.71e-07      1.000   -9.19e+04    9.19e+04\n",
      "city_11                              -0.0035   5.75e+04  -6.12e-08      1.000   -1.13e+05    1.13e+05\n",
      "city_12                               0.0031   6.35e+04    4.9e-08      1.000   -1.24e+05    1.24e+05\n",
      "city_13                              -0.0214   1.74e+05  -1.23e-07      1.000    -3.4e+05     3.4e+05\n",
      "city_14                               0.0085    9.2e+04   9.19e-08      1.000    -1.8e+05     1.8e+05\n",
      "city_15                              -0.0080   1.15e+05     -7e-08      1.000   -2.25e+05    2.25e+05\n",
      "city_16                               0.0178   2.12e+04    8.4e-07      1.000   -4.16e+04    4.16e+04\n",
      "city_17                              -0.0178   5.05e+04  -3.52e-07      1.000   -9.91e+04    9.91e+04\n",
      "city_18                               0.0086   5.38e+04   1.59e-07      1.000   -1.05e+05    1.05e+05\n",
      "city_19                              -0.0025   7010.781  -3.61e-07      1.000   -1.37e+04    1.37e+04\n",
      "city_20                               0.0004   1.55e+04   2.83e-08      1.000   -3.04e+04    3.04e+04\n",
      "city_21                               0.0054   4.51e+04   1.21e-07      1.000   -8.84e+04    8.84e+04\n",
      "city_22                              -0.0273   1.17e+05  -2.32e-07      1.000    -2.3e+05     2.3e+05\n",
      "gender_0                              0.0088        nan        nan        nan         nan         nan\n",
      "gender_1                              0.0087        nan        nan        nan         nan         nan\n",
      "gender_2                             -0.0146        nan        nan        nan         nan         nan\n",
      "registered_via_3                      0.0308   5.88e+05   5.24e-08      1.000   -1.15e+06    1.15e+06\n",
      "registered_via_4                      0.0434    4.1e+05   1.06e-07      1.000   -8.03e+05    8.03e+05\n",
      "registered_via_7                     -0.0874   9.18e+05  -9.52e-08      1.000    -1.8e+06     1.8e+06\n",
      "registered_via_9                      0.0581   8.13e+05   7.15e-08      1.000   -1.59e+06    1.59e+06\n",
      "registered_via_13                    -0.0272   1.09e+05   -2.5e-07      1.000   -2.13e+05    2.13e+05\n",
      "=====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "stat_logit(train_target,train_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0218998 26552\n",
      "    1 1433 15860\n",
      "\n",
      "Accuracy Score:\n",
      "0.893529597516\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.89      0.94    245550\n",
      "          1       0.37      0.92      0.53     17293\n",
      "\n",
      "avg / total       0.95      0.89      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.267962595211\n",
      "AUC Score:\n",
      "0.954283851469\n"
     ]
    }
   ],
   "source": [
    "log_model_1=train_logistic_regression(train_target,train_data_all)\n",
    "analytics(test_target, log_model_1, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model1=log_model_1.predict_proba(test_data)[:,1]\n",
    "test_data['model1']=y_score_model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Logistic modeling with all selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409790\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               is_churn   No. Observations:                70598\n",
      "Model:                          Logit   Df Residuals:                    70563\n",
      "Method:                           MLE   Df Model:                           34\n",
      "Date:                Thu, 30 Nov 2017   Pseudo R-squ.:                  0.4088\n",
      "Time:                        12:17:46   Log-Likelihood:                -28930.\n",
      "converged:                       True   LL-Null:                       -48935.\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "number_of_days_201702_listened    -0.9042      0.028    -31.990      0.000      -0.960      -0.849\n",
      "is_auto_renew                     -0.6430      0.011    -58.314      0.000      -0.665      -0.621\n",
      "total_cancel                       0.6273      0.009     66.071      0.000       0.609       0.646\n",
      "active_days                       -0.8293      0.012    -66.435      0.000      -0.854      -0.805\n",
      "avg_actual_amount_paid             0.0830      0.013      6.160      0.000       0.057       0.109\n",
      "most_fq_payment_method_id          0.1213      0.014      8.868      0.000       0.094       0.148\n",
      "num_75_mean                       -0.0329      0.016     -2.078      0.038      -0.064      -0.002\n",
      "number_of_days_listened            0.7285      0.030     24.099      0.000       0.669       0.788\n",
      "num_25_201702_sum                  0.0652      0.023      2.802      0.005       0.020       0.111\n",
      "num_50_201702_sum                 -0.0149      0.025     -0.600      0.548      -0.064       0.034\n",
      "num_100_201702_sum                 0.1832      0.026      6.933      0.000       0.131       0.235\n",
      "num_25_201702_mean                 0.0073      0.018      0.410      0.682      -0.028       0.042\n",
      "num_50_201702_mean                -0.0166      0.022     -0.770      0.441      -0.059       0.026\n",
      "num_totalsec_lasttwo_mean          0.0361      0.024      1.515      0.130      -0.011       0.083\n",
      "total_churn                        0.0058      0.012      0.487      0.627      -0.018       0.029\n",
      "registered_via_3                   0.1761      0.059      2.983      0.003       0.060       0.292\n",
      "registered_via_4                   0.1428      0.042      3.436      0.001       0.061       0.224\n",
      "registered_via_7                   0.1653      0.092      1.798      0.072      -0.015       0.346\n",
      "bd                                 0.0093      0.013      0.695      0.487      -0.017       0.036\n",
      "num_totalsec_sum                  -0.0705      0.034     -2.061      0.039      -0.137      -0.003\n",
      "num_100_med                       -0.0461      0.022     -2.069      0.039      -0.090      -0.002\n",
      "num_25_max                        -0.0291      0.018     -1.635      0.102      -0.064       0.006\n",
      "num_unq_max                        0.0357      0.022      1.618      0.106      -0.008       0.079\n",
      "num_totalsec_max                  -0.0294      0.016     -1.813      0.070      -0.061       0.002\n",
      "num_totalsec_min                   0.0131      0.011      1.227      0.220      -0.008       0.034\n",
      "num_985_201702_sum                -0.0270      0.014     -1.870      0.061      -0.055       0.001\n",
      "num_75_201702_mean                 0.0162      0.021      0.780      0.435      -0.025       0.057\n",
      "num_unq_201702_mean               -0.1357      0.022     -6.183      0.000      -0.179      -0.093\n",
      "num_unq_201701_sum                -0.0333      0.020     -1.638      0.101      -0.073       0.007\n",
      "num_25_201612_mean                -0.0272      0.014     -2.006      0.045      -0.054      -0.001\n",
      "num_100_201612_mean                0.0242      0.017      1.416      0.157      -0.009       0.058\n",
      "num_75_lasttwo_mean                0.0196      0.021      0.932      0.351      -0.022       0.061\n",
      "num_50_lastthree_mean             -0.0594      0.017     -3.415      0.001      -0.094      -0.025\n",
      "proportion_songs_above_50         -0.0322      0.015     -2.146      0.032      -0.062      -0.003\n",
      "registered_via_9                   0.2630      0.081      3.248      0.001       0.104       0.422\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#logistic modeling with prechoosen variables\n",
    "data_indepen_m2=train_data_all[['number_of_days_201702_listened','is_auto_renew','total_cancel','active_days','avg_actual_amount_paid','most_fq_payment_method_id','num_75_mean','number_of_days_listened','num_25_201702_sum','num_50_201702_sum','num_100_201702_sum','num_25_201702_mean','num_50_201702_mean','num_totalsec_lasttwo_mean','total_churn','registered_via_3','registered_via_4','registered_via_7','bd','num_totalsec_sum','num_100_med','num_25_max','num_unq_max','num_totalsec_max','num_totalsec_min','num_985_201702_sum','num_75_201702_mean','num_unq_201702_mean','num_unq_201701_sum','num_25_201612_mean','num_100_201612_mean','num_75_lasttwo_mean','num_50_lastthree_mean','proportion_songs_above_50','registered_via_9']]\n",
    "stat_logit(train_target,data_indepen_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_model_2=train_logistic_regression(train_target,data_indepen_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_m2=test_data[['number_of_days_201702_listened','is_auto_renew','total_cancel','active_days','avg_actual_amount_paid','most_fq_payment_method_id','num_75_mean','number_of_days_listened','num_25_201702_sum','num_50_201702_sum','num_100_201702_sum','num_25_201702_mean','num_50_201702_mean','num_totalsec_lasttwo_mean','total_churn','registered_via_3','registered_via_4','registered_via_7','bd','num_totalsec_sum','num_100_med','num_25_max','num_unq_max','num_totalsec_max','num_totalsec_min','num_985_201702_sum','num_75_201702_mean','num_unq_201702_mean','num_unq_201701_sum','num_25_201612_mean','num_100_201612_mean','num_75_lasttwo_mean','num_50_lastthree_mean','proportion_songs_above_50','registered_via_9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0218856 26694\n",
      "    1 1463 15830\n",
      "\n",
      "Accuracy Score:\n",
      "0.892875214482\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.89      0.94    245550\n",
      "          1       0.37      0.92      0.53     17293\n",
      "\n",
      "avg / total       0.95      0.89      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.26891897735\n",
      "AUC Score:\n",
      "0.9538704791\n"
     ]
    }
   ],
   "source": [
    "analytics(test_target, log_model_2, test_data_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model2=log_model_2.predict_proba(test_data_m2)[:,1]\n",
    "test_data['model2']=y_score_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Logistic Modeling- Dropping insignificant variables from all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409952\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               is_churn   No. Observations:                70598\n",
      "Model:                          Logit   Df Residuals:                    70578\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Thu, 30 Nov 2017   Pseudo R-squ.:                  0.4086\n",
      "Time:                        12:19:13   Log-Likelihood:                -28942.\n",
      "converged:                       True   LL-Null:                       -48935.\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "number_of_days_201702_listened    -0.9312      0.027    -34.843      0.000      -0.984      -0.879\n",
      "is_auto_renew                     -0.6413      0.011    -59.239      0.000      -0.662      -0.620\n",
      "total_cancel                       0.6266      0.009     66.072      0.000       0.608       0.645\n",
      "active_days                       -0.8252      0.012    -67.002      0.000      -0.849      -0.801\n",
      "avg_actual_amount_paid             0.0842      0.013      6.271      0.000       0.058       0.111\n",
      "most_fq_payment_method_id          0.1274      0.013      9.594      0.000       0.101       0.153\n",
      "num_75_mean                       -0.0347      0.016     -2.225      0.026      -0.065      -0.004\n",
      "number_of_days_listened            0.7123      0.029     24.931      0.000       0.656       0.768\n",
      "num_25_201702_sum                  0.0522      0.015      3.420      0.001       0.022       0.082\n",
      "num_100_201702_sum                 0.1911      0.023      8.162      0.000       0.145       0.237\n",
      "total_churn                        0.0062      0.012      0.517      0.605      -0.017       0.030\n",
      "registered_via_3                   0.0760      0.012      6.148      0.000       0.052       0.100\n",
      "registered_via_4                   0.0723      0.012      6.205      0.000       0.049       0.095\n",
      "num_totalsec_sum                  -0.0744      0.029     -2.559      0.010      -0.131      -0.017\n",
      "num_100_med                       -0.0309      0.018     -1.731      0.083      -0.066       0.004\n",
      "num_unq_201702_mean               -0.1275      0.016     -7.922      0.000      -0.159      -0.096\n",
      "num_25_201612_mean                -0.0230      0.012     -1.858      0.063      -0.047       0.001\n",
      "num_75_lasttwo_mean                0.0204      0.017      1.193      0.233      -0.013       0.054\n",
      "num_50_lastthree_mean             -0.0677      0.015     -4.526      0.000      -0.097      -0.038\n",
      "registered_via_9                   0.1259      0.014      9.075      0.000       0.099       0.153\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_indepen_m3=data_indepen_m2.drop([\n",
    "'num_50_201702_sum',\n",
    "'num_25_201702_mean',                \n",
    "'num_50_201702_mean',               \n",
    "'num_totalsec_lasttwo_mean',        \n",
    "'registered_via_7',                   \n",
    "'bd',                                \n",
    "'num_25_max',                        \n",
    "'num_unq_max',                       \n",
    "'num_totalsec_max',                  \n",
    "'num_totalsec_min',                  \n",
    "'num_985_201702_sum',                \n",
    "'num_75_201702_mean',                \n",
    "'num_unq_201701_sum',\n",
    "'num_100_201612_mean',\n",
    "'proportion_songs_above_50'],axis=1)\n",
    "stat_logit(train_target,data_indepen_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0218988 26562\n",
      "    1 1495 15798\n",
      "\n",
      "Accuracy Score:\n",
      "0.893255669734\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.89      0.94    245550\n",
      "          1       0.37      0.91      0.53     17293\n",
      "\n",
      "avg / total       0.95      0.89      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.269674806882\n",
      "AUC Score:\n",
      "0.953717558772\n"
     ]
    }
   ],
   "source": [
    "log_model_3=train_logistic_regression(train_target,data_indepen_m3)\n",
    "test_data_m3=test_data_m2.drop(['num_50_201702_sum',\n",
    "'num_25_201702_mean',                \n",
    "'num_50_201702_mean',               \n",
    "'num_totalsec_lasttwo_mean',        \n",
    "'registered_via_7',                   \n",
    "'bd',                                \n",
    "'num_25_max',                        \n",
    "'num_unq_max',                       \n",
    "'num_totalsec_max',                  \n",
    "'num_totalsec_min',                  \n",
    "'num_985_201702_sum',                \n",
    "'num_75_201702_mean',                \n",
    "'num_unq_201701_sum',\n",
    "'num_100_201612_mean',\n",
    "'proportion_songs_above_50'],axis=1)\n",
    "analytics(test_target, log_model_3, test_data_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model3=log_model_3.predict_proba(test_data_m3)[:,1]\n",
    "test_data['model3']=y_score_model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Logistic Modeling-Choose 4 Ranked Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.419724\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               is_churn   No. Observations:                70598\n",
      "Model:                          Logit   Df Residuals:                    70593\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 30 Nov 2017   Pseudo R-squ.:                  0.3945\n",
      "Time:                        12:19:28   Log-Likelihood:                -29632.\n",
      "converged:                       True   LL-Null:                       -48935.\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "number_of_days_201702_listened    -0.3257      0.010    -31.103      0.000      -0.346      -0.305\n",
      "is_auto_renew                     -0.6248      0.010    -61.905      0.000      -0.645      -0.605\n",
      "total_cancel                       0.6662      0.009     72.317      0.000       0.648       0.684\n",
      "active_days                       -0.7484      0.010    -78.628      0.000      -0.767      -0.730\n",
      "avg_actual_amount_paid             0.1592      0.012     13.154      0.000       0.135       0.183\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_indepen_m4=train_data_all[['number_of_days_201702_listened',\n",
    "'is_auto_renew',\n",
    "'total_cancel',\n",
    "'active_days',\n",
    "'avg_actual_amount_paid'\n",
    "]]\n",
    "stat_logit(train_target,data_indepen_m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0216585 28965\n",
      "    1 1369 15924\n",
      "\n",
      "Accuracy Score:\n",
      "0.884592703629\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.88      0.93    245550\n",
      "          1       0.35      0.92      0.51     17293\n",
      "\n",
      "avg / total       0.95      0.88      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.290114739573\n",
      "AUC Score:\n",
      "0.947698380034\n"
     ]
    }
   ],
   "source": [
    "log_model_4=train_logistic_regression(train_target,data_indepen_m4)\n",
    "test_data_m4=test_data[['number_of_days_201702_listened',\n",
    "'is_auto_renew',\n",
    "'total_cancel',\n",
    "'active_days',\n",
    "'avg_actual_amount_paid']]\n",
    "analytics(test_target, log_model_4, test_data_m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model4=log_model_4.predict_proba(test_data_m4)[:,1]\n",
    "test_data['model4']=y_score_model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 Logistic modeling with 4 and 3 ranked variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.419292\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               is_churn   No. Observations:                70598\n",
      "Model:                          Logit   Df Residuals:                    70592\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Thu, 30 Nov 2017   Pseudo R-squ.:                  0.3951\n",
      "Time:                        12:19:41   Log-Likelihood:                -29601.\n",
      "converged:                       True   LL-Null:                       -48935.\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "number_of_days_201702_listened    -0.3242      0.010    -30.924      0.000      -0.345      -0.304\n",
      "is_auto_renew                     -0.6360      0.010    -62.410      0.000      -0.656      -0.616\n",
      "total_cancel                       0.6660      0.009     72.273      0.000       0.648       0.684\n",
      "active_days                       -0.7421      0.010    -77.219      0.000      -0.761      -0.723\n",
      "avg_actual_amount_paid             0.1981      0.013     14.693      0.000       0.172       0.225\n",
      "most_fq_payment_method_id          0.0937      0.012      7.771      0.000       0.070       0.117\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_indepen_m5=train_data_all[['number_of_days_201702_listened',\n",
    "'is_auto_renew',\n",
    "'total_cancel',\n",
    "'active_days',\n",
    "'avg_actual_amount_paid',\n",
    "'most_fq_payment_method_id'\n",
    "]]\n",
    "stat_logit(train_target,data_indepen_m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0216857 28693\n",
      "    1 1375 15918\n",
      "\n",
      "Accuracy Score:\n",
      "0.885604714601\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.88      0.94    245550\n",
      "          1       0.36      0.92      0.51     17293\n",
      "\n",
      "avg / total       0.95      0.89      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.28846621317\n",
      "AUC Score:\n",
      "0.948085725603\n"
     ]
    }
   ],
   "source": [
    "log_model_5=train_logistic_regression(train_target,data_indepen_m5)\n",
    "test_data_m5=test_data[['number_of_days_201702_listened',\n",
    "'is_auto_renew',\n",
    "'total_cancel',\n",
    "'active_days',\n",
    "'avg_actual_amount_paid',\n",
    "'most_fq_payment_method_id']]\n",
    "analytics(test_target, log_model_5, test_data_m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model5=log_model_5.predict_proba(test_data_m5)[:,1]\n",
    "test_data['model5']=y_score_model5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6. Logistic Model with 2,3,4th ranked variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.410587\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               is_churn   No. Observations:                70598\n",
      "Model:                          Logit   Df Residuals:                    70580\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Thu, 30 Nov 2017   Pseudo R-squ.:                  0.4076\n",
      "Time:                        12:19:57   Log-Likelihood:                -28987.\n",
      "converged:                       True   LL-Null:                       -48935.\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "number_of_days_201702_listened    -0.8830      0.026    -34.130      0.000      -0.934      -0.832\n",
      "is_auto_renew                     -0.6421      0.011    -59.366      0.000      -0.663      -0.621\n",
      "total_cancel                       0.6285      0.009     66.329      0.000       0.610       0.647\n",
      "active_days                       -0.8218      0.012    -67.030      0.000      -0.846      -0.798\n",
      "avg_actual_amount_paid             0.0872      0.013      6.502      0.000       0.061       0.114\n",
      "most_fq_payment_method_id          0.1285      0.014      9.519      0.000       0.102       0.155\n",
      "num_75_mean                       -0.0546      0.012     -4.392      0.000      -0.079      -0.030\n",
      "number_of_days_listened            0.6440      0.021     31.185      0.000       0.604       0.684\n",
      "num_25_201702_sum                  0.0555      0.022      2.490      0.013       0.012       0.099\n",
      "num_50_201702_sum                 -0.0105      0.024     -0.438      0.662      -0.058       0.037\n",
      "num_100_201702_sum                 0.1135      0.022      5.222      0.000       0.071       0.156\n",
      "num_25_201702_mean                -0.0386      0.016     -2.399      0.016      -0.070      -0.007\n",
      "num_50_201702_mean                -0.0441      0.019     -2.352      0.019      -0.081      -0.007\n",
      "num_totalsec_lasttwo_mean         -0.0883      0.017     -5.307      0.000      -0.121      -0.056\n",
      "total_churn                        0.0076      0.012      0.632      0.527      -0.016       0.031\n",
      "registered_via_3                  -0.0134      0.011     -1.194      0.232      -0.035       0.009\n",
      "registered_via_4                   0.0098      0.011      0.911      0.362      -0.011       0.031\n",
      "registered_via_7                  -0.1328      0.016     -8.391      0.000      -0.164      -0.102\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_indepen_m6=train_data_all[['number_of_days_201702_listened',\n",
    "'is_auto_renew',\n",
    "'total_cancel',\n",
    "'active_days',\n",
    "'avg_actual_amount_paid',\n",
    "'most_fq_payment_method_id',\n",
    "'num_75_mean',\n",
    "'number_of_days_listened',\n",
    "'num_25_201702_sum',\n",
    "'num_50_201702_sum',\n",
    "'num_100_201702_sum',\n",
    "'num_25_201702_mean',\n",
    "'num_50_201702_mean',\n",
    "'num_totalsec_lasttwo_mean',\n",
    "'total_churn',\n",
    "'registered_via_3',\n",
    "'registered_via_4',\n",
    "'registered_via_7']]\n",
    "stat_logit(train_target,data_indepen_m6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0218866 26684\n",
      "    1 1462 15831\n",
      "\n",
      "Accuracy Score:\n",
      "0.892917064559\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.89      0.94    245550\n",
      "          1       0.37      0.92      0.53     17293\n",
      "\n",
      "avg / total       0.95      0.89      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.27007172725\n",
      "AUC Score:\n",
      "0.953804352176\n"
     ]
    }
   ],
   "source": [
    "log_model_6=train_logistic_regression(train_target,data_indepen_m6)\n",
    "test_data_m6=test_data[['number_of_days_201702_listened',\n",
    "'is_auto_renew',\n",
    "'total_cancel',\n",
    "'active_days',\n",
    "'avg_actual_amount_paid',\n",
    "'most_fq_payment_method_id',\n",
    "'num_75_mean',\n",
    "'number_of_days_listened',\n",
    "'num_25_201702_sum',\n",
    "'num_50_201702_sum',\n",
    "'num_100_201702_sum',\n",
    "'num_25_201702_mean',\n",
    "'num_50_201702_mean',\n",
    "'num_totalsec_lasttwo_mean',\n",
    "'total_churn',\n",
    "'registered_via_3',\n",
    "'registered_via_4',\n",
    "'registered_via_7']]\n",
    "analytics(test_target, log_model_6, test_data_m6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model6=log_model_6.predict_proba(test_data_m6)[:,1]\n",
    "test_data['model6']=y_score_model6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7. Logistic Model with RFE Selected Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.410114\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               is_churn   No. Observations:                70598\n",
      "Model:                          Logit   Df Residuals:                    70578\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Thu, 30 Nov 2017   Pseudo R-squ.:                  0.4083\n",
      "Time:                        12:20:13   Log-Likelihood:                -28953.\n",
      "converged:                       True   LL-Null:                       -48935.\n",
      "                                        LLR p-value:                     0.000\n",
      "=====================================================================================================\n",
      "                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "number_of_days_listened               0.8440      0.037     23.054      0.000       0.772       0.916\n",
      "num_totalsec_201702_sum               0.2869      0.033      8.695      0.000       0.222       0.352\n",
      "num_totalsec_201702_mean             -0.1915      0.027     -7.132      0.000      -0.244      -0.139\n",
      "number_of_days_201702_listened       -1.0073      0.247     -4.085      0.000      -1.491      -0.524\n",
      "num_unq_201701_sum                    0.0664      0.053      1.250      0.211      -0.038       0.170\n",
      "number_of_days_201701_listened       -0.2180      0.275     -0.794      0.427      -0.756       0.320\n",
      "num_unq_lasttwo_sum                  -0.1747      0.063     -2.774      0.006      -0.298      -0.051\n",
      "num_100_lasttwo_mean                  0.2893      0.066      4.414      0.000       0.161       0.418\n",
      "num_totalsec_lasttwo_mean            -0.2642      0.069     -3.852      0.000      -0.399      -0.130\n",
      "number_of_days_lasttwo_listened       0.5239      0.509      1.028      0.304      -0.475       1.522\n",
      "number_of_days_lastthree_listened    -0.3977      0.074     -5.354      0.000      -0.543      -0.252\n",
      "most_fq_payment_method_id             0.1218      0.013      9.071      0.000       0.096       0.148\n",
      "is_auto_renew                        -0.6348      0.011    -58.786      0.000      -0.656      -0.614\n",
      "total_cancel                          0.6272      0.009     66.696      0.000       0.609       0.646\n",
      "active_days                          -0.8264      0.011    -72.548      0.000      -0.849      -0.804\n",
      "avg_plan_list_price                  -0.4638      0.382     -1.213      0.225      -1.213       0.286\n",
      "avg_actual_amount_paid                0.5498      0.382      1.439      0.150      -0.199       1.299\n",
      "registered_via_3                      0.0703      0.012      5.692      0.000       0.046       0.095\n",
      "registered_via_4                      0.0689      0.012      5.921      0.000       0.046       0.092\n",
      "registered_via_9                      0.1155      0.014      8.324      0.000       0.088       0.143\n",
      "=====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_indepen_m7=train_data_all[['number_of_days_listened','num_totalsec_201702_sum','num_totalsec_201702_mean','number_of_days_201702_listened','num_unq_201701_sum','number_of_days_201701_listened','num_unq_lasttwo_sum','num_100_lasttwo_mean','num_totalsec_lasttwo_mean','number_of_days_lasttwo_listened','number_of_days_lastthree_listened','most_fq_payment_method_id','is_auto_renew','total_cancel','active_days','avg_plan_list_price','avg_actual_amount_paid','registered_via_3','registered_via_4','registered_via_9']]\n",
    "stat_logit(train_target,data_indepen_m7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0218878 26672\n",
      "    1 1436 15857\n",
      "\n",
      "Accuracy Score:\n",
      "0.893061637555\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.89      0.94    245550\n",
      "          1       0.37      0.92      0.53     17293\n",
      "\n",
      "avg / total       0.95      0.89      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.268801623459\n",
      "AUC Score:\n",
      "0.953859049727\n"
     ]
    }
   ],
   "source": [
    "log_model_7=train_logistic_regression(train_target,data_indepen_m7)\n",
    "test_data_m7=test_data[['number_of_days_listened','num_totalsec_201702_sum','num_totalsec_201702_mean','number_of_days_201702_listened','num_unq_201701_sum','number_of_days_201701_listened','num_unq_lasttwo_sum','num_100_lasttwo_mean','num_totalsec_lasttwo_mean','number_of_days_lasttwo_listened','number_of_days_lastthree_listened','most_fq_payment_method_id','is_auto_renew','total_cancel','active_days','avg_plan_list_price','avg_actual_amount_paid','registered_via_3','registered_via_4','registered_via_9']]\n",
    "analytics(test_target, log_model_7, test_data_m7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model7=log_model_7.predict_proba(test_data_m7)[:,1]\n",
    "test_data['model7']=y_score_model7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.8. Logistic Model with Grid Search using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bengi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch: tunning parameter\n",
    "temp = train_target.reshape(-1,1)\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lr=linear_model.LogisticRegression()\n",
    "parameters = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "model_lr = GridSearchCV(lr, parameters, scoring='neg_log_loss',cv=5) #focusing on minimizing log loss metric\n",
    "model_lr.fit(data_indepen_m7,train_target)\n",
    "print(model_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "      Prediction\n",
      "         0     1\n",
      "    0218890 26660\n",
      "    1 1434 15859\n",
      "\n",
      "Accuracy Score:\n",
      "0.893114901291\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.89      0.94    245550\n",
      "          1       0.37      0.92      0.53     17293\n",
      "\n",
      "avg / total       0.95      0.89      0.91    262843\n",
      "\n",
      "Log Loss:\n",
      "0.268754885813\n",
      "AUC Score:\n",
      "0.953854730198\n"
     ]
    }
   ],
   "source": [
    "analytics(test_target, model_lr, test_data_m7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_model8=model_lr.predict_proba(test_data_m7)[:,1]\n",
    "test_data['model8']=y_score_model8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTsE551zc/wB99r7miBTgggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a24d66898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ROC curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib \n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "i=0\n",
    "n=8#number of models\n",
    "col=test_data.columns\n",
    "p=154#column where the first model columns start\n",
    "colors=[\"r\", \"g\", \"b\",\"c\",\"C0\",\"m\",\"fuchsia\",\"C1\"]\n",
    "#colors = cm.rainbow(np.linspace(0,1,n)) #make sure that this equal to your number of models\n",
    "while(i<n):\n",
    "    value=test_data.iloc[:,p]\n",
    "    label=col[p]\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(test_target,value)\n",
    "    auc_score=roc_auc_score(test_target, value)\n",
    "    plt.plot(fpr_rf, tpr_rf, color=colors[i],label=label)\n",
    "    i=i+1\n",
    "    p=p+1\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve: AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taking the chosen product_proba\n",
    "y_score_model8=model_lr.predict_proba(test_data_m7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"proba_best_logistic_reg.csv\",y_score_model8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
